{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f2ab6a275df5de99",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-31T07:11:27.648187Z",
     "start_time": "2025-10-31T07:11:26.558358Z"
    }
   },
   "outputs": [],
   "source": [
    "#!pip install tensorflow numpy matplotlib opencv-python tensorflow-datasets\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "BASE_DIR = os.getcwd()\n",
    "IN_DIR = os.path.join(BASE_DIR, \"Preprocessed\")\n",
    "PREPROCESSED =os.path.join(BASE_DIR, \"Preprocessed\")\n",
    "SEGMENTED = os.path.join(BASE_DIR, \"Segmentation\")\n",
    "OUT_DIR = os.path.join(BASE_DIR, \"Segmentation\")\n",
    "#!pip install scikit-learn\n",
    "MID_DIR = PREPROCESSED\n",
    "if not os.path.exists(OUT_DIR):\n",
    "    os.makedirs(OUT_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ec5a8082c49c7509",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-31T07:11:28.400244Z",
     "start_time": "2025-10-31T07:11:28.391319Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nhow work\\n# main.py\\nfrom utils import Colors, color_text, greetegcextarct\\n\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Colour:\n",
    "  RED = \"\\033[31m\" #WRONG\n",
    "  GREEN = \"\\033[32m\"#GOOD\n",
    "  YELLOW = \"\\033[33m\"#maybe\n",
    "  BLUE = \"\\033[34m\"#Path\n",
    "  MAGENTA = \"\\033[35m\"#confirm\n",
    "\n",
    "  CYAN = \"\\033[36m\"\n",
    "  WHITE= \"\\033[37m\"\n",
    "\n",
    "  END= \"\\033[0m\"\n",
    "\n",
    "\n",
    "#Reusable end sequence for end via q\n",
    "def reuseable_end_sequence(prompter):\n",
    "  choice=input(prompter)\n",
    "  if choice.lower()=='q':# Q QUIT\n",
    "    print(f\"{Colour.RED}  Exiting Program{Colour.END}\")\n",
    "   # isEnd=True\n",
    "    raise SystemExit #immediate term\n",
    "  if choice.strip() == \"\": #EMPTY STRING\n",
    "    print(f\"{Colour.RED}   Input cannot be Left Empty.{Colour.END}\")\n",
    "    #print(\"\\033[31m  Invalid Input\\033[0m\")\n",
    "  return choice\n",
    "\n",
    "\n",
    "'''\n",
    "how work\n",
    "# main.py\n",
    "from utils import Colors, color_text, greetegcextarct\n",
    "\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63045a384214d846",
   "metadata": {},
   "source": [
    "## Load and Preprocess MNIST Data\n",
    "We use MNIST data set to train our model so we load the MNIST dataset from keras and proprocess by normalized and resize the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c8ad9e4449e2df67",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-31T07:11:44.117983Z",
     "start_time": "2025-10-31T07:11:44.102781Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "def preprocess_single(img_bgr, out_size=28, pad=5):\n",
    "    \"\"\"\n",
    "    Fully preprocess one input image for digit recognition.\n",
    "    Output: clean binary image (uint8), white digits on black background.\n",
    "    \"\"\"\n",
    "    # Ensure uint8 (OpenCV expects 0-255 uint8)\n",
    "    if img_bgr.dtype != np.uint8:\n",
    "        img_bgr = (img_bgr * 255).astype(np.uint8)\n",
    "\n",
    "    # 1) Grayscale safely\n",
    "    if len(img_bgr.shape) == 3:\n",
    "        gray = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2GRAY)\n",
    "    else:\n",
    "        gray = img_bgr.copy()\n",
    "\n",
    "    # 2) Light blur\n",
    "    gray = cv2.GaussianBlur(gray, (3, 3), 0)\n",
    "\n",
    "    # 3) Adaptive threshold (invert so digits are white)\n",
    "    bw = cv2.adaptiveThreshold(\n",
    "        gray, 255,\n",
    "        cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\n",
    "        cv2.THRESH_BINARY_INV,\n",
    "        25, 10\n",
    "    )\n",
    "\n",
    "    # 4) Tight crop\n",
    "    ys, xs = np.where(bw > 0)\n",
    "    if xs.size > 0 and ys.size > 0:\n",
    "        x0, x1, y0, y1 = xs.min(), xs.max(), ys.min(), ys.max()\n",
    "        tight = bw[y0:y1+1, x0:x1+1]\n",
    "    else:\n",
    "        tight = bw\n",
    "\n",
    "    # 5) Center pad to square\n",
    "    h, w = tight.shape\n",
    "    side = max(h, w) + 1*pad\n",
    "    canvas = np.zeros((side, side), dtype=np.uint8)\n",
    "    yoff, xoff = (side - h)//2, (side - w)//2\n",
    "    canvas[yoff:yoff+h, xoff:xoff+w] = tight\n",
    "\n",
    "    # 6) Resize + quick cleanup\n",
    "    resized = cv2.resize(canvas, (out_size, out_size), interpolation=cv2.INTER_AREA)\n",
    "    blurred = cv2.GaussianBlur(resized, (3, 3), 0)\n",
    "    _, final_bw = cv2.threshold(blurred, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "\n",
    "    return final_bw\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2dc94152e8e0c93",
   "metadata": {},
   "source": [
    "## Mutiple Digit Image Generator\n",
    "\n",
    "In testing phase, chat was used to see if it was possible. The below code does not reference Ai generated Work in the structure content of the code.\n",
    "    The open ChatLog is below:\n",
    "        https://chatgpt.com/share/68ca64d6-2fdc-800b-a487-24449f2bafa7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ce76fddcb45df8d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-31T01:48:34.156662Z",
     "start_time": "2025-10-31T01:48:34.149617Z"
    }
   },
   "outputs": [],
   "source": [
    "import string\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "def multiple_numbers(x, y, num_images, max_digits=10):\n",
    "  ''''\n",
    "  Generate Multiple digits or Chars per image,\n",
    "  Remember x is refing to the nump array of single char imgs, and shape (N,H,W)\n",
    "  While y is just the nump array of correpsonding labels\n",
    "\n",
    "  This function aims to return a list of combined images and the corresponding labels for each image before returning to the Preprocessing GUI\n",
    "  And Saving them as images to the Multi Folder\n",
    "  Aswell as the testing Function show multiple to test output is correct\n",
    "\n",
    "  '''\n",
    "  print(f\"{Colour.BLUE}   Moved to multiple_numbers{Colour.END}\") #DELETE delete Remove Remove Temp\n",
    "  imgs = []\n",
    "  spacing=10\n",
    "  labels = []\n",
    "  for i in range(num_images):\n",
    "    digits_per_image = np.random.randint(1, max_digits + 1)\n",
    "    ints = np.random.randint(0, len(x), digits_per_image)\n",
    "    chosen_digits = [x[idx] for idx in ints]\n",
    "    chosen_labels = [y[idx] for idx in ints]\n",
    "    spaced_digits=[]#This is just a blank column between digits\n",
    "    for d in chosen_digits:\n",
    "        spaced_digits.append(d)\n",
    "        #ADD IN THE SPACING COLUMN!!!!!\n",
    "        spaced_digits.append(np.zeros((d.shape[0],spacing), dtype=np.uint8))\n",
    "    #width =digits_per_image*chosen_digits[0].shape[1]+(digits_per_image-1)*spacing\n",
    "    spaced_digits = spaced_digits[:-1]\n",
    "    img = np.hstack(spaced_digits)\n",
    "\n",
    "    imgs.append(img)\n",
    "    labels.append(tuple(chosen_labels))\n",
    "\n",
    "  return imgs, labels\n",
    "\n",
    "\n",
    "#imgs,labels=multiple_numbers(x_train, y_train, num_images, max_digits=10)\n",
    "\n",
    "def make_json_safe(labels):\n",
    "    \"\"\"Recursive convert any to JSON ceral Python types.\"\"\"\n",
    "    if isinstance(labels, np.ndarray):\n",
    "        return [make_json_safe(x) for x in labels.tolist()]\n",
    "    elif isinstance(labels, (np.uint8, np.int32, np.int64, np.int16, np.int8)):\n",
    "        return int(labels)\n",
    "    elif isinstance(labels, tuple):\n",
    "        return [make_json_safe(x) for x in labels]\n",
    "    elif isinstance(labels, list):\n",
    "        return [make_json_safe(x) for x in labels]\n",
    "    else:\n",
    "        return labels\n",
    "\n",
    "#NOT WORKING\n",
    "def show_multiple(option,imgs,labels,reform=False):\n",
    "#Visuals for testing purpose\n",
    "\n",
    "    image_num=min(len(imgs),5) #Limit to 5 img for display\n",
    "    plt.figure(figsize=(13, 2))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    plt.show()\n",
    "    for i in range(image_num):\n",
    "        plt.subplot(1,image_num,i+1)\n",
    "\n",
    "        plt.imshow(imgs[i].squeeze(),cmap=\"gray\")\n",
    "        if reform==True:\n",
    "            img_arr = np.array(imgs[i])\n",
    "            if img_arr.size != 256*256:\n",
    "                raise ValueError(f\"Image {i} cannot reshape to 256x256, size={img_arr.size}\")\n",
    "            plt.imshow(img_arr.reshape(256, 256), cmap=\"gray\")\n",
    "\n",
    "\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    plt.show()\n",
    "    '''\n",
    "\n",
    "Some issues\n",
    "such as the inability to read 1 correctly\n",
    "Added ayfnebtatuib so it could learn robustness\n",
    "in small avriaitons\n",
    "also helps to avoid overfitting\n",
    "for this reason augmentaiton would be added for some reinfrorcement\n",
    "\n",
    "\n",
    "    '''\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9765cc2b651c86b",
   "metadata": {},
   "source": [
    "## Load and Preprocess MNIST Data gui\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbf98f93d715f394",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-01T03:01:59.779475Z",
     "start_time": "2025-11-01T03:00:22.325328Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mCycle Start: We are in the Preprocessing_gui\u001b[0m\n",
      "Please select a dataset:\n",
      "   1. MNIST\n",
      "   2. EMNIST\n",
      "   3. Multiple Image Generator\n",
      "   q. Quit\n",
      "\u001b[33mSelection\u001b[0m:\u001b[36m\n",
      "You have Selected Emnist.\u001b[0m\n",
      "\u001b[36m   Moved to eminst_loader\u001b[0m\n",
      "\u001b[36m   Moved to test_train_split\u001b[0m\n",
      "\u001b[35mTrain:\n",
      "  X_train:(88800, 28, 28, 1),\n",
      "  Y_train:(88800,)\n",
      "\u001b[0m\n",
      "\u001b[35mTest:\n",
      "  X_test:(14800, 28, 28, 1),\n",
      "  Y_test:(14800,)\n",
      "\u001b[0m\n",
      "\u001b[32m       0_Single_preprocessed_Emnist.png\u001b[0m\n",
      "\u001b[32m       1_Single_preprocessed_Emnist.png\u001b[0m\n",
      "\u001b[32m       2_Single_preprocessed_Emnist.png\u001b[0m\n",
      "\u001b[32m       3_Single_preprocessed_Emnist.png\u001b[0m\n",
      "\u001b[32m       4_Single_preprocessed_Emnist.png\u001b[0m\n",
      "\u001b[32m       5_Single_preprocessed_Emnist.png\u001b[0m\n",
      "\u001b[32m       6_Single_preprocessed_Emnist.png\u001b[0m\n",
      "\u001b[32m       7_Single_preprocessed_Emnist.png\u001b[0m\n",
      "\u001b[32m       8_Single_preprocessed_Emnist.png\u001b[0m\n",
      "\u001b[32m       9_Single_preprocessed_Emnist.png\u001b[0m\n",
      "\u001b[32m       10_Single_preprocessed_Emnist.png\u001b[0m\n",
      "\u001b[32m       11_Single_preprocessed_Emnist.png\u001b[0m\n",
      "\u001b[32m       12_Single_preprocessed_Emnist.png\u001b[0m\n",
      "\u001b[32m       13_Single_preprocessed_Emnist.png\u001b[0m\n",
      "\u001b[32m       14_Single_preprocessed_Emnist.png\u001b[0m\n",
      "\u001b[32m       15_Single_preprocessed_Emnist.png\u001b[0m\n",
      "\u001b[32m       16_Single_preprocessed_Emnist.png\u001b[0m\n",
      "\u001b[32m       17_Single_preprocessed_Emnist.png\u001b[0m\n",
      "\u001b[32m       18_Single_preprocessed_Emnist.png\u001b[0m\n",
      "\u001b[32m       19_Single_preprocessed_Emnist.png\u001b[0m\n",
      "\u001b[32m       20_Single_preprocessed_Emnist.png\u001b[0m\n",
      "\u001b[32m       21_Single_preprocessed_Emnist.png\u001b[0m\n",
      "\u001b[32m       22_Single_preprocessed_Emnist.png\u001b[0m\n",
      "\u001b[32m       23_Single_preprocessed_Emnist.png\u001b[0m\n",
      "\u001b[32m       24_Single_preprocessed_Emnist.png\u001b[0m\n",
      "\u001b[32m       25_Single_preprocessed_Emnist.png\u001b[0m\n",
      "\u001b[32m       26_Single_preprocessed_Emnist.png\u001b[0m\n",
      "\u001b[32m       27_Single_preprocessed_Emnist.png\u001b[0m\n",
      "\u001b[32m       28_Single_preprocessed_Emnist.png\u001b[0m\n",
      "\u001b[32m       29_Single_preprocessed_Emnist.png\u001b[0m\n",
      "\u001b[32m       30_Single_preprocessed_Emnist.png\u001b[0m\n",
      "\u001b[32m       31_Single_preprocessed_Emnist.png\u001b[0m\n",
      "\u001b[32m       32_Single_preprocessed_Emnist.png\u001b[0m\n",
      "\u001b[32m       33_Single_preprocessed_Emnist.png\u001b[0m\n",
      "\u001b[32m       34_Single_preprocessed_Emnist.png\u001b[0m\n",
      "\u001b[32m       35_Single_preprocessed_Emnist.png\u001b[0m\n",
      "\u001b[32m       36_Single_preprocessed_Emnist.png\u001b[0m\n",
      "\u001b[32m       37_Single_preprocessed_Emnist.png\u001b[0m\n",
      "\u001b[32m       38_Single_preprocessed_Emnist.png\u001b[0m\n",
      "\u001b[32m       39_Single_preprocessed_Emnist.png\u001b[0m\n",
      "\u001b[32m       40_Single_preprocessed_Emnist.png\u001b[0m\n",
      "\u001b[32m       41_Single_preprocessed_Emnist.png\u001b[0m\n",
      "\u001b[32m       42_Single_preprocessed_Emnist.png\u001b[0m\n",
      "\u001b[32m       43_Single_preprocessed_Emnist.png\u001b[0m\n",
      "\u001b[32m       44_Single_preprocessed_Emnist.png\u001b[0m\n",
      "\u001b[32m       45_Single_preprocessed_Emnist.png\u001b[0m\n",
      "\u001b[32m       46_Single_preprocessed_Emnist.png\u001b[0m\n",
      "\u001b[32m       47_Single_preprocessed_Emnist.png\u001b[0m\n",
      "\u001b[32m       48_Single_preprocessed_Emnist.png\u001b[0m\n",
      "\u001b[32m       49_Single_preprocessed_Emnist.png\u001b[0m\n",
      "\u001b[32m       50_Single_preprocessed_Emnist.png\u001b[0m\n",
      "\u001b[32m       51_Single_preprocessed_Emnist.png\u001b[0m\n",
      "\u001b[32m       52_Single_preprocessed_Emnist.png\u001b[0m\n",
      "\u001b[32m       53_Single_preprocessed_Emnist.png\u001b[0m\n",
      "\u001b[32m       54_Single_preprocessed_Emnist.png\u001b[0m\n",
      "\u001b[32m       55_Single_preprocessed_Emnist.png\u001b[0m\n",
      "\u001b[32m       56_Single_preprocessed_Emnist.png\u001b[0m\n",
      "\u001b[32m       57_Single_preprocessed_Emnist.png\u001b[0m\n",
      "\u001b[32m       58_Single_preprocessed_Emnist.png\u001b[0m\n",
      "\u001b[32m       59_Single_preprocessed_Emnist.png\u001b[0m\n",
      "\u001b[32m       60_Single_preprocessed_Emnist.png\u001b[0m\n",
      "\u001b[32m       61_Single_preprocessed_Emnist.png\u001b[0m\n",
      "\u001b[32m       62_Single_preprocessed_Emnist.png\u001b[0m\n",
      "\u001b[32m       63_Single_preprocessed_Emnist.png\u001b[0m\n",
      "\u001b[32m       64_Single_preprocessed_Emnist.png\u001b[0m\n",
      "\u001b[32m       65_Single_preprocessed_Emnist.png\u001b[0m\n",
      "\u001b[32m       66_Single_preprocessed_Emnist.png\u001b[0m\n",
      "\u001b[32m       67_Single_preprocessed_Emnist.png\u001b[0m\n",
      "\u001b[32m       68_Single_preprocessed_Emnist.png\u001b[0m\n",
      "\u001b[32m       69_Single_preprocessed_Emnist.png\u001b[0m\n",
      "\u001b[32m       70_Single_preprocessed_Emnist.png\u001b[0m\n",
      "\u001b[32m       71_Single_preprocessed_Emnist.png\u001b[0m\n",
      "\u001b[32m       72_Single_preprocessed_Emnist.png\u001b[0m\n",
      "\u001b[32m       73_Single_preprocessed_Emnist.png\u001b[0m\n",
      "\u001b[32m       74_Single_preprocessed_Emnist.png\u001b[0m\n",
      "\u001b[32m       75_Single_preprocessed_Emnist.png\u001b[0m\n",
      "\u001b[32m       76_Single_preprocessed_Emnist.png\u001b[0m\n",
      "\u001b[32m       77_Single_preprocessed_Emnist.png\u001b[0m\n",
      "\u001b[32m       78_Single_preprocessed_Emnist.png\u001b[0m\n",
      "\u001b[32m       79_Single_preprocessed_Emnist.png\u001b[0m\n",
      "\u001b[32m       80_Single_preprocessed_Emnist.png\u001b[0m\n",
      "\u001b[32m       81_Single_preprocessed_Emnist.png\u001b[0m\n",
      "\u001b[32m       82_Single_preprocessed_Emnist.png\u001b[0m\n",
      "\u001b[32m       83_Single_preprocessed_Emnist.png\u001b[0m\n",
      "\u001b[32m       84_Single_preprocessed_Emnist.png\u001b[0m\n",
      "\u001b[32m       85_Single_preprocessed_Emnist.png\u001b[0m\n",
      "\u001b[32m       86_Single_preprocessed_Emnist.png\u001b[0m\n",
      "\u001b[32m       87_Single_preprocessed_Emnist.png\u001b[0m\n",
      "\u001b[32m       88_Single_preprocessed_Emnist.png\u001b[0m\n",
      "\u001b[32m       89_Single_preprocessed_Emnist.png\u001b[0m\n",
      "\u001b[32m       90_Single_preprocessed_Emnist.png\u001b[0m\n",
      "\u001b[32m       91_Single_preprocessed_Emnist.png\u001b[0m\n",
      "\u001b[32m       92_Single_preprocessed_Emnist.png\u001b[0m\n",
      "\u001b[32m       93_Single_preprocessed_Emnist.png\u001b[0m\n",
      "\u001b[32m       94_Single_preprocessed_Emnist.png\u001b[0m\n",
      "\u001b[32m       95_Single_preprocessed_Emnist.png\u001b[0m\n",
      "\u001b[32m       96_Single_preprocessed_Emnist.png\u001b[0m\n",
      "\u001b[32m       97_Single_preprocessed_Emnist.png\u001b[0m\n",
      "\u001b[32m       98_Single_preprocessed_Emnist.png\u001b[0m\n",
      "\u001b[32m       99_Single_preprocessed_Emnist.png\u001b[0m\n",
      "Preprocessed images are in: \u001b[32mC:\\Users\\joann\\PycharmProjects\\Recog\\Preprocessed\\Emnist\u001b[0m\n",
      "Please select a dataset:\n",
      "   1. MNIST\n",
      "   2. EMNIST\n",
      "   3. Multiple Image Generator\n",
      "   q. Quit\n",
      "\u001b[33mSelection\u001b[0m:"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "Interrupted by user",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 350\u001b[39m\n\u001b[32m    340\u001b[39m             \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mPreprocessed images are in: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mColour.GREEN\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mOUT_DIR_2\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mColour.END\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m    341\u001b[39m         \u001b[38;5;66;03m# Dataset split\u001b[39;00m\n\u001b[32m    342\u001b[39m                 \u001b[38;5;66;03m# https://stackoverflow.com/questions/47321709/how-to-split-train-and-test-dataset-to-x-train-y-train-and-x-test-y-test\u001b[39;00m\n\u001b[32m    343\u001b[39m \n\u001b[32m    344\u001b[39m \n\u001b[32m    345\u001b[39m \n\u001b[32m    346\u001b[39m     \u001b[38;5;66;03m#LATER ADD THIS IN PROPERLY FOR IMAEG UPALODIGN\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m350\u001b[39m \u001b[43mpreprocessing_gui\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    353\u001b[39m \u001b[33;03m'''\u001b[39;00m\n\u001b[32m    354\u001b[39m \n\u001b[32m    355\u001b[39m \u001b[33;03mMAJOR NOTE FOR ERPORT\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    362\u001b[39m \u001b[33;03madded x test in multiple\u001b[39;00m\n\u001b[32m    363\u001b[39m \u001b[33;03m'''\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m'\u001b[39m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 179\u001b[39m, in \u001b[36mpreprocessing_gui\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    177\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mPlease select a dataset:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m   1. MNIST\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m   2. EMNIST\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m   3. Multiple Image Generator\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m   q. Quit\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    178\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mColour.YELLOW\u001b[38;5;132;01m}\u001b[39;00m\u001b[33mSelection\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mColour.END\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m:\u001b[39m\u001b[33m\"\u001b[39m, end=\u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m179\u001b[39m choice = \u001b[43mreuseable_end_sequence\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    181\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m choice \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m choice.strip():\n\u001b[32m    182\u001b[39m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 16\u001b[39m, in \u001b[36mreuseable_end_sequence\u001b[39m\u001b[34m(prompter)\u001b[39m\n\u001b[32m     15\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mreuseable_end_sequence\u001b[39m(prompter):\n\u001b[32m---> \u001b[39m\u001b[32m16\u001b[39m   choice=\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mprompter\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     17\u001b[39m   \u001b[38;5;28;01mif\u001b[39;00m choice.lower()==\u001b[33m'\u001b[39m\u001b[33mq\u001b[39m\u001b[33m'\u001b[39m:\u001b[38;5;66;03m# Q QUIT\u001b[39;00m\n\u001b[32m     18\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mColour.RED\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m  Exiting Program\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mColour.END\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\PycharmProjects\\Recog\\.venv1\\Lib\\site-packages\\ipykernel\\kernelbase.py:1396\u001b[39m, in \u001b[36mKernel.raw_input\u001b[39m\u001b[34m(self, prompt)\u001b[39m\n\u001b[32m   1394\u001b[39m     msg = \u001b[33m\"\u001b[39m\u001b[33mraw_input was called, but this frontend does not support input requests.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1395\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m StdinNotImplementedError(msg)\n\u001b[32m-> \u001b[39m\u001b[32m1396\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_input_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1397\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1398\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_shell_context_var\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_shell_parent_ident\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1399\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mget_parent\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mshell\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1400\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpassword\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m   1401\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\PycharmProjects\\Recog\\.venv1\\Lib\\site-packages\\ipykernel\\kernelbase.py:1441\u001b[39m, in \u001b[36mKernel._input_request\u001b[39m\u001b[34m(self, prompt, ident, parent, password)\u001b[39m\n\u001b[32m   1438\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m:\n\u001b[32m   1439\u001b[39m     \u001b[38;5;66;03m# re-raise KeyboardInterrupt, to truncate traceback\u001b[39;00m\n\u001b[32m   1440\u001b[39m     msg = \u001b[33m\"\u001b[39m\u001b[33mInterrupted by user\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1441\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m(msg) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1442\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[32m   1443\u001b[39m     \u001b[38;5;28mself\u001b[39m.log.warning(\u001b[33m\"\u001b[39m\u001b[33mInvalid Message:\u001b[39m\u001b[33m\"\u001b[39m, exc_info=\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: Interrupted by user"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Changed Requirements\n",
    "No longer needs\n",
    "\n",
    "\n",
    "from emnist import extract_training_samples, extract_test_samples\n",
    "\n",
    "\n",
    "USIES tensorflwo fatabase instead fo rmnsit and emnsit\n",
    "\n",
    "install line\n",
    "\n",
    "changed logic form using apthlib\n",
    "to ajsut use os\n",
    "\n",
    "''''## grabs the parent directory of  file.'''\n",
    "\n",
    "import sys\n",
    "OUT_DIR = os.path.join(BASE_DIR, \"Preprocessed\")\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import cv2\n",
    "import json\n",
    "\n",
    "#!pip install tensorflow opencv-python tensorflow-datasets\n",
    "#!pip install opencv-python\n",
    "import tensorflow as tf\n",
    "\n",
    "import tensorflow_datasets as tfds\n",
    "builder = tfds.builder('mnist')\n",
    "\n",
    "# Force download using DownloadConfig as alt\n",
    "download_config = tfds.download.DownloadConfig()\n",
    "builder.download_and_prepare(download_config=download_config)\n",
    "\n",
    "BASE_DIR = Path.cwd()\n",
    "# Define  subfolders\n",
    "\n",
    "\n",
    "\n",
    "def emnist_loader():\n",
    "    print(f\"{Colour.CYAN}   Moved to eminst_loader{Colour.END}\") #DELETE delete Remove Remove Temp\n",
    "    (df_train, df_test) = tfds.load(\n",
    "    'emnist/letters',\n",
    "    split=['train', 'test'],\n",
    "    as_supervised=True\n",
    ")\n",
    "\n",
    "    dataset=\"emnist\"\n",
    "    x_train, y_train, x_test, y_test= test_train_split(dataset,df_train,df_test)\n",
    "\n",
    "    return x_train, y_train, x_test, y_test\n",
    "\n",
    "\n",
    "\n",
    "def test_train_split(dataset,df_train,df_test):\n",
    "    print(f\"{Colour.CYAN}   Moved to test_train_split{Colour.END}\") #DELETE delete Remove Remove Temp\n",
    "\n",
    "    x_train, y_train = [], []\n",
    "    x_test, y_test = [], []\n",
    "    if dataset == 'mnist':\n",
    "        for img, label in tfds.as_numpy(df_train):\n",
    "            x_train.append(img)\n",
    "            y_train.append(label)\n",
    "        x_train = np.array(x_train, dtype='float32') / 255.0\n",
    "        y_train = np.array(y_train,dtype='int64')\n",
    "         # append img and labels to test instances\n",
    "\n",
    "\n",
    "        for img, label in tfds.as_numpy(df_test):\n",
    "                x_test.append(img)\n",
    "                y_test.append(label)\n",
    "        x_test = np.array(x_test, dtype='float32') / 255.0\n",
    "        y_test = np.array(y_test,dtype='int64')\n",
    "\n",
    "\n",
    "\n",
    "    #x_train, y_train = np.array(x_train), np.array(y_train)\n",
    "    if dataset == 'emnist':\n",
    "        x_train = [img.squeeze().T for img in x_train]\n",
    "        for img, label in tfds.as_numpy(df_train):\n",
    "            img = tf.image.rot90(img, k=1)      # EMNIST fix\n",
    "            img = tf.image.flip_left_right(img) # EMNIST fix\n",
    "            x_train.append(img)\n",
    "            y_train.append(label - 1)\n",
    "        for img, label in tfds.as_numpy(df_test):\n",
    "             img = tf.image.rot90(img, k=1)\n",
    "             img = tf.image.flip_left_right(img)\n",
    "             x_test.append(img)\n",
    "             y_test.append(label - 1)\n",
    "        x_train = np.array(x_train).reshape(-1, 28, 28, 1).astype(\"float32\") / 255.0\n",
    "        x_test  = np.array(x_test).reshape(-1, 28, 28, 1).astype(\"float32\") / 255.0\n",
    "        y_train = np.array(y_train)\n",
    "        y_test  = np.array(y_test)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    print(f\"{Colour.MAGENTA}Train:\\n  X_train:{x_train.shape},\\n  Y_train:{y_train.shape}\\n{Colour.END}\")\n",
    "    print(f\"{Colour.MAGENTA}Test:\\n  X_test:{x_test.shape},\\n  Y_test:{y_test.shape}\\n{Colour.END}\")\n",
    "\n",
    "    return x_train, y_train, x_test, y_test\n",
    "\n",
    "\n",
    "\n",
    "'''\n",
    "Updated so both use the same tfds databse to minise need for libaries'''\n",
    "def mnist_loader():\n",
    "    print(f\"{Colour.CYAN}   Moved to minst_loader{Colour.END}\") #DELETE delete Remove Remove Temp\n",
    "    (df_train, df_test) = tfds.load(\n",
    "    'mnist',\n",
    "    split=['train', 'test'],\n",
    "    as_supervised=True\n",
    ")\n",
    "    print(\"Dataset Loaded\")\n",
    "\n",
    "\n",
    "    dataset=\"mnist\"\n",
    "    x_train, y_train, x_test, y_test= test_train_split(dataset,df_train,df_test)\n",
    "    return x_train, y_train, x_test, y_test\n",
    "\n",
    "#Completely changed\n",
    "\n",
    "'''\n",
    "No longer uses shifted and chars\n",
    "this was done for the seperateion fo the two classes\n",
    "'''\n",
    "def process_label(label_list, dataset):\n",
    "    \"\"\"\n",
    "    Convert label to int for JSON and also provide readable characters.\n",
    "\n",
    "    Returns a tuple: (shifted ints, chars)\n",
    "    - MNIST: 0-9\n",
    "    - EMNIST: shift +10 and map 1->A, 2->B, ..., 26->Z\n",
    "    \"\"\"\n",
    "    import numpy as np\n",
    "\n",
    "    # Ensure input is a list\n",
    "    if isinstance(label_list, (int, np.integer)):\n",
    "        label_list = [label_list]\n",
    "\n",
    "    ints = []\n",
    "    chars = []\n",
    "\n",
    "    # Mapping for EMNIST letters (1->A, 26->Z)\n",
    "    EMNIST_LETTER_MAP = {i: chr(64+i) for i in range(1, 27)}# 1->A, 26->Z\n",
    "\n",
    "    for d in label_list:\n",
    "        d = int(d)\n",
    "        ints.append(d)\n",
    "        if dataset.lower() in [\"emnist\"]:\n",
    "            # Shift for JSON: 1->10, 2->11, ..., 26->35\n",
    "            chars.append(EMNIST_LETTER_MAP.get(d, f\"Unknown({d})\"))\n",
    "        else:  # MNIST\n",
    "            chars.append(str(d))\n",
    "\n",
    "    return ints, chars\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def preprocessing_gui():\n",
    "\n",
    "    imgs, labels = [], []\n",
    "    option = None\n",
    "    print(f\"{Colour.BLUE}Cycle Start: We are in the Preprocessing_gui{Colour.END}\")\n",
    "    # initialize all training/testing arrays\n",
    "    x_train, y_train, x_test, y_test = [], [], [], []\n",
    "\n",
    "    while True:\n",
    "        isEnd = False\n",
    "\n",
    "        while not isEnd:\n",
    "            print(\"Please select a dataset:\\n   1. MNIST\\n   2. EMNIST\\n   3. Multiple Image Generator\\n   q. Quit\")\n",
    "            print(f\"{Colour.YELLOW}Selection{Colour.END}:\", end=\"\")\n",
    "            choice = reuseable_end_sequence(\"\")\n",
    "\n",
    "            if not choice or not choice.strip():\n",
    "                continue\n",
    "\n",
    "            dataset_testing = int(choice)\n",
    "\n",
    "            # Ask how many images the user wants\n",
    "            choice2 = reuseable_end_sequence(\"\\nPlease enter Number of images Wanted: \")\n",
    "            choice2 = int(choice2) if choice2 and choice2.strip() else 5\n",
    "            dataset=\"N/A\"\n",
    "            # ---------- SINGLE DATASET CASE ----------\n",
    "            if dataset_testing in [1, 2]:\n",
    "                multiple = \"_Single_\"\n",
    "\n",
    "                if dataset_testing == 1:\n",
    "                    dataset = \"Mnist\"\n",
    "                    option = 0\n",
    "                    print(f\"{Colour.CYAN}\\nYou have Selected {dataset}.{Colour.END}\")\n",
    "                    x_train, y_train, x_test, y_test = mnist_loader()\n",
    "\n",
    "                elif dataset_testing == 2:\n",
    "                    dataset = \"Emnist\"\n",
    "                    option = 1\n",
    "\n",
    "                    print(f\"{Colour.CYAN}\\nYou have Selected {dataset}.{Colour.END}\")\n",
    "\n",
    "                    x_train, y_train, x_test, y_test = emnist_loader()\n",
    "                 # ---------- BOTH DATASET CASE ----------\n",
    "                OUT_DIR_2 = os.path.join(OUT_DIR,  dataset)\n",
    "                #If no exist make it\n",
    "                if not os.path.exists(OUT_DIR_2):\n",
    "                    os.makedirs(OUT_DIR_2)\n",
    "\n",
    "                all_data = []\n",
    "                # Preprocess and save images\n",
    "                for i in range(min(choice2, len(x_train))):\n",
    "                    img = x_train[i]\n",
    "                    if len(img.shape) == 3 and img.shape[2] == 1:\n",
    "                        img = img.squeeze(axis=2)  # convert 28x28x1 -> 28x28\n",
    "                    if len(img.shape) == 2:\n",
    "                        img_bgr = cv2.cvtColor(img, cv2.COLOR_GRAY2BGR)\n",
    "                    elif len(img.shape) == 3 and img.shape[2] == 3:\n",
    "                        img_bgr = img.copy()\n",
    "                    else:\n",
    "                        print(f\"{Colour.RED}  Unexpected image shape: {img.shape}{Colour.END}\")\n",
    "                        continue\n",
    "                    current_labels, char_display = process_label(y_train[i], dataset)\n",
    "                    pre_img = preprocess_single(img_bgr, out_size=128)\n",
    "                    out_png = os.path.join(OUT_DIR_2, f\"{i}{multiple}preprocessed_{dataset}.png\")\n",
    "                    cv2.imwrite(str(out_png), pre_img)\n",
    "                    img_name = f\"{i}{multiple}preprocessed_{dataset}\"\n",
    "                    all_data.append({\"Title\": img_name, \"Chars\": current_labels,\"Display\":char_display})\n",
    "                    print(f\"{Colour.GREEN}       {i}{multiple}preprocessed_{dataset}.png{Colour.END}\")\n",
    "\n",
    "\n",
    "                # Save JSON\n",
    "                json_path =os.path.join(OUT_DIR_2, f\"Single_{dataset}_labels.json\")\n",
    "\n",
    "                with open(json_path, \"w\") as f:\n",
    "                    json.dump(all_data, f, indent=4)\n",
    "            # ---------- MULTIPLE IMAGE GENERATOR ----------\n",
    "\n",
    "            #used for testing more than training\n",
    "\n",
    "            elif dataset_testing == 3:\n",
    "                multiple = \"_Multi_\"\n",
    "                print(\"\\nPlease Select Dataset: Mnist(1), Emnist(2)\")\n",
    "                print(f\"{Colour.YELLOW}Selection{Colour.END}:\", end=\"\")\n",
    "                choice = reuseable_end_sequence(\"\")\n",
    "                if not choice or not choice.strip():\n",
    "                    continue\n",
    "                dataset_choice = int(choice)\n",
    "\n",
    "                match dataset_choice:\n",
    "                    #Updated to use new FUNCTIONS MNIST LAODER AND TEST TRAIN SPLIT\n",
    "                    case 1:\n",
    "                        dataset = \"Mnist\"\n",
    "                        option = 0\n",
    "                        x_train, y_train, x_test, _ = mnist_loader()\n",
    "                    case 2:\n",
    "                        dataset = \"Emnist\"\n",
    "                        option = 1\n",
    "                        x_train, y_train, x_test, _ = emnist_loader()\n",
    "\n",
    "                    case _:\n",
    "                        raise ValueError(\"Invalid Selection.\")\n",
    "\n",
    "\n",
    "                    # Ensure training data exists\n",
    "                if len(x_train) == 0 or len(y_train) == 0:\n",
    "                    print(\"No training images loaded for Multiple Image Generator.\")\n",
    "                    continue\n",
    "\n",
    "                # Convert any (28,28,1) arrays to (28,28) for multiple_numbers\n",
    "                for i in range(min(choice2, len(x_train))):\n",
    "\n",
    "                    img = x_train[i]\n",
    "\n",
    "                    if x_train.ndim == 4 and x_train.shape[-1] == 1:\n",
    "                        x_train = x_train.squeeze(-1)  # remove last channel dimension\n",
    "                        #added x test mech\n",
    "                    elif x_test.ndim == 4 and x_test.shape[-1] == 1:\n",
    "                        x_test = x_test.squeeze(-1)\n",
    "                    elif img.ndim != 2:\n",
    "                        print(f\"{Colour.RED}  Unexpected image shape: {img.shape}{Colour.END}\")\n",
    "                        continue\n",
    "\n",
    "                # Generate multi-digit/letter images\n",
    "                imgs, labels = multiple_numbers(x_train, y_train, choice2, max_digits=10)\n",
    "                show_multiple(option, imgs, labels, reform=False)\n",
    "\n",
    "            all_data = []\n",
    "            OUT_DIR_2 = os.path.join(OUT_DIR,  dataset)\n",
    "            #If no exist make it\n",
    "            if not os.path.exists(OUT_DIR_2):\n",
    "                    os.makedirs(OUT_DIR_2)\n",
    "\n",
    "\n",
    "            for i, (img, label_list) in enumerate(zip(imgs, labels)):\n",
    "                if img.ndim == 3 and img.shape[2] == 1:\n",
    "                    img = img.squeeze(axis=2)\n",
    "                img_bgr = cv2.cvtColor(img, cv2.COLOR_GRAY2BGR) if img.ndim == 2 else img.copy()\n",
    "\n",
    "                pre_img = preprocess_single(img_bgr , out_size=256)\n",
    "                out_png = os.path.join(OUT_DIR_2, f\"{i}{multiple}preprocessed_{dataset}.png\")\n",
    "                cv2.imwrite(str(out_png), pre_img)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "             # Build JSON for labels\n",
    "\n",
    "            #for i, label_list in enumerate(labels):\n",
    "\n",
    "                        # map EMNIST letters to characters\n",
    "                       # current_labels = [\n",
    "                            #chr(d + 96) if 1 <= d <= 26 else str(d-1 if d<=10 else d-36)\n",
    "                          #  label_list[i]\n",
    "                       # ]\n",
    "                current_labels, char_display = process_label(label_list, dataset)\n",
    "                current_labels = [int(d) for d in current_labels]\n",
    "\n",
    "\n",
    "                img_name = f\"{i}{multiple}preprocessed_{dataset}\"\n",
    "                all_data.append({\"Title\": img_name, \"Chars\": current_labels,\n",
    "                                 \"Display\":char_display})\n",
    "\n",
    "            json_path = os.path.join(OUT_DIR_2, f\"Multi_{dataset}_labels.json\")\n",
    "            with open(json_path, \"w\") as f:\n",
    "                json.dump(all_data, f, indent=4)\n",
    "\n",
    "                # Show generated images\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "           # print(f\"{Colour.MAGENTA}Training Images: {len(x_train)}, Training Labels: {len(y_train)}{Colour.END}\")\n",
    "            print(f\"Preprocessed images are in: {Colour.GREEN}{OUT_DIR_2}{Colour.END}\")\n",
    "        # Dataset split\n",
    "                # https://stackoverflow.com/questions/47321709/how-to-split-train-and-test-dataset-to-x-train-y-train-and-x-test-y-test\n",
    "\n",
    "\n",
    "\n",
    "    #LATER ADD THIS IN PROPERLY FOR IMAEG UPALODIGN\n",
    "\n",
    "\n",
    "\n",
    "preprocessing_gui()\n",
    "\n",
    "\n",
    "'''\n",
    "\n",
    "MAJOR NOTE FOR ERPORT\n",
    "During hte making of the multi digit issue\n",
    "\n",
    "I had a issue where once i was able to fdix the leters one\n",
    "multi dig wetent working\n",
    "this was because i had put hte for in range loop after all the code and it was being overwritten by the preimg that connects to precess single\n",
    "ValueError: could not broadcast input array from shape (28,28) into shape (28,28,1)\n",
    "added x test in multiple\n",
    "'''''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c77cf6865b860ae4",
   "metadata": {},
   "source": [
    "## Segmentation and Preprocessing Functions\n",
    "When Testing data we dont know what dataset will other gonna provide so we need Preprocess to clean the image and segmentation to seperate each digit to one image (when image that other provide have many digit in one image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33a8b787922c4519",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-31T01:57:29.179910Z",
     "start_time": "2025-10-31T01:57:29.175496Z"
    }
   },
   "outputs": [],
   "source": [
    "def segment_contours(bw, dilate_kernel=(2, 2), min_area=60, padding=5):\n",
    "    contours, _ = cv2.findContours(bw, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    boxes = []\n",
    "    h_img, w_img = bw.shape[:2]\n",
    "\n",
    "    for c in contours:\n",
    "        x, y, w, h = cv2.boundingRect(c)\n",
    "        if w*h >= min_area:\n",
    "            x_new = max(0, x - padding)\n",
    "            y_new = max(0, y - padding)\n",
    "            w_new = min(w + 2*padding, w_img - x_new)\n",
    "            h_new = min(h + 2*padding, h_img - y_new)\n",
    "            boxes.append((x_new, y_new, w_new, h_new))\n",
    "\n",
    "    boxes = sorted(boxes, key=lambda b: b[0])\n",
    "    return boxes\n",
    "\n",
    "def segment_and_extract_digits(img_gray, boxes, out_size=28):\n",
    "    \"\"\"\n",
    "    Segment multiple digits from a raw image and return 28x28 normalized crops.\n",
    "    Returns: digits, annotated image, bounding boxes\n",
    "    \"\"\"\n",
    "    digits = []\n",
    "    bw_for_seg = cv2.cvtColor(img_gray, cv2.COLOR_GRAY2BGR)\n",
    "\n",
    "    for (x, y, w, h) in boxes:\n",
    "        roi = img_gray[y:y+h, x:x+w]\n",
    "        if roi.size == 0:\n",
    "            continue\n",
    "        roi_resized = cv2.resize(roi, (out_size, out_size))\n",
    "        digits.append(roi_resized)\n",
    "        cv2.rectangle(bw_for_seg, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
    "\n",
    "    # Ensure 'labels' is always the bounding boxes passed in\n",
    "    labels = boxes  # <-- return the boxes instead of cv2.connectedComponents\n",
    "\n",
    "    return digits, bw_for_seg, labels,x, y, w, h\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "403c2737cbbb742a",
   "metadata": {},
   "source": [
    "### Segmentation  Gui"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94acb740f29d02b5",
   "metadata": {},
   "source": [
    "### In this section, we load the MNIST dataset, which contains grayscale images of handwritten digits (0–9).\n",
    "Each image is 28×28 pixels. We normalize the pixel values (divide by 255) to bring them into the [0,1] range, which helps models converge faster.\n",
    "We also flatten the data for non-convolutional models (like Dense Neural Network or KNN) while keeping the original shape (28×28×1) for CNN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9f9d116f054f10a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-31T03:29:07.072961Z",
     "start_time": "2025-10-31T03:29:05.591291Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please Select A Option:\n",
      "     1.Segment Only the MNIST Folder\n",
      "     2. Segment the EMNIST Folder\n",
      "     3.Segment Both Folders\n",
      "     q.Quit\n",
      "\u001b[33mSelection\u001b[0m:    \u001b[36mYou have chosen to Segment only the Emnist Folder\u001b[0m\n",
      "Copied JSON: Multi_Emnist_labels.json -> C:\\Users\\joann\\PycharmProjects\\Recog\\Segmentation\\Emnist\n",
      "Copied JSON: Single_Emnist_labels.json -> C:\\Users\\joann\\PycharmProjects\\Recog\\Segmentation\\Emnist\n",
      "      \u001b[32m[OK] 0_Multi_preprocessed_Emnist: \u001b[31m2 digits detected\u001b[0m\n",
      "      \u001b[32m[OK] 0_Single_preprocessed_Emnist: \u001b[31m1 digits detected\u001b[0m\n",
      "      \u001b[32m[OK] 10_Single_preprocessed_Emnist: \u001b[31m1 digits detected\u001b[0m\n",
      "      \u001b[32m[OK] 11_Single_preprocessed_Emnist: \u001b[31m1 digits detected\u001b[0m\n",
      "      \u001b[32m[OK] 12_Single_preprocessed_Emnist: \u001b[31m1 digits detected\u001b[0m\n",
      "      \u001b[32m[OK] 13_Single_preprocessed_Emnist: \u001b[31m1 digits detected\u001b[0m\n",
      "      \u001b[32m[OK] 14_Single_preprocessed_Emnist: \u001b[31m1 digits detected\u001b[0m\n",
      "      \u001b[32m[OK] 15_Single_preprocessed_Emnist: \u001b[31m1 digits detected\u001b[0m\n",
      "      \u001b[32m[OK] 16_Single_preprocessed_Emnist: \u001b[31m1 digits detected\u001b[0m\n",
      "      \u001b[32m[OK] 17_Single_preprocessed_Emnist: \u001b[31m1 digits detected\u001b[0m\n",
      "      \u001b[32m[OK] 18_Single_preprocessed_Emnist: \u001b[31m1 digits detected\u001b[0m\n",
      "      \u001b[32m[OK] 19_Single_preprocessed_Emnist: \u001b[31m1 digits detected\u001b[0m\n",
      "      \u001b[32m[OK] 1_Multi_preprocessed_Emnist: \u001b[31m7 digits detected\u001b[0m\n",
      "      \u001b[32m[OK] 1_Single_preprocessed_Emnist: \u001b[31m1 digits detected\u001b[0m\n",
      "      \u001b[32m[OK] 20_Single_preprocessed_Emnist: \u001b[31m1 digits detected\u001b[0m\n",
      "      \u001b[32m[OK] 21_Single_preprocessed_Emnist: \u001b[31m1 digits detected\u001b[0m\n",
      "      \u001b[32m[OK] 22_Single_preprocessed_Emnist: \u001b[31m1 digits detected\u001b[0m\n",
      "      \u001b[32m[OK] 23_Single_preprocessed_Emnist: \u001b[31m2 digits detected\u001b[0m\n",
      "      \u001b[32m[OK] 24_Single_preprocessed_Emnist: \u001b[31m1 digits detected\u001b[0m\n",
      "      \u001b[32m[OK] 25_Single_preprocessed_Emnist: \u001b[31m1 digits detected\u001b[0m\n",
      "      \u001b[32m[OK] 26_Single_preprocessed_Emnist: \u001b[31m1 digits detected\u001b[0m\n",
      "      \u001b[32m[OK] 27_Single_preprocessed_Emnist: \u001b[31m1 digits detected\u001b[0m\n",
      "      \u001b[32m[OK] 28_Single_preprocessed_Emnist: \u001b[31m1 digits detected\u001b[0m\n",
      "      \u001b[32m[OK] 29_Single_preprocessed_Emnist: \u001b[31m1 digits detected\u001b[0m\n",
      "      \u001b[32m[OK] 2_Multi_preprocessed_Emnist: \u001b[31m1 digits detected\u001b[0m\n",
      "      \u001b[32m[OK] 2_Single_preprocessed_Emnist: \u001b[31m1 digits detected\u001b[0m\n",
      "      \u001b[32m[OK] 30_Single_preprocessed_Emnist: \u001b[31m2 digits detected\u001b[0m\n",
      "      \u001b[32m[OK] 31_Single_preprocessed_Emnist: \u001b[31m1 digits detected\u001b[0m\n",
      "      \u001b[32m[OK] 32_Single_preprocessed_Emnist: \u001b[31m1 digits detected\u001b[0m\n",
      "      \u001b[32m[OK] 33_Single_preprocessed_Emnist: \u001b[31m1 digits detected\u001b[0m\n",
      "      \u001b[32m[OK] 34_Single_preprocessed_Emnist: \u001b[31m1 digits detected\u001b[0m\n",
      "      \u001b[32m[OK] 35_Single_preprocessed_Emnist: \u001b[31m1 digits detected\u001b[0m\n",
      "      \u001b[32m[OK] 36_Single_preprocessed_Emnist: \u001b[31m1 digits detected\u001b[0m\n",
      "      \u001b[32m[OK] 37_Single_preprocessed_Emnist: \u001b[31m1 digits detected\u001b[0m\n",
      "      \u001b[32m[OK] 38_Single_preprocessed_Emnist: \u001b[31m1 digits detected\u001b[0m\n",
      "      \u001b[32m[OK] 39_Single_preprocessed_Emnist: \u001b[31m1 digits detected\u001b[0m\n",
      "      \u001b[32m[OK] 3_Multi_preprocessed_Emnist: \u001b[31m7 digits detected\u001b[0m\n",
      "      \u001b[32m[OK] 3_Single_preprocessed_Emnist: \u001b[31m1 digits detected\u001b[0m\n",
      "      \u001b[32m[OK] 40_Single_preprocessed_Emnist: \u001b[31m1 digits detected\u001b[0m\n",
      "      \u001b[32m[OK] 41_Single_preprocessed_Emnist: \u001b[31m1 digits detected\u001b[0m\n",
      "      \u001b[32m[OK] 42_Single_preprocessed_Emnist: \u001b[31m1 digits detected\u001b[0m\n",
      "      \u001b[32m[OK] 43_Single_preprocessed_Emnist: \u001b[31m1 digits detected\u001b[0m\n",
      "      \u001b[32m[OK] 44_Single_preprocessed_Emnist: \u001b[31m1 digits detected\u001b[0m\n",
      "      \u001b[32m[OK] 45_Single_preprocessed_Emnist: \u001b[31m1 digits detected\u001b[0m\n",
      "      \u001b[32m[OK] 46_Single_preprocessed_Emnist: \u001b[31m1 digits detected\u001b[0m\n",
      "      \u001b[32m[OK] 47_Single_preprocessed_Emnist: \u001b[31m1 digits detected\u001b[0m\n",
      "      \u001b[32m[OK] 48_Single_preprocessed_Emnist: \u001b[31m1 digits detected\u001b[0m\n",
      "      \u001b[32m[OK] 49_Single_preprocessed_Emnist: \u001b[31m1 digits detected\u001b[0m\n",
      "      \u001b[32m[OK] 4_Multi_preprocessed_Emnist: \u001b[31m1 digits detected\u001b[0m\n",
      "      \u001b[32m[OK] 4_Single_preprocessed_Emnist: \u001b[31m1 digits detected\u001b[0m\n",
      "      \u001b[32m[OK] 50_Single_preprocessed_Emnist: \u001b[31m1 digits detected\u001b[0m\n",
      "      \u001b[32m[OK] 51_Single_preprocessed_Emnist: \u001b[31m1 digits detected\u001b[0m\n",
      "      \u001b[32m[OK] 52_Single_preprocessed_Emnist: \u001b[31m1 digits detected\u001b[0m\n",
      "      \u001b[32m[OK] 53_Single_preprocessed_Emnist: \u001b[31m1 digits detected\u001b[0m\n",
      "      \u001b[32m[OK] 54_Single_preprocessed_Emnist: \u001b[31m1 digits detected\u001b[0m\n",
      "      \u001b[32m[OK] 55_Single_preprocessed_Emnist: \u001b[31m1 digits detected\u001b[0m\n",
      "      \u001b[32m[OK] 56_Single_preprocessed_Emnist: \u001b[31m1 digits detected\u001b[0m\n",
      "      \u001b[32m[OK] 57_Single_preprocessed_Emnist: \u001b[31m1 digits detected\u001b[0m\n",
      "      \u001b[32m[OK] 58_Single_preprocessed_Emnist: \u001b[31m1 digits detected\u001b[0m\n",
      "      \u001b[32m[OK] 59_Single_preprocessed_Emnist: \u001b[31m1 digits detected\u001b[0m\n",
      "      \u001b[32m[OK] 5_Multi_preprocessed_Emnist: \u001b[31m7 digits detected\u001b[0m\n",
      "      \u001b[32m[OK] 5_Single_preprocessed_Emnist: \u001b[31m1 digits detected\u001b[0m\n",
      "      \u001b[32m[OK] 60_Single_preprocessed_Emnist: \u001b[31m1 digits detected\u001b[0m\n",
      "      \u001b[32m[OK] 61_Single_preprocessed_Emnist: \u001b[31m1 digits detected\u001b[0m\n",
      "      \u001b[32m[OK] 62_Single_preprocessed_Emnist: \u001b[31m1 digits detected\u001b[0m\n",
      "      \u001b[32m[OK] 63_Single_preprocessed_Emnist: \u001b[31m1 digits detected\u001b[0m\n",
      "      \u001b[32m[OK] 64_Single_preprocessed_Emnist: \u001b[31m1 digits detected\u001b[0m\n",
      "      \u001b[32m[OK] 65_Single_preprocessed_Emnist: \u001b[31m1 digits detected\u001b[0m\n",
      "      \u001b[32m[OK] 66_Single_preprocessed_Emnist: \u001b[31m1 digits detected\u001b[0m\n",
      "      \u001b[32m[OK] 67_Single_preprocessed_Emnist: \u001b[31m1 digits detected\u001b[0m\n",
      "      \u001b[32m[OK] 68_Single_preprocessed_Emnist: \u001b[31m1 digits detected\u001b[0m\n",
      "      \u001b[32m[OK] 69_Single_preprocessed_Emnist: \u001b[31m1 digits detected\u001b[0m\n",
      "      \u001b[32m[OK] 6_Multi_preprocessed_Emnist: \u001b[31m7 digits detected\u001b[0m\n",
      "      \u001b[32m[OK] 6_Single_preprocessed_Emnist: \u001b[31m1 digits detected\u001b[0m\n",
      "      \u001b[32m[OK] 70_Single_preprocessed_Emnist: \u001b[31m1 digits detected\u001b[0m\n",
      "      \u001b[32m[OK] 71_Single_preprocessed_Emnist: \u001b[31m1 digits detected\u001b[0m\n",
      "      \u001b[32m[OK] 72_Single_preprocessed_Emnist: \u001b[31m1 digits detected\u001b[0m\n",
      "      \u001b[32m[OK] 73_Single_preprocessed_Emnist: \u001b[31m1 digits detected\u001b[0m\n",
      "      \u001b[32m[OK] 74_Single_preprocessed_Emnist: \u001b[31m1 digits detected\u001b[0m\n",
      "      \u001b[32m[OK] 75_Single_preprocessed_Emnist: \u001b[31m1 digits detected\u001b[0m\n",
      "      \u001b[32m[OK] 76_Single_preprocessed_Emnist: \u001b[31m1 digits detected\u001b[0m\n",
      "      \u001b[32m[OK] 77_Single_preprocessed_Emnist: \u001b[31m1 digits detected\u001b[0m\n",
      "      \u001b[32m[OK] 78_Single_preprocessed_Emnist: \u001b[31m1 digits detected\u001b[0m\n",
      "      \u001b[32m[OK] 79_Single_preprocessed_Emnist: \u001b[31m1 digits detected\u001b[0m\n",
      "      \u001b[32m[OK] 7_Multi_preprocessed_Emnist: \u001b[31m4 digits detected\u001b[0m\n",
      "      \u001b[32m[OK] 7_Single_preprocessed_Emnist: \u001b[31m1 digits detected\u001b[0m\n",
      "      \u001b[32m[OK] 80_Single_preprocessed_Emnist: \u001b[31m1 digits detected\u001b[0m\n",
      "      \u001b[32m[OK] 81_Single_preprocessed_Emnist: \u001b[31m1 digits detected\u001b[0m\n",
      "      \u001b[32m[OK] 82_Single_preprocessed_Emnist: \u001b[31m1 digits detected\u001b[0m\n",
      "      \u001b[32m[OK] 83_Single_preprocessed_Emnist: \u001b[31m1 digits detected\u001b[0m\n",
      "      \u001b[32m[OK] 84_Single_preprocessed_Emnist: \u001b[31m1 digits detected\u001b[0m\n",
      "      \u001b[32m[OK] 85_Single_preprocessed_Emnist: \u001b[31m1 digits detected\u001b[0m\n",
      "      \u001b[32m[OK] 86_Single_preprocessed_Emnist: \u001b[31m1 digits detected\u001b[0m\n",
      "      \u001b[32m[OK] 87_Single_preprocessed_Emnist: \u001b[31m1 digits detected\u001b[0m\n",
      "      \u001b[32m[OK] 88_Single_preprocessed_Emnist: \u001b[31m1 digits detected\u001b[0m\n",
      "      \u001b[32m[OK] 89_Single_preprocessed_Emnist: \u001b[31m1 digits detected\u001b[0m\n",
      "      \u001b[32m[OK] 8_Multi_preprocessed_Emnist: \u001b[31m2 digits detected\u001b[0m\n",
      "      \u001b[32m[OK] 8_Single_preprocessed_Emnist: \u001b[31m1 digits detected\u001b[0m\n",
      "      \u001b[32m[OK] 90_Single_preprocessed_Emnist: \u001b[31m1 digits detected\u001b[0m\n",
      "      \u001b[32m[OK] 91_Single_preprocessed_Emnist: \u001b[31m1 digits detected\u001b[0m\n",
      "      \u001b[32m[OK] 92_Single_preprocessed_Emnist: \u001b[31m1 digits detected\u001b[0m\n",
      "      \u001b[32m[OK] 93_Single_preprocessed_Emnist: \u001b[31m1 digits detected\u001b[0m\n",
      "      \u001b[32m[OK] 94_Single_preprocessed_Emnist: \u001b[31m1 digits detected\u001b[0m\n",
      "      \u001b[32m[OK] 95_Single_preprocessed_Emnist: \u001b[31m1 digits detected\u001b[0m\n",
      "      \u001b[32m[OK] 96_Single_preprocessed_Emnist: \u001b[31m1 digits detected\u001b[0m\n",
      "      \u001b[32m[OK] 97_Single_preprocessed_Emnist: \u001b[31m1 digits detected\u001b[0m\n",
      "      \u001b[32m[OK] 98_Single_preprocessed_Emnist: \u001b[31m1 digits detected\u001b[0m\n",
      "      \u001b[32m[OK] 99_Single_preprocessed_Emnist: \u001b[31m1 digits detected\u001b[0m\n",
      "      \u001b[32m[OK] 9_Multi_preprocessed_Emnist: \u001b[31m3 digits detected\u001b[0m\n",
      "      \u001b[32m[OK] 9_Single_preprocessed_Emnist: \u001b[31m1 digits detected\u001b[0m\n",
      "[ERROR] Could not read image: C:\\Users\\joann\\PycharmProjects\\Recog\\Preprocessed\\Emnist\\Multi_Emnist_labels.json\n",
      "[ERROR] Could not read image: C:\\Users\\joann\\PycharmProjects\\Recog\\Preprocessed\\Emnist\\Single_Emnist_labels.json\n",
      "\n",
      "\u001b[33mTask 2 complete. Overlays with thin boxes saved in:C:\\Users\\joann\\PycharmProjects\\Recog\\Segmentation\\Emnist\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "## import os\n",
    "import re\n",
    "import cv2\n",
    "import json\n",
    "\n",
    "IN_DIR = os.path.join(BASE_DIR, \"Preprocessed\")\n",
    "PREPROCESSED = os.path.join(BASE_DIR, \"Preprocessed\")\n",
    "SEGMENTED = os.path.join(BASE_DIR, \"Segmentation\")\n",
    "OUT_DIR = os.path.join(BASE_DIR, \"Segmentation\")\n",
    "MID_DIR = PREPROCESSED\n",
    "\n",
    "# Create the output directory if it doesn't exist\n",
    "os.makedirs(OUT_DIR, exist_ok=True)\n",
    "\n",
    "import shutil\n",
    "''''\n",
    "\n",
    "Segmentation will split like this\n",
    "3 folders\n",
    "Mu\n",
    "\n",
    "'''\n",
    "\n",
    "\n",
    "\n",
    "def segment_gui():\n",
    "    print(f\"Please Select A Option:\\n     1.Segment Only the MNIST Folder\\n     2. Segment the EMNIST Folder\\n     3.Segment Both Folders\\n     q.Quit\")\n",
    "    print(f\"{Colour.YELLOW}Selection{Colour.END}:\", end=\"\")\n",
    "    choice = reuseable_end_sequence(\"\")\n",
    "    seg_choice = int(choice)\n",
    "    ''''\n",
    "    Image SEGEMNTING\n",
    "    should be automatic\n",
    "    '''\n",
    "\n",
    "\n",
    "    match seg_choice:\n",
    "        case 1:\n",
    "            dataset = \"Mnist\"\n",
    "            print(f\"    {Colour.CYAN}You have chosen to Segment only the {dataset} Folder{Colour.END}\")\n",
    "\n",
    "            IN_DIR = os.path.join(PREPROCESSED, \"Mnist\")\n",
    "            OUT_DIR = os.path.join(SEGMENTED, \"Mnist\")\n",
    "\n",
    "            # Create the directory if it doesn't exist\n",
    "            os.makedirs(OUT_DIR, exist_ok=True)\n",
    "        case 2:\n",
    "            dataset = \"Emnist\"\n",
    "            print(f\"    {Colour.CYAN}You have chosen to Segment only the {dataset} Folder{Colour.END}\")\n",
    "\n",
    "            IN_DIR = os.path.join(PREPROCESSED, \"Emnist\")\n",
    "            OUT_DIR = os.path.join(SEGMENTED, \"Emnist\")\n",
    "\n",
    "            # Create the directory if it doesn't exist\n",
    "            os.makedirs(OUT_DIR, exist_ok=True)\n",
    "\n",
    "        case _:\n",
    "            print(f\" {Colour.RED}Invalid Selection{Colour.END}\")\n",
    "\n",
    "\n",
    "    # AKA this would open in Preprocessed/Mnist\n",
    "    json_files_data=[]\n",
    "    out_path = os.path.join(OUT_DIR, f\"labels.json\")\n",
    "    for fname in os.listdir(IN_DIR):\n",
    "\n",
    "        if fname.endswith('json'):\n",
    "            preprocess_path = os.path.join(IN_DIR, fname)  # full path to JSON file\n",
    "            segment_path = os.path.join(OUT_DIR, fname)\n",
    "            shutil.copy2(preprocess_path, segment_path)  # exact copy\n",
    "            with open(preprocess_path, \"r\") as f:\n",
    "                data = json.load(f)\n",
    "            print(f\"Copied JSON: {fname} -> {OUT_DIR}\")\n",
    "\n",
    "    matches=[]\n",
    "    for fname in os.listdir(IN_DIR):\n",
    "\n",
    "            path = os.path.join(IN_DIR, fname)\n",
    "            img_gray = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "            if img_gray is None:\n",
    "                print(f\"[ERROR] Could not read image: {path}\")\n",
    "                continue\n",
    "            boxes = segment_contours(img_gray)\n",
    "            digits, imgs_box, labels, x, y, w, h = segment_and_extract_digits(img_gray, boxes)\n",
    "            base = os.path.splitext(fname)[0]\n",
    "\n",
    "            out_path = os.path.join(OUT_DIR, f\"{base}.png\")\n",
    "            cv2.imwrite(out_path, imgs_box)\n",
    "\n",
    "\n",
    "            print(f\"      {Colour.GREEN}[OK] {base}: {Colour.RED}{len(boxes)} digits detected{Colour.END}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    print(f\"\\n{Colour.YELLOW}Task 2 complete. Overlays with thin boxes saved in:{OUT_DIR}{Colour.END}\")\n",
    "    # return boxes\n",
    "\n",
    "\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "boxes = segment_gui()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afcf9ca817e4bf66",
   "metadata": {},
   "source": [
    "#Everything below is new code for test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc0b5152d39c1df9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-31T07:12:30.775661Z",
     "start_time": "2025-10-31T07:12:30.283200Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Displaying images for JSON: Multi_Emnist_labels.json\n",
      "   \u001b[35mTitle: 0_Multi_preprocessed_Emnist\u001b[0m\n",
      "   \u001b[35mChars: [17, 16]\u001b[0m\n",
      "   \u001b[35mTitle: 1_Multi_preprocessed_Emnist\u001b[0m\n",
      "   \u001b[35mChars: [4, 15, 4, 9]\u001b[0m\n",
      "   \u001b[35mTitle: 2_Multi_preprocessed_Emnist\u001b[0m\n",
      "   \u001b[35mChars: [19]\u001b[0m\n",
      "   \u001b[35mTitle: 3_Multi_preprocessed_Emnist\u001b[0m\n",
      "   \u001b[35mChars: [16, 17, 21, 15, 26, 4, 21]\u001b[0m\n",
      "   \u001b[35mTitle: 4_Multi_preprocessed_Emnist\u001b[0m\n",
      "   \u001b[35mChars: [7]\u001b[0m\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x300 with 5 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Displaying images for JSON: Single_Emnist_labels.json\n",
      "   \u001b[35mTitle: 0_Single_preprocessed_Emnist\u001b[0m\n",
      "   \u001b[35mChars: [25]\u001b[0m\n",
      "   \u001b[35mTitle: 1_Single_preprocessed_Emnist\u001b[0m\n",
      "   \u001b[35mChars: [7]\u001b[0m\n",
      "   \u001b[35mTitle: 2_Single_preprocessed_Emnist\u001b[0m\n",
      "   \u001b[35mChars: [25]\u001b[0m\n",
      "   \u001b[35mTitle: 3_Single_preprocessed_Emnist\u001b[0m\n",
      "   \u001b[35mChars: [11]\u001b[0m\n",
      "   \u001b[35mTitle: 4_Single_preprocessed_Emnist\u001b[0m\n",
      "   \u001b[35mChars: [10]\u001b[0m\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x300 with 5 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "### import os\n",
    "import re\n",
    "import cv2\n",
    "\n",
    "IN_DIR = os.path.join(BASE_DIR, \"Preprocessed\")\n",
    "PREPROCESSED = os.path.join(BASE_DIR, \"Preprocessed\")\n",
    "SEGMENTED = os.path.join(BASE_DIR, \"Segmentation\")\n",
    "OUT_DIR = os.path.join(BASE_DIR, \"Segmentation\")\n",
    "MNIST_PATH = os.path.join(SEGMENTED, \"Mnist\")\n",
    "EMNIST_PATH = os.path.join(SEGMENTED, \"Emnist\")\n",
    "MID_DIR = PREPROCESSED\n",
    "\n",
    "\n",
    "\n",
    "import os\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "\n",
    "# Paths\n",
    "JSON_DIR = EMNIST_PATH    # folder containing  JSON files\n",
    "IMG_DIR = EMNIST_PATH   # folder containing PNG images\n",
    "\n",
    "def display_images_from_all_jsons(json_dir, img_dir, max_images_per_json=5):\n",
    "    # Loop through all JSON files\n",
    "    for json_file in os.listdir(json_dir):\n",
    "        if not json_file.endswith(\".json\"):\n",
    "            continue\n",
    "\n",
    "        json_path = os.path.join(json_dir, json_file)\n",
    "        with open(json_path, \"r\") as f:\n",
    "            data = json.load(f)\n",
    "\n",
    "        print(f\"\\nDisplaying images for JSON: {json_file}\")\n",
    "\n",
    "        plt.figure(figsize=(15, 3))\n",
    "        count = 0\n",
    "        for item in data:\n",
    "            if count >= max_images_per_json:\n",
    "                break\n",
    "            title = item.get(\"Title\")\n",
    "            char = item.get(\"Chars\")\n",
    "            if not title:\n",
    "                continue\n",
    "\n",
    "            png_path = os.path.join(img_dir, f\"{title}.png\")\n",
    "            if not os.path.exists(png_path):\n",
    "                print(f\"[WARNING] Image not found for title: {title}\")\n",
    "                continue\n",
    "\n",
    "            img = cv2.imread(png_path, cv2.IMREAD_GRAYSCALE)\n",
    "            if img is None:\n",
    "                print(f\"[ERROR] Failed to read image: {png_path}\")\n",
    "                continue\n",
    "\n",
    "            plt.subplot(1, max_images_per_json, count + 1)\n",
    "            plt.imshow(img, cmap=\"gray\")\n",
    "            plt.title(title)\n",
    "            plt.axis(\"off\")\n",
    "            count += 1\n",
    "            print(f\"   {Colour.MAGENTA}Title: {title}{Colour.END}\")\n",
    "            print(f\"   {Colour.MAGENTA}Chars: {char}{Colour.END}\")\n",
    "\n",
    "        plt.show()\n",
    "\n",
    "# Example usage\n",
    "display_images_from_all_jsons(JSON_DIR, IMG_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52c98604377654c3",
   "metadata": {},
   "source": [
    "### In this section, we load the MNIST dataset, which contains grayscale images of handwritten digits (0–9).\n",
    "Each image is 28×28 pixels. We normalize the pixel values (divide by 255) to bring them into the [0,1] range, which helps models converge faster.\n",
    "We also flatten the data for non-convolutional models (like Dense Neural Network or KNN) while keeping the original shape (28×28×1) for CNN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc62146b41c8c334",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "209ee24e3f961aa",
   "metadata": {},
   "source": [
    "## Build Models\n",
    "We use multiple models for prediction because we don’t know what kind of images users will upload. Using different models helps handle various image types and improves accuracy and reliability."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a8744fb5437e78d",
   "metadata": {},
   "source": [
    "### Train CNN Model\n",
    "Train a Convolutional Neural Network (CNN) to learn spatial image features. This model should give the best accuracy on handwritten digits.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f11db7fce3a062f4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-31T07:13:09.409989Z",
     "start_time": "2025-10-31T07:13:09.208761Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "#Changes\n",
    "#Updated to Use Function\n",
    "#Added Input Layer\n",
    "\n",
    "def Convolutional_Neural_Network(input_shape,num_classes):\n",
    "        print(f\"{Colour.YELLOW}\\n--- Training CNN Model ---{Colour.END}\")\n",
    "        model =  tf.keras.models.Sequential(\n",
    "              [\n",
    "              tf.keras.layers.Input(shape=input_shape),\n",
    "             # tf.keras.layers.Input(shape=(28,28,1)),input_shape\n",
    "                       #Scan image with small FILTERS/KENNEL----------Transform image into 32 Feature Maps ( Map show where spec patts were found edges,dots,lines)\n",
    "              tf.keras.layers.Conv2D(64,(3,3),activation='relu'),\n",
    "              #Reduce size of image Without Loosing Crit details-------increase speed of model as less details to filt\n",
    "              tf.keras.layers.MaxPooling2D((2,2)),      #2,2 AS EACH 2 by 2 area becomes 1 pixel  AKA SHRINK IMAGE IN HALF\n",
    "              tf.keras.layers.Conv2D(128, (3,3), activation='relu'),   #3,3 as its a good balacnce for small local features,  ANOTHER RELU  as it keeps learning non-lin and avoid DEAD VALS\n",
    "              #Reduce data size and compelxity\n",
    "              tf.keras.layers.MaxPooling2D((2,2)), #\n",
    "              #Take the 2d data(GRID) and flattern it into 1d AKA SINGLE ROW\n",
    "              tf.keras.layers.Flatten(),# EG: if out was (7,7,64) it would flattern into long vec of 7x7x64=3136 numbers\n",
    "              #Every input connects to every neuron----------Weird neural splasticity\n",
    "              tf.keras.layers.Dense(128, activation='relu'),# 64 is th num of neurons in this layer, and relu for help with non lin/speed,\n",
    "              tf.keras.layers.Dropout(0.4),#added for models kink for the letter q and h\n",
    "\n",
    "              tf.keras.layers.Dense(num_classes, activation='softmax')# 10 output neurons aka ONE FOR EACH POTENIAL DIGIT\n",
    "              #Softmax tursn the 10 raw scores itno proabilits that all add up to 1\n",
    "              ],\n",
    "        name=\"Convolutional_Neural_Network\"\n",
    "        )\n",
    "\n",
    "        print(model.name)\n",
    "        model.compile(\n",
    "              optimizer='adam',#How the model update itself\n",
    "              loss='categorical_crossentropy', # how it measure mistajkes\n",
    "              metrics=['accuracy']  #track often of correct guess\n",
    "\n",
    "              )\n",
    "\n",
    "\n",
    "        model.summary()\n",
    "        return model\n",
    "\n",
    "\n",
    "def Convolutional_Analysis(model, x_test, y_test, num_classes):\n",
    "\n",
    "    print(f\"{Colour.YELLOW}\\n--- Evaluating CNN Model ---{Colour.END}\")\n",
    "\n",
    "    # Ensure y_test is a clean 1-D array\n",
    "    y_true = np.array(y_test).reshape(-1)\n",
    "\n",
    "    # One-hot encode for evaluation\n",
    "    y_test_cat = to_categorical(y_true, num_classes=num_classes)\n",
    "\n",
    "    # Confirm equal lengths\n",
    "    assert x_test.shape[0] == y_test_cat.shape[0], \\\n",
    "        f\"Mismatch: x_test={x_test.shape[0]}, y_test={y_test_cat.shape[0]}\"\n",
    "\n",
    "    # Evaluate model\n",
    "    cnn_loss, cnn_accuracy = model.evaluate(x_test, y_test_cat, verbose=1)\n",
    "    print(f\"Test Accuracy: {Colour.RED}{cnn_accuracy * 100:.2f}%{Colour.END}\")\n",
    "    print(f\"Test Loss: {Colour.RED}{cnn_loss:.4f}{Colour.END}\")\n",
    "\n",
    "    # Predictions\n",
    "    preds = model.predict(x_test, verbose=0)\n",
    "    y_pred = np.argmax(preds, axis=1)\n",
    "    cnn_f1 = f1_score(y_true, y_pred, average=\"weighted\")\n",
    "\n",
    "\n",
    "    print(f\"Weighted F1-Score: {Colour.RED}{cnn_f1:.4f}{Colour.END}\")\n",
    "\n",
    "    mistakes = np.where(y_pred != y_true)[0]\n",
    "    print(f\"Total Mistakes: {len(mistakes)}\")\n",
    "\n",
    "    if len(mistakes) > 0:\n",
    "        plt.figure(figsize=(15, 3))\n",
    "        for i, idx in enumerate(mistakes[:10]):\n",
    "            plt.subplot(1, 10, i+1)\n",
    "            plt.imshow(x_test[idx].squeeze(), cmap=\"gray\")\n",
    "            plt.title(f\"T:{y_true[idx]} P:{y_pred[idx]}\")\n",
    "            plt.axis(\"off\")\n",
    "        plt.show()\n",
    "\n",
    "    return cnn_accuracy, cnn_f1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49064f1f3ffde08",
   "metadata": {},
   "source": [
    "### Train KNN Model\n",
    "Use K-Nearest Neighbors (KNN) as a traditional ML model for comparison. Evaluate accuracy and F1-score on the test set.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c8bb81c32d84f7f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-31T05:44:37.191700Z",
     "start_time": "2025-10-31T05:44:37.184150Z"
    }
   },
   "outputs": [],
   "source": [
    "import time\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "\n",
    "def K_Nearest_Neighbors(x_train_flat,y_train):\n",
    "    print(f\"{Colour.YELLOW}\\n--- Training KNN Model ---{Colour.END}\")\n",
    "\n",
    "\n",
    "    knn = KNeighborsClassifier(n_neighbors=3,\n",
    "                               weights='distance',#if closer the neighbour matter more\n",
    "                               n_jobs=-1)#use all cpu cores\n",
    "    knn.fit(x_train_flat, y_train)\n",
    "\n",
    "    #knn.summary\n",
    "    return knn\n",
    "def K_Analysis(knn,x_test_flat,y_test):\n",
    "    print(f\"{Colour.YELLOW}\\n--- Evaluating KNN Model ---{Colour.END}\")\n",
    "    y_pred_knn = knn.predict(x_test_flat)\n",
    "    knn_accuracy = accuracy_score(y_test, y_pred_knn)\n",
    "    knn_f1 = f1_score(y_test, y_pred_knn, average='weighted')\n",
    "\n",
    "    print(f\"Test Accuracy: {Colour.RED}{knn_accuracy * 100:.2f}%{Colour.END}\")\n",
    "    print(f\"Weighted F1-Score: {Colour.RED}{knn_f1:.4f}{Colour.END}\")\n",
    "\n",
    "\n",
    "# --- Configuration ---\n",
    "RANDOM_SEED = 42\n",
    "# Increased RF estimators for better performance on flattened data\n",
    "N_ESTIMATORS_RF = 300\n",
    "# Increased CNN epochs for better training convergence\n",
    "EPOCHS_CNN = 5\n",
    "BLOCK_SIZE = 28 # MNIST digit size\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#random forest\n",
    "#ADDED Max depth for\n",
    "def train_random_forest(x_train_rf,y_train_rf):\n",
    "    \"\"\"Trains the Random Forest model.\"\"\"\n",
    "    print(f\"{Colour.YELLOW}--- Training RF Model ---{Colour.END}\")\n",
    "    rf = RandomForestClassifier(\n",
    "        # Increased estimators (300) Maybe put to 100\n",
    "        n_estimators=N_ESTIMATORS_RF,\n",
    "        max_depth=50,\n",
    "        random_state=RANDOM_SEED,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "\n",
    "    rf.fit(x_train_rf, y_train_rf)\n",
    "    return rf\n",
    "\n",
    "def rf_Analysis(rf,x_test_flat,y_test):\n",
    "    print(f\"{Colour.YELLOW}\\n--- Evaluating RF Model ---{Colour.END}\")\n",
    "    start_time = time.time()\n",
    "    y_pred_rf=rf.predict(x_test_flat)\n",
    "    rf_accuracy = accuracy_score(y_test, y_pred_rf)\n",
    "    rf_f1 = f1_score(y_test, y_pred_rf, average='weighted')\n",
    "\n",
    "    print(f\"Test Accuracy: {Colour.RED}{rf_accuracy * 100:.2f}%{Colour.END}\")\n",
    "    print(f\"Weighted F1-Score: {Colour.RED}{rf_f1:.4f}{Colour.END}\")\n",
    "\n",
    "    end_time = time.time()\n",
    "    print(f\"RF Training completed in {Colour.RED}{end_time - start_time:.2f} seconds.{Colour.END}\")\n",
    "    return rf\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f52ab13848bca62",
   "metadata": {},
   "source": [
    "### Train Dense Neural Network\n",
    "Train a fully connected (Dense) model as a simple baseline for digit classification. Evaluate using accuracy and F1-score.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd1712d644f8121f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-31T05:35:35.856509Z",
     "start_time": "2025-10-31T05:35:35.847507Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "\n",
    "\n",
    "# ------------------------------\n",
    "# Dense Neural Network\n",
    "# ------------------------------\n",
    "def Dense_Neural_Network(input_shape, num_classes):\n",
    "    print(f\"{Colour.YELLOW}\\n--- Training DNN Model ---{Colour.END}\")\n",
    "    model = tf.keras.models.Sequential([\n",
    "        tf.keras.layers.Input(shape=input_shape),\n",
    "        tf.keras.layers.Dense(512, activation='relu'),\n",
    "        tf.keras.layers.Dropout(0.3),\n",
    "        tf.keras.layers.Dense(256, activation='relu'),\n",
    "        tf.keras.layers.Dropout(0.3),\n",
    "        tf.keras.layers.Dense(128, activation='relu'),\n",
    "        tf.keras.layers.Dense(num_classes, activation='softmax')\n",
    "    ])\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# ------------------------------\n",
    "# Evaluate model\n",
    "# ------------------------------\n",
    "def Dense_Analysis(model, x_test, y_test, num_classes=36):\n",
    "    print(f\"{Colour.YELLOW}\\n--- Evaluating DNN Model ---{Colour.END}\")\n",
    "    # Ensure y_test is a clean 1-D array\n",
    "    y_true = np.array(y_test).reshape(-1).astype(int)\n",
    "    y_pred_prob = model.predict(x_test, verbose=0)\n",
    "    y_pred = np.argmax(y_pred_prob, axis=1)\n",
    "     # Confirm equal lengths\n",
    "\n",
    "    dnn_loss, dnn_accuracy = model.evaluate(x_test, to_categorical(y_true, num_classes), verbose=0)\n",
    "\n",
    "\n",
    "\n",
    "    dnn_f1 = f1_score(y_true, y_pred, average='weighted')\n",
    "    print(f\"Test Accuracy: {Colour.RED}{dnn_accuracy * 100:.2f}%{Colour.END}\")\n",
    "    print(f\"Test Loss: {Colour.RED}{dnn_loss:.4f}{Colour.END}\")\n",
    "\n",
    "    print(f\"Weighted F1-Score: {Colour.RED}{dnn_f1:.4f}{Colour.END}\")\n",
    "\n",
    "    mistakes = np.where(y_pred != y_true)[0]\n",
    "    print(f\"Total Mistakes: {len(mistakes)}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# ------------------------------\n",
    "# Train model\n",
    "# ------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dc793cbb6a4efb3",
   "metadata": {},
   "source": [
    "### Function Call\n",
    "Method to call all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9525ece6e8946d37",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-01T03:27:31.520624Z",
     "start_time": "2025-11-01T03:27:28.663987Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mCycle Start: We are in the get_model\u001b[0m\n",
      "Please select a dataset(0=Mnist)(1=Emnist) or (2=load preexisting) Quit(q)\n",
      "\u001b[33mSelection\u001b[0m:"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "Interrupted by user",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[19]\u001b[39m\u001b[32m, line 435\u001b[39m\n\u001b[32m    433\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\033\u001b[39;00m\u001b[33m[31m  Invalid Input! Please enter a valid selection.\u001b[39m\u001b[38;5;130;01m\\033\u001b[39;00m\u001b[33m[0m\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m    434\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m num_classes, model_path\n\u001b[32m--> \u001b[39m\u001b[32m435\u001b[39m \u001b[43mget_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwhich_model\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43mskip_input\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m    437\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mkeras\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmodels\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m load_model\n\u001b[32m    439\u001b[39m \u001b[33;03m'''''\u001b[39;00m\n\u001b[32m    440\u001b[39m \u001b[33;03mIDEA\u001b[39;00m\n\u001b[32m    441\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    503\u001b[39m \n\u001b[32m    504\u001b[39m \u001b[33;03m'''\u001b[39;00m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[19]\u001b[39m\u001b[32m, line 139\u001b[39m, in \u001b[36mget_model\u001b[39m\u001b[34m(which_model, skip_input)\u001b[39m\n\u001b[32m    137\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mColour.YELLOW\u001b[38;5;132;01m}\u001b[39;00m\u001b[33mSelection\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mColour.END\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m:\u001b[39m\u001b[33m\"\u001b[39m, end=\u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    138\u001b[39m dataset=\u001b[33m\"\u001b[39m\u001b[33mn/a\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m139\u001b[39m choice=\u001b[43mreuseable_end_sequence\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m#Characters cause what the fuck is them\u001b[39;00m\n\u001b[32m    140\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m choice \u001b[38;5;129;01mand\u001b[39;00m choice.strip():\n\u001b[32m    141\u001b[39m         dataset_choice=\u001b[38;5;28mint\u001b[39m(choice)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 16\u001b[39m, in \u001b[36mreuseable_end_sequence\u001b[39m\u001b[34m(prompter)\u001b[39m\n\u001b[32m     15\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mreuseable_end_sequence\u001b[39m(prompter):\n\u001b[32m---> \u001b[39m\u001b[32m16\u001b[39m   choice=\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mprompter\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     17\u001b[39m   \u001b[38;5;28;01mif\u001b[39;00m choice.lower()==\u001b[33m'\u001b[39m\u001b[33mq\u001b[39m\u001b[33m'\u001b[39m:\u001b[38;5;66;03m# Q QUIT\u001b[39;00m\n\u001b[32m     18\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mColour.RED\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m  Exiting Program\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mColour.END\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\PycharmProjects\\Recog\\.venv1\\Lib\\site-packages\\ipykernel\\kernelbase.py:1396\u001b[39m, in \u001b[36mKernel.raw_input\u001b[39m\u001b[34m(self, prompt)\u001b[39m\n\u001b[32m   1394\u001b[39m     msg = \u001b[33m\"\u001b[39m\u001b[33mraw_input was called, but this frontend does not support input requests.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1395\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m StdinNotImplementedError(msg)\n\u001b[32m-> \u001b[39m\u001b[32m1396\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_input_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1397\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1398\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_shell_context_var\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_shell_parent_ident\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1399\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mget_parent\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mshell\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1400\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpassword\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m   1401\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\PycharmProjects\\Recog\\.venv1\\Lib\\site-packages\\ipykernel\\kernelbase.py:1441\u001b[39m, in \u001b[36mKernel._input_request\u001b[39m\u001b[34m(self, prompt, ident, parent, password)\u001b[39m\n\u001b[32m   1438\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m:\n\u001b[32m   1439\u001b[39m     \u001b[38;5;66;03m# re-raise KeyboardInterrupt, to truncate traceback\u001b[39;00m\n\u001b[32m   1440\u001b[39m     msg = \u001b[33m\"\u001b[39m\u001b[33mInterrupted by user\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1441\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m(msg) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1442\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[32m   1443\u001b[39m     \u001b[38;5;28mself\u001b[39m.log.warning(\u001b[33m\"\u001b[39m\u001b[33mInvalid Message:\u001b[39m\u001b[33m\"\u001b[39m, exc_info=\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: Interrupted by user"
     ]
    }
   ],
   "source": [
    "## Here will be the model calling stuff\n",
    "''''\n",
    "We want to split the functions as its too heavy\n",
    "\n",
    "\n",
    "'''\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "import joblib\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "IN_DIR = os.path.join(BASE_DIR, \"Preprocessed\")\n",
    "SEGMENTED = os.path.join(BASE_DIR, \"Segmentation\")\n",
    "OUT_DIR = os.path.join(BASE_DIR, \"Segmentation\")\n",
    "os.makedirs(OUT_DIR, exist_ok=True)\n",
    "\n",
    "DUAL_FOLDER = SEGMENTED\n",
    "json_file = os.path.join(DUAL_FOLDER, \"labels.json\")\n",
    "import tensorflow as tf\n",
    "\n",
    "#from pathlib import Path\n",
    "#from sklearn.utils import shuffle\n",
    "from PIL import Image\n",
    "import os\n",
    "import json\n",
    "import cv2\n",
    "#from pathlib import Path\n",
    "import numpy as np\n",
    "\n",
    "#fucked\n",
    "#mopt wprl\n",
    "\n",
    "from datetime import datetime\n",
    "'''\n",
    "It was easier to use concaternate to combind both\n",
    "'''\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def char_to_int(c):\n",
    "    \"\"\"Convert a single character to integer label.\"\"\"\n",
    "    if c.isdigit():\n",
    "        return int(c)\n",
    "    elif c.isalpha():\n",
    "        return ord(c.lower()) - ord('a') + 10\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "\n",
    "#TO ADD COMPAT WITH OTHER MODS ADD OPTYION 1 = reshape for mlp,dnn etc\n",
    "def json_loader():\n",
    "    x_data, y_data, filenames = [], [], []\n",
    "    choice = int(input(\"Enter your choice:(mnist=0)(emnist=1) \"))\n",
    "\n",
    "    if choice == 0:\n",
    "        folder = os.path.join(SEGMENTED, \"Mnist\")\n",
    "        dataset=\"Mnist\"\n",
    "    elif choice == 1:\n",
    "        folder = os.path.join(SEGMENTED, \"Emnist\")\n",
    "        dataset=\"Emnist\"\n",
    "\n",
    "    for fname in os.listdir(folder):\n",
    "        if not fname.endswith(\".json\"):\n",
    "            continue\n",
    "        with open(os.path.join(folder, fname), \"r\") as f:\n",
    "            data = json.load(f)\n",
    "        for item in data:\n",
    "            title = item.get(\"Title\")\n",
    "            chars = item.get(\"Chars\")\n",
    "            if not title or not chars:\n",
    "                continue\n",
    "            png_path = os.path.join(folder, f\"{title}.png\")  # Assuming PNG name = Title + .png\n",
    "            if not os.path.exists(png_path):\n",
    "                print(f\"File not found: {png_path}\")\n",
    "                continue\n",
    "            img = Image.open(png_path).convert(\"L\").resize((64, 64))\n",
    "            x_data.append(np.array(img, dtype=np.float32) / 255.0)\n",
    "            filenames.append(png_path)\n",
    "            y_data.append(chars)  # Directly append the int list\n",
    "\n",
    "    print(f\"Loaded {len(x_data)} images from JSON.\")\n",
    "    return np.array(x_data), np.array(y_data, dtype=object), filenames,dataset\n",
    "\n",
    "''''\n",
    "We want to split the functions as its too heavy\n",
    "\n",
    "\n",
    "'''\n",
    "def datagen_block(x_train):\n",
    "      # Data augmentation\n",
    "      datagen = ImageDataGenerator(\n",
    "                    rotation_range=15,       # rotate +=15 degrees\n",
    "                    width_shift_range=0.1,  # Changed from shift =+2 pixels t0 0.1 for consitenct\n",
    "                    height_shift_range=0.1, # Changed from shift =+2 pixels t0 0.1 for consitenct aka the valure was  2/28,\n",
    "                    zoom_range=0.2,          # slight zoom chanegd to 0.2\n",
    "                    shear_range=0.1, #old val5,           # small shear\n",
    "                    horizontal_flip=False    # do not flip letters\n",
    "                    ,\n",
    "                    vertical_flip=False,\n",
    "                    validation_split=0.1  # keep 10% for validation\n",
    "                )\n",
    "      datagen.fit(x_train)\n",
    "      return datagen\n",
    "#REPALCE MLP WITH SVM!!!!!!!\n",
    "# Before using it in case 1\n",
    "\n",
    "from tensorflow.keras.models import save_model\n",
    "\n",
    "def get_model(which_model=None, skip_input=False):\n",
    "  save_dir = \"models\"\n",
    "  os.makedirs(save_dir, exist_ok=True)\n",
    "  available_models = [\n",
    "      \"Pray\",\n",
    "      \"Convolutional Neural Networks (CNN) \",\n",
    "      \"Deep Neural Networks (DNN) \",\n",
    "\n",
    "      \"Random Forest(RF)\",\n",
    "      \"K-Nearest Neighbors (KNN)\"\n",
    "      \"All\"\n",
    "  ]\n",
    "  while True:\n",
    "    try:\n",
    "\n",
    "      #skip[ case]\n",
    "      if not skip_input:\n",
    "        print(\"\\033[34mCycle Start: We are in the get_model\\033[0m\") #DELETE delete Remove Remove Temp\n",
    "       #print(f\"{Colour.RED}Training Images: {x_train.shape}, Training Labels: {y_train.shape}{Colour.END}\")\n",
    "\n",
    "\n",
    "        print(f\"Please select a dataset(0=Mnist)(1=Emnist) or (2=load preexisting) Quit(q)\")\n",
    "        print(f\"{Colour.YELLOW}Selection{Colour.END}:\", end=\"\")\n",
    "        dataset=\"n/a\"\n",
    "        choice=reuseable_end_sequence(\"\") #Characters cause what the fuck is them\n",
    "        if choice and choice.strip():\n",
    "                dataset_choice=int(choice)\n",
    "                match dataset_choice:\n",
    "                  case 0:\n",
    "                    dataset=\"Mnist\"\n",
    "                    print(f\"{Colour.CYAN}You have Selected {dataset}.{Colour.END}\\n\")\n",
    "                    option=0\n",
    "\n",
    "                    x_train, y_train, x_test, y_test = mnist_loader()\n",
    "\n",
    "                    np.savez_compressed(\"mnist.npz\", x_train=x_train, y_train=y_train,\n",
    "                    x_test=x_test, y_test=y_test)\n",
    "\n",
    "                  case 1:\n",
    "                    dataset=\"Emnist\"\n",
    "\n",
    "                    print(f\"{Colour.CYAN}You have Selected {dataset}.{Colour.END}\\n\")\n",
    "                    option=1\n",
    "\n",
    "                    x_train, y_train, x_test, y_test =emnist_loader()\n",
    "\n",
    "\n",
    "                    print(f\"X_train:{x_train.shape}\\n Y_train:{y_train.shape}\\n X_test:{x_test.shape}\\n  Y_test:{y_test.shape}\\n\")\n",
    "                       # Convert & normalize in-place\n",
    "\n",
    "                    #One Hot Encoded\n",
    "                    # Dense and KNN use flattened input\n",
    "                   # x_train_flat = x_train.reshape(-1, 28*28)\n",
    "                    #x_test_flat  = x_test.reshape(-1, 28*28)\n",
    "                    # Flatten for Dense network\n",
    "                    #x_train_flat = x_train.reshape(x_train.shape[0], -1)\n",
    "                   # x_test_flat  = x_test.reshape(x_test.shape[0], -1)\n",
    "\n",
    "                    # Reshape for CNN\n",
    "                    #x_train_cnn = np.expand_dims(x_train, -1)\n",
    "                    #x_test_cnn  = np.expand_dims(x_test, -1)\n",
    "                    np.savez_compressed(\"emnist.npz\", x_train=x_train, y_train=y_train,\n",
    "                    x_test=x_test, y_test=y_test)\n",
    "\n",
    "\n",
    "                  case 2:\n",
    "                    choice=int(input(\"Please select a dataset:(0=Mnist)(1=Emnist)\"))\n",
    "\n",
    "                    if choice==0:\n",
    "                        file_path = \"mnist.npz\"\n",
    "                        dataset=\"Mnist\"\n",
    "                        if os.path.exists(file_path):\n",
    "                            data = np.load(file_path)\n",
    "                        data = np.load(file_path)\n",
    "\n",
    "                    elif choice==1:\n",
    "                        file_path = \"emnist.npz\"\n",
    "                        dataset=\"Emnist\"\n",
    "                        if os.path.exists(file_path):\n",
    "                            data = np.load(file_path)\n",
    "                        data = np.load(file_path)\n",
    "\n",
    "                    else:\n",
    "                        print(\"Invalid choice\")\n",
    "                    if choice in [0,1]:\n",
    "\n",
    "                        x_train = data['x_train']\n",
    "                        y_train = data['y_train']\n",
    "                        x_test  = data['x_test']\n",
    "                        y_test  = data['y_test']\n",
    "                        print(f\"x_train shape: {x_train.shape}, y_train shape: {y_train.shape}\")\n",
    "                        print(f\"x_test shape: {x_test.shape}, y_test shape: {y_test.shape}\")\n",
    "\n",
    "                  case 3:\n",
    "                      print(\"folder\")\n",
    "                      x_train, y_train, filenames,dataset = json_loader()\n",
    "                      x_test, y_test = x_train, y_train\n",
    "\n",
    "                  case _:\n",
    "                    raise ValueError(f\"Invalid Selection.\")\n",
    "        OUT_DIR_2 = os.path.join(OUT_DIR, dataset)\n",
    "\n",
    "            # One-hot encode labels\n",
    "\n",
    "\n",
    "        print(\"Please select a model(0=NoModel, 1=CNN, 2= DNN, 3=RF, 4=KNN, 5=ALL)\")\n",
    "        which_model = int(\n",
    "              input(\"Selection:\")\n",
    "          )\n",
    "\n",
    "      if which_model==0 or which_model is None:\n",
    "        print(\"No Model\")\n",
    "        return None, which_model\n",
    "    #Cylic or cycle redunandy tests\n",
    "      if  skip_input:\n",
    "        print(\"\\033[34mReturned to the get_model function\\033[0m\")#DELETE delete Remove Remove Temp\n",
    "      #processed_img = preprocess_for_model(img, which_model)\n",
    "      num_classes= len(np.unique(y_train))\n",
    "      x_train_flat = x_train.reshape(x_train.shape[0], -1).astype(\"float32\") / 255.0\n",
    "      x_test_flat  = x_test.reshape(x_test.shape[0], -1).astype(\"float32\") / 255.0\n",
    "\n",
    "      match which_model:\n",
    "          case 0:\n",
    "\n",
    "            print(\"no model\")\n",
    "          # Multi Layer Perception Model (MLPs)\n",
    "\n",
    "\n",
    "\n",
    "          # Convolutional Neural Networks (CNNs)\n",
    "          case 1:\n",
    "\n",
    "                print(f\"you have selected {available_models[which_model]}\")\n",
    "\n",
    "                #Expand dims if needed (28x28 -> 28x28x1)\n",
    "\n",
    "                if x_train.ndim == 3:# (N, H, W)\n",
    "                    x_train = np.expand_dims(x_train, -1)\n",
    "                if x_test.ndim == 3:\n",
    "                    x_test = np.expand_dims(x_test, -1)\n",
    "\n",
    "                #call for num classes\n",
    "                model_ran=0\n",
    "                model_name=\"CNN\"\n",
    "                num_classes,model_path=dataset_selection(dataset,model_ran,model_name)\n",
    "                # One-hot encode labels\n",
    "\n",
    "                y_train_cat = to_categorical(y_train, num_classes)\n",
    "                y_test_cat  = to_categorical(y_test, num_classes)\n",
    "\n",
    "\n",
    "                # Data augmentation\n",
    "                datagen=datagen_block(x_train)\n",
    "\n",
    "                model = Convolutional_Neural_Network((28, 28, 1), num_classes)\n",
    "\n",
    "                # Callbacks\n",
    "                model_ran=1\n",
    "                num_classes,model_path=dataset_selection(dataset,model_ran,model_name)\n",
    "                # mvoed to dataset classmodel_path = os.path.join(MODELS_DIR, \"cnn.keras\")\n",
    "               # print(x_train[0])\n",
    "                #print(y_train_cat[0])\n",
    "               # print(y_test_cat[0])\n",
    "                #print(x_test[0])\n",
    "                # Train with augmented data\n",
    "                if dataset==\"Mnist\":\n",
    "                    model.fit(\n",
    "                        datagen.flow(x_train, y_train_cat, batch_size=64),#changed from 32 to 64\n",
    "                        epochs=20,\n",
    "                        validation_data=(x_test, y_test_cat),\n",
    "\n",
    "                        #steps_per_epoch=64,\n",
    "                        verbose=1\n",
    "                    )\n",
    "                else:\n",
    "\n",
    "                    model.fit(\n",
    "                        datagen.flow(x_train, y_train_cat, batch_size=64),#changed from 32 to 64\n",
    "                        epochs=35,\n",
    "                        validation_data=(x_test, y_test_cat),\n",
    "\n",
    "                        #steps_per_epoch=64,\n",
    "                        verbose=1\n",
    "                    )\n",
    "\n",
    "\n",
    "\n",
    "                # Evaluate and display mistakes\n",
    "                Convolutional_Analysis(model, x_test, y_test , num_classes)\n",
    "\n",
    "\n",
    "                print(f\"CNN model saved at: {model_path}\")\n",
    "\n",
    "               # Save model (overwrite old CNN)\n",
    "                if os.path.exists(model_path):\n",
    "                    os.remove(model_path)\n",
    "                model.save(model_path)\n",
    "\n",
    "          case 2:\n",
    "            print(f\"you have selected {available_models[which_model]}\")\n",
    "\n",
    "            # Flatten images for DNN\n",
    "\n",
    "            if x_train.ndim == 4 and x_train.shape[-1] == 1:\n",
    "                x_train = x_train.squeeze(-1)\n",
    "\n",
    "            if x_test.ndim == 4 and x_test.shape[-1] == 1:\n",
    "                x_test = x_test.squeeze(-1)\n",
    "\n",
    "\n",
    "            y_train_int = np.array(y_train, dtype=np.int32)\n",
    "            y_test_int  = np.array(y_test, dtype=np.int32)\n",
    "            model_name=\"DNN\"\n",
    "            # Get number of classes and model path\n",
    "            model_ran = 0\n",
    "            num_classes, model_path = dataset_selection(dataset, model_ran,model_name)\n",
    "            #num_classes = len(np.unique(y_train_int))\n",
    "\n",
    "            # Create DNN model\n",
    "            model = Dense_Neural_Network((x_train_flat.shape[1],), num_classes)\n",
    "\n",
    "            # One-hot encode labels for Keras\n",
    "            y_train_cat = to_categorical(y_train_int, num_classes)\n",
    "            y_test_cat  = to_categorical(y_test_int, num_classes)\n",
    "\n",
    "            model_ran = 1\n",
    "            num_classes, model_path = dataset_selection(dataset, model_ran,model_name)\n",
    "\n",
    "            # (old broken one-hot removed this is one of the changes I made since the demo)\n",
    "            # y_train_cat = to_categorical(y_train, num_classes)\n",
    "            # y_test_cat  = to_categorical(y_test, num_classes)\n",
    "\n",
    "            # Train with augmented data\n",
    "            if dataset==\"Mnist\":\n",
    "                model.fit(\n",
    "                         x_train_flat, y_train_cat,\n",
    "                         epochs=15,\n",
    "                         validation_data=(x_test_flat, y_test_cat),\n",
    "                         batch_size=64,\n",
    "                         #steps_per_epoch=64,\n",
    "                         verbose=1\n",
    "                    )\n",
    "            else:\n",
    "                model.fit(\n",
    "                     x_train_flat, y_train_cat,\n",
    "                     epochs=22,\n",
    "                     validation_data=(x_test_flat, y_test_cat),\n",
    "                     batch_size=64,\n",
    "                     #steps_per_epoch=64,\n",
    "                     verbose=1\n",
    "                )\n",
    "\n",
    "            # Evaluate and display mistakes\n",
    "            Dense_Analysis(model, x_test_flat, y_test, num_classes)\n",
    "\n",
    "            # Save model (overwrite old DNN)\n",
    "            if os.path.exists(model_path):\n",
    "                os.remove(model_path)\n",
    "            model.save(model_path)\n",
    "\n",
    "\n",
    "\n",
    "         #rANDOM FOREST\n",
    "          case 3:\n",
    "            print(f\"you have selected {available_models[which_model]}\")\n",
    "            model_ran=0\n",
    "            model_name=\"RF\"\n",
    "            num_classes, model_path = dataset_selection(dataset, model_ran,model_name)\n",
    "\n",
    "            # RF requires flattened input (N, 784)\n",
    "\n",
    "\n",
    "            x_train_rf = x_train.reshape(x_train.shape[0], -1)\n",
    "            x_test_rf = x_test.reshape(x_test.shape[0], -1)\n",
    "            y_train_rf = y_train\n",
    "            y_test_rf = y_test\n",
    "\n",
    "            print(f\"RF Train Data Shape: {x_train_rf.shape}\")\n",
    "             # Train the Random Forest Model\n",
    "            model = train_random_forest(x_train_rf,y_train_rf)\n",
    "            rf_Analysis(model,x_test_flat,y_test)\n",
    "            model_ran=1\n",
    "            num_classes, model_path = dataset_selection(dataset, model_ran,model_name)\n",
    "             # Save model (overwrite old DNN)\n",
    "            if os.path.exists(model_path):\n",
    "                os.remove(model_path)\n",
    "\n",
    "            joblib.dump(model, model_path)\n",
    "\n",
    "        #KNN\n",
    "          case 4:\n",
    "            print(f\"you have selected {available_models[which_model]}\")\n",
    "            knn=K_Nearest_Neighbors(x_train_flat,y_train\n",
    ")\n",
    "            K_Analysis(knn,x_test_flat,y_test)\n",
    "              #all\n",
    "\n",
    "          case 5:\n",
    "               print(f\"you have selected {available_models[which_model]}\")\n",
    "          case _:\n",
    "            raise ValueError(\"\\033[31m  Invalid Input! Please enter a valid selection.\\033[0m\\n\")#  ' 0 or 1' whjich better\n",
    "    except ValueError as e:\n",
    "        print(e)\n",
    "\n",
    "def dataset_selection(dataset,model_ran,model_name):\n",
    "\n",
    "                # Build model\n",
    "    MODELS_DIR = os.path.join(BASE_DIR, \"Models\")\n",
    "    os.makedirs(MODELS_DIR, exist_ok=True)\n",
    "    if dataset == \"Mnist\":\n",
    "        num_classes = 10\n",
    "\n",
    "        model_path = os.path.join(MODELS_DIR, f\"mnist_{model_name}.keras\")\n",
    " #\n",
    "    elif dataset == \"Emnist\":\n",
    "        num_classes = 27\n",
    "        model_path = os.path.join(MODELS_DIR, f\"emnist_{model_name}.keras\")\n",
    "    else:\n",
    "        raise ValueError(\"\\033[31m  Invalid Input! Please enter a valid selection.\\033[0m\\n\")\n",
    "    return num_classes, model_path\n",
    "get_model(which_model=None,skip_input=False)\n",
    "\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "'''''\n",
    "IDEA\n",
    "\n",
    "Run model ask\n",
    "move to train or test\n",
    "after confirm\n",
    "it fil in rel details\n",
    "\n",
    "issue\n",
    "We will ne4ed to have cases for t type of models\n",
    "\n",
    "\n",
    "\n",
    "imports model_choice form the thing\n",
    "ebfore\n",
    "\n",
    "If it is 1\n",
    "then it rusn all the mlp stuff etc\n",
    "\n",
    "It ran for 32 epochs\n",
    "\n",
    "second time it ran for 39\n",
    "Epoch 39/100\n",
    "\n",
    "Test Accuracy: 95.47%\n",
    "Test Loss: 0.1869\n",
    "Weighted F1-Score: 0.9566\n",
    "Total Mistakes:1123\n",
    "\n",
    "third run epoch 49/100\n",
    "Test Accuracy: 95.54%\n",
    "Test Loss: 0.1897\n",
    "Weighted F1-Score: 0.9575\n",
    "Total Mistakes:1106\n",
    "\n",
    "4\n",
    "Epoch 32/100\n",
    "1047/1047 ━━━━━━━━━━━━━━━━━━━━ 23s 22ms/step - accuracy: 0.9839 - loss: 0.0393 - val_accuracy: 0.9616 - val_loss: 0.1726 - learning_rate: 6.2500e-05\n",
    "\n",
    "--- Evaluating CNN Model ---\n",
    "775/775 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step - accuracy: 0.9549 - loss: 0.1694\n",
    "775/775 ━━━━━━━━━━━━━━━━━━━━ 2s 3ms/step\n",
    "Test Accuracy: 95.49%\n",
    "Test Loss: 0.1694\n",
    "Weighted F1-Score: 0.9568\n",
    "Total Mistakes:1118\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "case 4:#beta test no work yet temp\n",
    "                        folder = input(\"Enter folder path: \")\n",
    "                        x_train, y_train = load_images_from_folder(folder)\n",
    "                        x_test, y_test = x_train, y_train  # simple split\n",
    "case 2:\n",
    "                    dataset=\"Folder\"\n",
    "print working dir\n",
    "Ask user if they would liek to use emnsit or mnist\n",
    "if mnist\n",
    "dataset=\"mnist\"\n",
    "go to the folder    OUT_DIR_2 = os.path.join(OUT_DIR, dataset) aka go to the folder\n",
    "then search for jsons\n",
    "and for images\n",
    "\n",
    "\n",
    "'''\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c53591a48bde7a8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-01T04:19:23.972466Z",
     "start_time": "2025-11-01T04:19:04.840045Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 122ms/step\n",
      "C:\\Users\\joann\\PycharmProjects\\Recog\\Preprocessed\\0_Single_preprocessed_Emnist.png: TRUE=24  PRED=24\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step\n",
      "C:\\Users\\joann\\PycharmProjects\\Recog\\Preprocessed\\1_Single_preprocessed_Emnist.png: TRUE=6  PRED=19\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step\n",
      "C:\\Users\\joann\\PycharmProjects\\Recog\\Preprocessed\\2_Single_preprocessed_Emnist.png: TRUE=24  PRED=24\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step\n",
      "C:\\Users\\joann\\PycharmProjects\\Recog\\Preprocessed\\3_Single_preprocessed_Emnist.png: TRUE=10  PRED=10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step\n",
      "C:\\Users\\joann\\PycharmProjects\\Recog\\Preprocessed\\4_Single_preprocessed_Emnist.png: TRUE=9  PRED=18\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step\n",
      "C:\\Users\\joann\\PycharmProjects\\Recog\\Preprocessed\\5_Single_preprocessed_Emnist.png: TRUE=3  PRED=2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step\n",
      "C:\\Users\\joann\\PycharmProjects\\Recog\\Preprocessed\\6_Single_preprocessed_Emnist.png: TRUE=3  PRED=3\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 98ms/step\n",
      "C:\\Users\\joann\\PycharmProjects\\Recog\\Preprocessed\\7_Single_preprocessed_Emnist.png: TRUE=23  PRED=23\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step\n",
      "C:\\Users\\joann\\PycharmProjects\\Recog\\Preprocessed\\8_Single_preprocessed_Emnist.png: TRUE=6  PRED=6\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step\n",
      "C:\\Users\\joann\\PycharmProjects\\Recog\\Preprocessed\\9_Single_preprocessed_Emnist.png: TRUE=17  PRED=15\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step\n",
      "C:\\Users\\joann\\PycharmProjects\\Recog\\Preprocessed\\10_Single_preprocessed_Emnist.png: TRUE=3  PRED=3\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step\n",
      "C:\\Users\\joann\\PycharmProjects\\Recog\\Preprocessed\\11_Single_preprocessed_Emnist.png: TRUE=24  PRED=9\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step\n",
      "C:\\Users\\joann\\PycharmProjects\\Recog\\Preprocessed\\12_Single_preprocessed_Emnist.png: TRUE=21  PRED=21\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step\n",
      "C:\\Users\\joann\\PycharmProjects\\Recog\\Preprocessed\\13_Single_preprocessed_Emnist.png: TRUE=1  PRED=1\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step\n",
      "C:\\Users\\joann\\PycharmProjects\\Recog\\Preprocessed\\14_Single_preprocessed_Emnist.png: TRUE=3  PRED=3\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step\n",
      "C:\\Users\\joann\\PycharmProjects\\Recog\\Preprocessed\\15_Single_preprocessed_Emnist.png: TRUE=12  PRED=12\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step\n",
      "C:\\Users\\joann\\PycharmProjects\\Recog\\Preprocessed\\16_Single_preprocessed_Emnist.png: TRUE=15  PRED=15\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step\n",
      "C:\\Users\\joann\\PycharmProjects\\Recog\\Preprocessed\\17_Single_preprocessed_Emnist.png: TRUE=13  PRED=13\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step\n",
      "C:\\Users\\joann\\PycharmProjects\\Recog\\Preprocessed\\18_Single_preprocessed_Emnist.png: TRUE=20  PRED=20\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step\n",
      "C:\\Users\\joann\\PycharmProjects\\Recog\\Preprocessed\\19_Single_preprocessed_Emnist.png: TRUE=10  PRED=23\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step\n",
      "C:\\Users\\joann\\PycharmProjects\\Recog\\Preprocessed\\20_Single_preprocessed_Emnist.png: TRUE=10  PRED=23\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step\n",
      "C:\\Users\\joann\\PycharmProjects\\Recog\\Preprocessed\\21_Single_preprocessed_Emnist.png: TRUE=17  PRED=19\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step\n",
      "C:\\Users\\joann\\PycharmProjects\\Recog\\Preprocessed\\22_Single_preprocessed_Emnist.png: TRUE=22  PRED=20\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step\n",
      "C:\\Users\\joann\\PycharmProjects\\Recog\\Preprocessed\\23_Single_preprocessed_Emnist.png: TRUE=17  PRED=2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step\n",
      "C:\\Users\\joann\\PycharmProjects\\Recog\\Preprocessed\\24_Single_preprocessed_Emnist.png: TRUE=18  PRED=18\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step\n",
      "C:\\Users\\joann\\PycharmProjects\\Recog\\Preprocessed\\25_Single_preprocessed_Emnist.png: TRUE=7  PRED=0\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step\n",
      "C:\\Users\\joann\\PycharmProjects\\Recog\\Preprocessed\\26_Single_preprocessed_Emnist.png: TRUE=15  PRED=3\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step\n",
      "C:\\Users\\joann\\PycharmProjects\\Recog\\Preprocessed\\27_Single_preprocessed_Emnist.png: TRUE=14  PRED=14\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step\n",
      "C:\\Users\\joann\\PycharmProjects\\Recog\\Preprocessed\\28_Single_preprocessed_Emnist.png: TRUE=23  PRED=23\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step\n",
      "C:\\Users\\joann\\PycharmProjects\\Recog\\Preprocessed\\29_Single_preprocessed_Emnist.png: TRUE=14  PRED=14\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step\n",
      "C:\\Users\\joann\\PycharmProjects\\Recog\\Preprocessed\\30_Single_preprocessed_Emnist.png: TRUE=13  PRED=13\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step\n",
      "C:\\Users\\joann\\PycharmProjects\\Recog\\Preprocessed\\31_Single_preprocessed_Emnist.png: TRUE=9  PRED=9\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step\n",
      "C:\\Users\\joann\\PycharmProjects\\Recog\\Preprocessed\\32_Single_preprocessed_Emnist.png: TRUE=4  PRED=4\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step\n",
      "C:\\Users\\joann\\PycharmProjects\\Recog\\Preprocessed\\33_Single_preprocessed_Emnist.png: TRUE=1  PRED=19\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step\n",
      "C:\\Users\\joann\\PycharmProjects\\Recog\\Preprocessed\\34_Single_preprocessed_Emnist.png: TRUE=14  PRED=14\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step\n",
      "C:\\Users\\joann\\PycharmProjects\\Recog\\Preprocessed\\35_Single_preprocessed_Emnist.png: TRUE=10  PRED=20\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step\n",
      "C:\\Users\\joann\\PycharmProjects\\Recog\\Preprocessed\\36_Single_preprocessed_Emnist.png: TRUE=19  PRED=19\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 103ms/step\n",
      "C:\\Users\\joann\\PycharmProjects\\Recog\\Preprocessed\\37_Single_preprocessed_Emnist.png: TRUE=24  PRED=24\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step\n",
      "C:\\Users\\joann\\PycharmProjects\\Recog\\Preprocessed\\38_Single_preprocessed_Emnist.png: TRUE=9  PRED=14\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step\n",
      "C:\\Users\\joann\\PycharmProjects\\Recog\\Preprocessed\\39_Single_preprocessed_Emnist.png: TRUE=23  PRED=23\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step\n",
      "C:\\Users\\joann\\PycharmProjects\\Recog\\Preprocessed\\40_Single_preprocessed_Emnist.png: TRUE=12  PRED=12\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step\n",
      "C:\\Users\\joann\\PycharmProjects\\Recog\\Preprocessed\\41_Single_preprocessed_Emnist.png: TRUE=20  PRED=20\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step\n",
      "C:\\Users\\joann\\PycharmProjects\\Recog\\Preprocessed\\42_Single_preprocessed_Emnist.png: TRUE=18  PRED=18\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step\n",
      "C:\\Users\\joann\\PycharmProjects\\Recog\\Preprocessed\\43_Single_preprocessed_Emnist.png: TRUE=2  PRED=2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step\n",
      "C:\\Users\\joann\\PycharmProjects\\Recog\\Preprocessed\\44_Single_preprocessed_Emnist.png: TRUE=7  PRED=7\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step\n",
      "C:\\Users\\joann\\PycharmProjects\\Recog\\Preprocessed\\45_Single_preprocessed_Emnist.png: TRUE=12  PRED=12\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step\n",
      "C:\\Users\\joann\\PycharmProjects\\Recog\\Preprocessed\\46_Single_preprocessed_Emnist.png: TRUE=6  PRED=19\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step\n",
      "C:\\Users\\joann\\PycharmProjects\\Recog\\Preprocessed\\47_Single_preprocessed_Emnist.png: TRUE=3  PRED=3\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step\n",
      "C:\\Users\\joann\\PycharmProjects\\Recog\\Preprocessed\\48_Single_preprocessed_Emnist.png: TRUE=21  PRED=21\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step\n",
      "C:\\Users\\joann\\PycharmProjects\\Recog\\Preprocessed\\49_Single_preprocessed_Emnist.png: TRUE=24  PRED=24\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step\n",
      "C:\\Users\\joann\\PycharmProjects\\Recog\\Preprocessed\\50_Single_preprocessed_Emnist.png: TRUE=19  PRED=9\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step\n",
      "C:\\Users\\joann\\PycharmProjects\\Recog\\Preprocessed\\51_Single_preprocessed_Emnist.png: TRUE=23  PRED=23\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step\n",
      "C:\\Users\\joann\\PycharmProjects\\Recog\\Preprocessed\\52_Single_preprocessed_Emnist.png: TRUE=0  PRED=0\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step\n",
      "C:\\Users\\joann\\PycharmProjects\\Recog\\Preprocessed\\53_Single_preprocessed_Emnist.png: TRUE=13  PRED=13\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step\n",
      "C:\\Users\\joann\\PycharmProjects\\Recog\\Preprocessed\\54_Single_preprocessed_Emnist.png: TRUE=11  PRED=11\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step\n",
      "C:\\Users\\joann\\PycharmProjects\\Recog\\Preprocessed\\55_Single_preprocessed_Emnist.png: TRUE=4  PRED=4\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step\n",
      "C:\\Users\\joann\\PycharmProjects\\Recog\\Preprocessed\\56_Single_preprocessed_Emnist.png: TRUE=12  PRED=12\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step\n",
      "C:\\Users\\joann\\PycharmProjects\\Recog\\Preprocessed\\57_Single_preprocessed_Emnist.png: TRUE=6  PRED=18\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step\n",
      "C:\\Users\\joann\\PycharmProjects\\Recog\\Preprocessed\\58_Single_preprocessed_Emnist.png: TRUE=8  PRED=11\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step\n",
      "C:\\Users\\joann\\PycharmProjects\\Recog\\Preprocessed\\59_Single_preprocessed_Emnist.png: TRUE=4  PRED=4\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step\n",
      "C:\\Users\\joann\\PycharmProjects\\Recog\\Preprocessed\\60_Single_preprocessed_Emnist.png: TRUE=9  PRED=9\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step\n",
      "C:\\Users\\joann\\PycharmProjects\\Recog\\Preprocessed\\61_Single_preprocessed_Emnist.png: TRUE=20  PRED=20\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step\n",
      "C:\\Users\\joann\\PycharmProjects\\Recog\\Preprocessed\\62_Single_preprocessed_Emnist.png: TRUE=8  PRED=8\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step\n",
      "C:\\Users\\joann\\PycharmProjects\\Recog\\Preprocessed\\63_Single_preprocessed_Emnist.png: TRUE=2  PRED=2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step\n",
      "C:\\Users\\joann\\PycharmProjects\\Recog\\Preprocessed\\64_Single_preprocessed_Emnist.png: TRUE=13  PRED=13\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step\n",
      "C:\\Users\\joann\\PycharmProjects\\Recog\\Preprocessed\\65_Single_preprocessed_Emnist.png: TRUE=18  PRED=18\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step\n",
      "C:\\Users\\joann\\PycharmProjects\\Recog\\Preprocessed\\66_Single_preprocessed_Emnist.png: TRUE=2  PRED=2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step\n",
      "C:\\Users\\joann\\PycharmProjects\\Recog\\Preprocessed\\67_Single_preprocessed_Emnist.png: TRUE=1  PRED=18\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step\n",
      "C:\\Users\\joann\\PycharmProjects\\Recog\\Preprocessed\\68_Single_preprocessed_Emnist.png: TRUE=20  PRED=20\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step\n",
      "C:\\Users\\joann\\PycharmProjects\\Recog\\Preprocessed\\69_Single_preprocessed_Emnist.png: TRUE=25  PRED=25\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step\n",
      "C:\\Users\\joann\\PycharmProjects\\Recog\\Preprocessed\\70_Single_preprocessed_Emnist.png: TRUE=5  PRED=19\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step\n",
      "C:\\Users\\joann\\PycharmProjects\\Recog\\Preprocessed\\71_Single_preprocessed_Emnist.png: TRUE=3  PRED=3\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step\n",
      "C:\\Users\\joann\\PycharmProjects\\Recog\\Preprocessed\\72_Single_preprocessed_Emnist.png: TRUE=12  PRED=12\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step\n",
      "C:\\Users\\joann\\PycharmProjects\\Recog\\Preprocessed\\73_Single_preprocessed_Emnist.png: TRUE=11  PRED=2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step\n",
      "C:\\Users\\joann\\PycharmProjects\\Recog\\Preprocessed\\74_Single_preprocessed_Emnist.png: TRUE=5  PRED=19\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step\n",
      "C:\\Users\\joann\\PycharmProjects\\Recog\\Preprocessed\\75_Single_preprocessed_Emnist.png: TRUE=9  PRED=3\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step\n",
      "C:\\Users\\joann\\PycharmProjects\\Recog\\Preprocessed\\76_Single_preprocessed_Emnist.png: TRUE=15  PRED=3\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step\n",
      "C:\\Users\\joann\\PycharmProjects\\Recog\\Preprocessed\\77_Single_preprocessed_Emnist.png: TRUE=25  PRED=25\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step\n",
      "C:\\Users\\joann\\PycharmProjects\\Recog\\Preprocessed\\78_Single_preprocessed_Emnist.png: TRUE=10  PRED=10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step\n",
      "C:\\Users\\joann\\PycharmProjects\\Recog\\Preprocessed\\79_Single_preprocessed_Emnist.png: TRUE=17  PRED=4\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step\n",
      "C:\\Users\\joann\\PycharmProjects\\Recog\\Preprocessed\\80_Single_preprocessed_Emnist.png: TRUE=19  PRED=19\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step\n",
      "C:\\Users\\joann\\PycharmProjects\\Recog\\Preprocessed\\81_Single_preprocessed_Emnist.png: TRUE=18  PRED=18\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step\n",
      "C:\\Users\\joann\\PycharmProjects\\Recog\\Preprocessed\\82_Single_preprocessed_Emnist.png: TRUE=10  PRED=10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step\n",
      "C:\\Users\\joann\\PycharmProjects\\Recog\\Preprocessed\\83_Single_preprocessed_Emnist.png: TRUE=20  PRED=20\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step\n",
      "C:\\Users\\joann\\PycharmProjects\\Recog\\Preprocessed\\84_Single_preprocessed_Emnist.png: TRUE=3  PRED=3\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step\n",
      "C:\\Users\\joann\\PycharmProjects\\Recog\\Preprocessed\\85_Single_preprocessed_Emnist.png: TRUE=20  PRED=20\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step\n",
      "C:\\Users\\joann\\PycharmProjects\\Recog\\Preprocessed\\86_Single_preprocessed_Emnist.png: TRUE=14  PRED=14\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step\n",
      "C:\\Users\\joann\\PycharmProjects\\Recog\\Preprocessed\\87_Single_preprocessed_Emnist.png: TRUE=2  PRED=2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step\n",
      "C:\\Users\\joann\\PycharmProjects\\Recog\\Preprocessed\\88_Single_preprocessed_Emnist.png: TRUE=0  PRED=0\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step\n",
      "C:\\Users\\joann\\PycharmProjects\\Recog\\Preprocessed\\89_Single_preprocessed_Emnist.png: TRUE=2  PRED=2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step\n",
      "C:\\Users\\joann\\PycharmProjects\\Recog\\Preprocessed\\90_Single_preprocessed_Emnist.png: TRUE=12  PRED=12\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step\n",
      "C:\\Users\\joann\\PycharmProjects\\Recog\\Preprocessed\\91_Single_preprocessed_Emnist.png: TRUE=8  PRED=8\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step\n",
      "C:\\Users\\joann\\PycharmProjects\\Recog\\Preprocessed\\92_Single_preprocessed_Emnist.png: TRUE=9  PRED=9\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step\n",
      "C:\\Users\\joann\\PycharmProjects\\Recog\\Preprocessed\\93_Single_preprocessed_Emnist.png: TRUE=15  PRED=15\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step\n",
      "C:\\Users\\joann\\PycharmProjects\\Recog\\Preprocessed\\94_Single_preprocessed_Emnist.png: TRUE=17  PRED=15\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step\n",
      "C:\\Users\\joann\\PycharmProjects\\Recog\\Preprocessed\\95_Single_preprocessed_Emnist.png: TRUE=21  PRED=21\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step\n",
      "C:\\Users\\joann\\PycharmProjects\\Recog\\Preprocessed\\96_Single_preprocessed_Emnist.png: TRUE=2  PRED=2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step\n",
      "C:\\Users\\joann\\PycharmProjects\\Recog\\Preprocessed\\97_Single_preprocessed_Emnist.png: TRUE=0  PRED=0\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step\n",
      "C:\\Users\\joann\\PycharmProjects\\Recog\\Preprocessed\\98_Single_preprocessed_Emnist.png: TRUE=14  PRED=14\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step\n",
      "C:\\Users\\joann\\PycharmProjects\\Recog\\Preprocessed\\99_Single_preprocessed_Emnist.png: TRUE=3  PRED=3\n",
      "\n",
      "ACCURACY BEFORE REINFORCEMENT: 73.00% (73/100)\n",
      " Misclassified samples: 27\n",
      "\n",
      "🔁 Running reinforcement fine-tuning...\n",
      "Epoch 1/3\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step - accuracy: 0.0000e+00 - loss: 2.4791\n",
      "Epoch 2/3\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - accuracy: 0.2593 - loss: 2.1331\n",
      "Epoch 3/3\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 143ms/step - accuracy: 0.2593 - loss: 1.9010\n",
      "Reinforcement finished.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import cv2\n",
    "import numpy as np\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# -------------------- SETTINGS --------------------\n",
    "PREPROCESSED = r\"C:\\Users\\joann\\PycharmProjects\\Recog\\Preprocessed\"\n",
    "SEGMENTED = r\"C:\\Users\\joann\\PycharmProjects\\Recog\\Segmentation\"\n",
    "MODELS_DIR = r\"C:\\Users\\joann\\PycharmProjects\\Recog\\Models\"\n",
    "\n",
    "IMG_SIZE = (28, 28)\n",
    "EPOCHS_REINFORCE = 3  # small number for reinforcement\n",
    "\n",
    "# -------------------- IMAGE PREPROCESS --------------------\n",
    "def preprocess_image(img_path):\n",
    "    img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "    img = cv2.resize(img, IMG_SIZE)\n",
    "    img = img.astype(\"float32\") / 255.0\n",
    "    img = np.expand_dims(img, axis=-1)\n",
    "    return img\n",
    "\n",
    "# -------------------- REINFORCEMENT PREDICTION --------------------\n",
    "def reinforce_predict(folder, json_file, model):\n",
    "    with open(json_file, \"r\") as jf:\n",
    "        data = json.load(jf)\n",
    "\n",
    "    misclassified_imgs = []\n",
    "    misclassified_labels = []\n",
    "\n",
    "    total, correct = 0, 0\n",
    "    for item in data:\n",
    "        title = item.get(\"Title\")\n",
    "        chars = item.get(\"Chars\")\n",
    "        if not title or not chars:\n",
    "            continue\n",
    "\n",
    "        png_path = os.path.join(folder, f\"{title}.png\")\n",
    "        if not os.path.exists(png_path):\n",
    "            print(\"Missing PNG:\", png_path)\n",
    "            continue\n",
    "\n",
    "        true_label = int(chars[0])\n",
    "        img = preprocess_image(png_path)\n",
    "        pred = np.argmax(model.predict(np.expand_dims(img, 0)), axis=1)[0]\n",
    "\n",
    "        total += 1\n",
    "        if pred == true_label:\n",
    "            correct += 1\n",
    "        else:\n",
    "            misclassified_imgs.append(img)\n",
    "            misclassified_labels.append(true_label)\n",
    "\n",
    "        print(f\"{png_path}: TRUE={true_label}  PRED={pred}\")\n",
    "\n",
    "    print(f\"\\nACCURACY BEFORE REINFORCEMENT: {correct/total*100:.2f}% ({correct}/{total})\")\n",
    "    print(f\" Misclassified samples: {len(misclassified_imgs)}\")\n",
    "\n",
    "    # -------------------- REINFORCEMENT TRAINING --------------------\n",
    "    if misclassified_imgs:\n",
    "        X_reinforce = np.array(misclassified_imgs)\n",
    "        y_reinforce = to_categorical(misclassified_labels, num_classes=model.output_shape[-1])\n",
    "\n",
    "        print(\"\\n🔁 Running reinforcement fine-tuning...\")\n",
    "        model.fit(X_reinforce, y_reinforce, epochs=EPOCHS_REINFORCE, verbose=1)\n",
    "\n",
    "    print(\"Reinforcement finished.\\n\")\n",
    "    return model\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "model_path = os.path.join(MODELS_DIR, \"emnist_cnn.keras\")\n",
    "model = load_model(model_path)\n",
    "\n",
    "json_file = os.path.join(PREPROCESSED, \"Single_Emnist_labels.json\")\n",
    "model = reinforce_predict(PREPROCESSED, json_file, model)\n",
    "\n",
    "# Save the updated model\n",
    "model.save(os.path.join(MODELS_DIR, \"emnist_cnn.keras\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db040c63ee97cf5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-01T04:18:11.460063Z",
     "start_time": "2025-11-01T04:18:11.456685Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cd363cd0e48b154",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
