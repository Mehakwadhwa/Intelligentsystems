{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ivP9iahYhY5_",
    "outputId": "987f485c-3e06-427f-86ca-edabd98d24d3"
   },
   "outputs": [],
   "source": [
    "#!pip install tensorflow-datasets\n",
    "import os\n",
    "from pathlib import Path\n",
    "import cv2 #OpenCV for image processing-- read,write transform\n",
    "import numpy as np# image handling\n",
    "from tensorflow.keras.datasets import mnist# just the main bitch\n",
    "import tensorflow_datasets as tfds\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qkdh6yxzQmiF"
   },
   "source": [
    "#Pre-Processing\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Weird fucking issue\n",
    "#Wanted mutiple numbers in a thing\n",
    "#decided fuck you i cant give a shit \n",
    "#Load the number muncher\n",
    "#THIS SECTION HAS REFERENCE CHATGBT \n",
    "#AS PER THE REQUIRMEENTS IN THE SYLLABUS I AM ACKNOLWEDGING ITS ASSISTANCE AND WILL LINK IN REPORT\n",
    "\n",
    "#https://chatgpt.com/share/68ca428f-7efc-800b-9fa5-3e4a7afdec98\n",
    "\n",
    "\n",
    "#issue numbr 2\n",
    "#NOW THAT THERE IS MORE\n",
    "#WE NEED TO MAKE SURE WE CAN SEGEMENT INTO PARTS LIKE\n",
    "#EACH BLOCK IS 28 X 28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Please choose how many images 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Task 1 complete! Preprocessed images are in: C:\\Users\\yugaa\\Documents\\Intelligentsystems\\notebooks\\Preprocessed\n"
     ]
    }
   ],
   "source": [
    "#Weird fucking issue\n",
    "#Wanted mutiple numbers in a thing\n",
    "#decided fuck you i cant give a shit \n",
    "#Load the number muncher\n",
    "#THIS SECTION HAS REFERENCE CHATGBT \n",
    "#AS PER THE REQUIRMEENTS IN THE SYLLABUS I AM ACKNOLWEDGING ITS ASSISTANCE AND WILL LINK IN REPORT\n",
    "BASE_DIR = Path(os.getcwd())\n",
    "\n",
    "OUT_DIR  = BASE_DIR /\"Preprocessed\"\n",
    "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "#https://chatgpt.com/share/68ca428f-7efc-800b-9fa5-3e4a7afdec98\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "def mutiple_numbers(x,y,num_images, max_digits=10):\n",
    "    imgs=[]\n",
    "    labels=[]\n",
    "    for i in range(num_images):\n",
    "        digits_per_image = np.random.randint(1, max_digits + 1)\n",
    "        #Random man selects in dices\n",
    "        ints= np.random.randint(0, len(x), digits_per_image) \n",
    "        chosen_digits=[x[idx]for idx in ints]\n",
    "        chosen_labels=[y[idx]for idx in ints]\n",
    "        #Stack them like pringles\n",
    "        img=np.hstack(chosen_digits)\n",
    "        #There was a issue with cutting off parts to fix this issue The trees spoke to me\n",
    "\n",
    "        imgs.append(img)\n",
    "        labels.append(tuple(chosen_labels))#dont ask\n",
    "        print(f\"Generated {len(imgs)} images\")\n",
    "\n",
    "    return imgs,labels\n",
    "\n",
    "# Generate 10 combined images\n",
    "#imgs, labels = mutiple_numbers(x_train, y_train, num_images, max_digits=10)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#issue numbr 2\n",
    "#NOW THAT THERE IS MORE\n",
    "#WE NEED TO MAKE SURE WE CAN SEGEMENT INTO PARTS LIKE\n",
    "#EACH BLOCK IS 28 X 28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "XbnON2lo0kQL"
   },
   "outputs": [],
   "source": [
    "#To avoid unnessary code rewrite\n",
    "df_train, df_test=tfds.load(\n",
    "    'omniglot',\n",
    "    split=['train','test'],\n",
    "    as_supervised=True\n",
    ")\n",
    "imgs,labels=[],[]\n",
    "for img,lab in tfds.as_numpy(df_train):\n",
    "    imgs.append(img)\n",
    "    labels.append(lab)\n",
    "X=np.array(imgs)\n",
    "y=np.array(labels)\n",
    "#Dataset split\n",
    "#https://stackoverflow.com/questions/47321709/how-to-split-train-and-test-dataset-to-x-train-y-train-and-x-test-y-test\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Be3kmRL1jLuR",
    "outputId": "428b885e-f497-46c6-cccf-af00ff6fa6eb"
   },
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Please select a dataset[0,1,2]1=Create new images 1\n",
      "Please choose how many images 33\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Task 1 complete! Preprocessed images are in: C:\\Users\\yugaa\\Documents\\Intelligentsystems\\notebooks\\Preprocessed\n",
      "\n",
      "Task 1 complete! Preprocessed images are in: C:\\Users\\yugaa\\Documents\\Intelligentsystems\\notebooks\\Preprocessed\n"
     ]
    }
   ],
   "source": [
    "BASE_DIR = Path(os.getcwd())\n",
    "\n",
    "OUT_DIR  = BASE_DIR /\"Preprocessed\"\n",
    "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "#preprocessing function area\n",
    "def preprocess_single(img_bgr, out_size=128, pad=10):# expect 3channel BGR image- out size as 128x 128 pixel pad is just padding\n",
    "    \"\"\"\n",
    "      Preprocess one image:\n",
    "      1. Convert to grayscale\n",
    "      2. Threshold to binary (digits white on black)\n",
    "      3. Crop -> center pad -> resize to out_size (default 128x128)\n",
    "      Returns: preprocessed image (uint8)\n",
    "      \"\"\"\n",
    "    # --- Grayscale ---\n",
    "    gray=cv2.cvtColor(img_bgr,cv2.COLOR_BGR2GRAY)#convert 3 channel BGR to 1 channel grayscale IN DOCUMENTATION REPORT LOGIC IS MOST DIGIT REC MODESL DONT NEED COLOUR\n",
    "#There was a issue with loading Mnist from keras, and using opencv  as it expected 8bit grayscale\n",
    "#gray was a float not a uint8 so i had to convert it so opencv would accept it\n",
    "    if gray.dtype != \"uint8\":\n",
    "       gray=(gray* 255).astype(\"uint8\")\n",
    "\n",
    "    # --- Adaptive threshold (digits white on black) ---\n",
    "    bw = cv2.adaptiveThreshold(gray, 255,\n",
    "                               cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\n",
    "                               cv2.THRESH_BINARY_INV,\n",
    "                               25, 10)# works like this: Convert to gray-> use a adaptive threshold to handle any uneven lighting(The simple thres was a asshole to work with) the thresh binary part inverts images so digits become WHITE(THIS IS A COMMON PRACTISE IN MACHINE LEARNING LOOK AT PAPER E4)\n",
    "    '''Remeber BW= Binary image ys=row indices of white pixels and xs= column indices of white pixels'''\n",
    "\n",
    "    # --- Tight crop around digits ---\n",
    "    ys, xs = np.where(bw > 0)\n",
    "    if xs.size and ys.size:\n",
    "        x0,x1=xs.min(),xs.max()#left edge of digit, right edge of digit\n",
    "        y0,y1=ys.min(),ys.max()#top edge of digit, bottom edge of digit\n",
    "        tight=bw[y0:y1+1,x0:x1+1]#Removes all unnessary black background and focuses only on the digit by cropping the image to the defined rectangle\n",
    "    else:\n",
    "        tight=bw #Troubleshooter ensures array always returns even if none found\n",
    "\n",
    "    # --- Center pad to square ---\n",
    "    digit_height,digit_width=tight.shape\n",
    "    canvas_side = max(digit_height, digit_width) + 2 * pad\n",
    "    padded_canvas = np.zeros((canvas_side, canvas_side), dtype=np.uint8)#make the empty\n",
    "    # offset calculations to center on the canvas\n",
    "    yoffset=(canvas_side-digit_height)//2\n",
    "    xoffset=(canvas_side -digit_width)//2\n",
    "    padded_canvas[yoffset:yoffset+digit_height,xoffset:xoffset+digit_width]=tight\n",
    "    # --- Resize to fixed size (default 128x128) ---\n",
    "    resized = cv2.resize(padded_canvas, (out_size, out_size), interpolation=cv2.INTER_AREA)# resize to 128x128 and the inter-area acts like scale feature in css,\n",
    "    return resized\n",
    "#ML models need consistent image sizing that is why it is resized that is important mention report in basic part.\n",
    "\n",
    "dataset_testing=int(input(\"Please select a dataset[0,1,2]1=Create new images\"))\n",
    "if dataset_testing ==  0:\n",
    "  #Load mnist  images and labels into training data\n",
    "  #This will allow near 60k trainign images and around 10k test images, without having to use the kraggle repository and enaring with crosiant\n",
    "  (x_train,y_train),(x_test,y_test)=mnist.load_data()\n",
    "  print(\"Training Images: \", x_train.shape)#x train is image of a digit\n",
    "  print(\"Training Labels: \",y_train.shape) # y_train is the label of the digit aka 0-9\n",
    "  x_train = x_train.astype('float32') / 255.0\n",
    "  x_test = x_test.astype('float32') / 255.0\n",
    "  #ADDED ONE HOT ENCODING--------vital for bin\n",
    "  y_train_cat=to_categorical(y_train, num_classes=10)\n",
    "  y_test_cat =to_categorical(y_test, num_classes=10)\n",
    "    \n",
    "# ---------- Run preprocessing and save----------\n",
    "  which_nums_processing=100#SET TO 100 because its small  this is a test mech\n",
    "  for i in range(which_nums_processing):\n",
    "    #img_gray = x_train[i]#must be SQUARE LINES NOT THE BRACKETS OR ELSE IT WILL SAY OBECJT NOT CALLABLE!!!!!\n",
    "  #  img_bgr = cv2.cvtColor(img_gray, cv2.COLOR_GRAY2BGR) #convert to BGR so its compatible with the preprocesser function\n",
    "    #send to preprocess\n",
    "      img = x_train[i]\n",
    "      if len(img.shape) == 2:  # grayscale\n",
    "        img_bgr = cv2.cvtColor(img, cv2.COLOR_GRAY2BGR)\n",
    "      elif len(img.shape) == 3 and img.shape[2] == 3:  # already BGR/RGB\n",
    "        img_bgr = img.copy()\n",
    "      else:\n",
    "        raise ValueError(f\"Unexpected image shape: {img.shape}\")\n",
    "  pre_img = preprocess_single(img_bgr, out_size=128)   # <--- made images bigger\n",
    "  # Save output PNG\n",
    "  out_png = OUT_DIR / f\"img_{i}_preprocessed.png\"\n",
    "  cv2.imwrite(out_png, pre_img)\n",
    "  print(f\"[OK] Image {i}: saved {out_png}\")\n",
    "\n",
    "if dataset_testing == 1:\n",
    "    num_images=int(input(\"Please choose how many images\"))\n",
    "    mutiple_numbers(x_train, y_train, num_images, max_digits=10)\n",
    "     # Visualize only 4\n",
    "    for i, img in enumerate(imgs):\n",
    "        pre_img = img.astype(np.uint8)\n",
    "        out_png = OUT_DIR / f\"img_{i}_preprocessed.png\"\n",
    "        cv2.imwrite(str(out_png), pre_img)\n",
    "    print(f\"\\nTask 1 complete! Preprocessed images are in: {OUT_DIR}\")\n",
    "    \n",
    "\n",
    "\n",
    "elif dataset_testing == 2:\n",
    "    #To avoid unnessary code rewrite\n",
    "  df_train, df_test=tfds.load(\n",
    "      'omniglot',\n",
    "      split=['train','test'],\n",
    "      as_supervised=True\n",
    "  )\n",
    "  x_train,y_train=[],[]\n",
    "  for img, lab in tfds.as_numpy(df_train):\n",
    "    x_train.append(img)\n",
    "    y_train.append(lab)\n",
    "  x_train,y_train=np.array(x_train),np.array(y_train)\n",
    "\n",
    "  #append img and labels to test instances\n",
    "  x_test,y_test=[],[]\n",
    "\n",
    "  for img,lab in tfds.as_numpy(df_test):\n",
    "      x_test.append(img)\n",
    "      y_test.append(lab)\n",
    "x_test,y_test=np.array(x_test),np.array(y_test)\n",
    "  #Dataset split\n",
    "  #https://stackoverflow.com/questions/47321709/how-to-split-train-and-test-dataset-to-x-train-y-train-and-x-test-y-test\n",
    "\n",
    "#this is incomplete\n",
    "def preprocess_letters(img, out=28):\n",
    "  #resize\n",
    "  img_resized=cv2.resize(img,(out,out))\n",
    "  #grayscale convert\n",
    "  if len(img_resized.shape)==3 and img_resized.shape[-1]==3:\n",
    "    img_resized=cv2.cvtColor(img_resized,cv2.COLOR_RGB2GRAY)\n",
    "  #normalize 0-1\n",
    "  img_resized=img_resized.astype(\"float32\")/255.0\n",
    "  return img_resized\n",
    "x_train = np.array([preprocess_letters(img) for img in x_train])\n",
    "x_test  = np.array([preprocess_letters(img) for img in x_test])\n",
    "\n",
    "\n",
    "\n",
    "#Loop over extensions, Build path, check file exists, return if path found else return none\n",
    "\n",
    "def find_image(idx):\n",
    "    \"\"\"Return path for numbered file with common extensions.\"\"\"\n",
    "    for ext in (\".jpg\", \".jpeg\", \".png\", \".webp\"):\n",
    "        p = os.path.join(BASE_DIR, f\"{idx}{ext}\")\n",
    "      ##      return p\n",
    "    return None\n",
    "\n",
    "\n",
    "print(f\"\\nTask 1 complete! Preprocessed images are in: {OUT_DIR}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tFhZBkdZwIvp"
   },
   "outputs": [],
   "source": [
    "#CLEAN AND PREPROCESS THE DATA\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H6gCwzKSRUfQ"
   },
   "source": [
    "#Segmentation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dx4LPEQTofBn",
    "outputId": "8a426664-9c33-4011-9162-b29286007529"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] image1_preprocessed.png: 4 digits detected → C:\\Users\\yugaa\\Documents\\Intelligentsystems\\notebooks\\segmentation\\image1_preprocessed_boxes.png\n",
      "[OK] image2_preprocessed.png: 3 digits detected → C:\\Users\\yugaa\\Documents\\Intelligentsystems\\notebooks\\segmentation\\image2_preprocessed_boxes.png\n",
      "[OK] image3_preprocessed.png: 2 digits detected → C:\\Users\\yugaa\\Documents\\Intelligentsystems\\notebooks\\segmentation\\image3_preprocessed_boxes.png\n",
      "[OK] image4_preprocessed.png: 3 digits detected → C:\\Users\\yugaa\\Documents\\Intelligentsystems\\notebooks\\segmentation\\image4_preprocessed_boxes.png\n",
      "[OK] image5_preprocessed.png: 4 digits detected → C:\\Users\\yugaa\\Documents\\Intelligentsystems\\notebooks\\segmentation\\image5_preprocessed_boxes.png\n",
      "[OK] image6_preprocessed.png: 5 digits detected → C:\\Users\\yugaa\\Documents\\Intelligentsystems\\notebooks\\segmentation\\image6_preprocessed_boxes.png\n",
      "[OK] img_0_preprocessed.png: 0 digits detected → C:\\Users\\yugaa\\Documents\\Intelligentsystems\\notebooks\\segmentation\\img_0_preprocessed_boxes.png\n",
      "[OK] img_10_preprocessed.png: 0 digits detected → C:\\Users\\yugaa\\Documents\\Intelligentsystems\\notebooks\\segmentation\\img_10_preprocessed_boxes.png\n",
      "[OK] img_11_preprocessed.png: 0 digits detected → C:\\Users\\yugaa\\Documents\\Intelligentsystems\\notebooks\\segmentation\\img_11_preprocessed_boxes.png\n",
      "[OK] img_12_preprocessed.png: 0 digits detected → C:\\Users\\yugaa\\Documents\\Intelligentsystems\\notebooks\\segmentation\\img_12_preprocessed_boxes.png\n",
      "[OK] img_13_preprocessed.png: 0 digits detected → C:\\Users\\yugaa\\Documents\\Intelligentsystems\\notebooks\\segmentation\\img_13_preprocessed_boxes.png\n",
      "[OK] img_14_preprocessed.png: 0 digits detected → C:\\Users\\yugaa\\Documents\\Intelligentsystems\\notebooks\\segmentation\\img_14_preprocessed_boxes.png\n",
      "[OK] img_15_preprocessed.png: 0 digits detected → C:\\Users\\yugaa\\Documents\\Intelligentsystems\\notebooks\\segmentation\\img_15_preprocessed_boxes.png\n",
      "[OK] img_16_preprocessed.png: 0 digits detected → C:\\Users\\yugaa\\Documents\\Intelligentsystems\\notebooks\\segmentation\\img_16_preprocessed_boxes.png\n",
      "[OK] img_17_preprocessed.png: 0 digits detected → C:\\Users\\yugaa\\Documents\\Intelligentsystems\\notebooks\\segmentation\\img_17_preprocessed_boxes.png\n",
      "[OK] img_18_preprocessed.png: 0 digits detected → C:\\Users\\yugaa\\Documents\\Intelligentsystems\\notebooks\\segmentation\\img_18_preprocessed_boxes.png\n",
      "[OK] img_19_preprocessed.png: 0 digits detected → C:\\Users\\yugaa\\Documents\\Intelligentsystems\\notebooks\\segmentation\\img_19_preprocessed_boxes.png\n",
      "[OK] img_1_preprocessed.png: 0 digits detected → C:\\Users\\yugaa\\Documents\\Intelligentsystems\\notebooks\\segmentation\\img_1_preprocessed_boxes.png\n",
      "[OK] img_20_preprocessed.png: 0 digits detected → C:\\Users\\yugaa\\Documents\\Intelligentsystems\\notebooks\\segmentation\\img_20_preprocessed_boxes.png\n",
      "[OK] img_21_preprocessed.png: 0 digits detected → C:\\Users\\yugaa\\Documents\\Intelligentsystems\\notebooks\\segmentation\\img_21_preprocessed_boxes.png\n",
      "[OK] img_22_preprocessed.png: 0 digits detected → C:\\Users\\yugaa\\Documents\\Intelligentsystems\\notebooks\\segmentation\\img_22_preprocessed_boxes.png\n",
      "[OK] img_23_preprocessed.png: 0 digits detected → C:\\Users\\yugaa\\Documents\\Intelligentsystems\\notebooks\\segmentation\\img_23_preprocessed_boxes.png\n",
      "[OK] img_24_preprocessed.png: 0 digits detected → C:\\Users\\yugaa\\Documents\\Intelligentsystems\\notebooks\\segmentation\\img_24_preprocessed_boxes.png\n",
      "[OK] img_25_preprocessed.png: 0 digits detected → C:\\Users\\yugaa\\Documents\\Intelligentsystems\\notebooks\\segmentation\\img_25_preprocessed_boxes.png\n",
      "[OK] img_26_preprocessed.png: 0 digits detected → C:\\Users\\yugaa\\Documents\\Intelligentsystems\\notebooks\\segmentation\\img_26_preprocessed_boxes.png\n",
      "[OK] img_27_preprocessed.png: 0 digits detected → C:\\Users\\yugaa\\Documents\\Intelligentsystems\\notebooks\\segmentation\\img_27_preprocessed_boxes.png\n",
      "[OK] img_28_preprocessed.png: 0 digits detected → C:\\Users\\yugaa\\Documents\\Intelligentsystems\\notebooks\\segmentation\\img_28_preprocessed_boxes.png\n",
      "[OK] img_29_preprocessed.png: 0 digits detected → C:\\Users\\yugaa\\Documents\\Intelligentsystems\\notebooks\\segmentation\\img_29_preprocessed_boxes.png\n",
      "[OK] img_2_preprocessed.png: 0 digits detected → C:\\Users\\yugaa\\Documents\\Intelligentsystems\\notebooks\\segmentation\\img_2_preprocessed_boxes.png\n",
      "[OK] img_30_preprocessed.png: 0 digits detected → C:\\Users\\yugaa\\Documents\\Intelligentsystems\\notebooks\\segmentation\\img_30_preprocessed_boxes.png\n",
      "[OK] img_31_preprocessed.png: 0 digits detected → C:\\Users\\yugaa\\Documents\\Intelligentsystems\\notebooks\\segmentation\\img_31_preprocessed_boxes.png\n",
      "[OK] img_32_preprocessed.png: 0 digits detected → C:\\Users\\yugaa\\Documents\\Intelligentsystems\\notebooks\\segmentation\\img_32_preprocessed_boxes.png\n",
      "[OK] img_33_preprocessed.png: 0 digits detected → C:\\Users\\yugaa\\Documents\\Intelligentsystems\\notebooks\\segmentation\\img_33_preprocessed_boxes.png\n",
      "[OK] img_34_preprocessed.png: 0 digits detected → C:\\Users\\yugaa\\Documents\\Intelligentsystems\\notebooks\\segmentation\\img_34_preprocessed_boxes.png\n",
      "[OK] img_35_preprocessed.png: 0 digits detected → C:\\Users\\yugaa\\Documents\\Intelligentsystems\\notebooks\\segmentation\\img_35_preprocessed_boxes.png\n",
      "[OK] img_36_preprocessed.png: 0 digits detected → C:\\Users\\yugaa\\Documents\\Intelligentsystems\\notebooks\\segmentation\\img_36_preprocessed_boxes.png\n",
      "[OK] img_37_preprocessed.png: 0 digits detected → C:\\Users\\yugaa\\Documents\\Intelligentsystems\\notebooks\\segmentation\\img_37_preprocessed_boxes.png\n",
      "[OK] img_38_preprocessed.png: 0 digits detected → C:\\Users\\yugaa\\Documents\\Intelligentsystems\\notebooks\\segmentation\\img_38_preprocessed_boxes.png\n",
      "[OK] img_39_preprocessed.png: 0 digits detected → C:\\Users\\yugaa\\Documents\\Intelligentsystems\\notebooks\\segmentation\\img_39_preprocessed_boxes.png\n",
      "[OK] img_3_preprocessed.png: 0 digits detected → C:\\Users\\yugaa\\Documents\\Intelligentsystems\\notebooks\\segmentation\\img_3_preprocessed_boxes.png\n",
      "[OK] img_40_preprocessed.png: 0 digits detected → C:\\Users\\yugaa\\Documents\\Intelligentsystems\\notebooks\\segmentation\\img_40_preprocessed_boxes.png\n",
      "[OK] img_41_preprocessed.png: 0 digits detected → C:\\Users\\yugaa\\Documents\\Intelligentsystems\\notebooks\\segmentation\\img_41_preprocessed_boxes.png\n",
      "[OK] img_42_preprocessed.png: 0 digits detected → C:\\Users\\yugaa\\Documents\\Intelligentsystems\\notebooks\\segmentation\\img_42_preprocessed_boxes.png\n",
      "[OK] img_43_preprocessed.png: 0 digits detected → C:\\Users\\yugaa\\Documents\\Intelligentsystems\\notebooks\\segmentation\\img_43_preprocessed_boxes.png\n",
      "[OK] img_44_preprocessed.png: 0 digits detected → C:\\Users\\yugaa\\Documents\\Intelligentsystems\\notebooks\\segmentation\\img_44_preprocessed_boxes.png\n",
      "[OK] img_45_preprocessed.png: 0 digits detected → C:\\Users\\yugaa\\Documents\\Intelligentsystems\\notebooks\\segmentation\\img_45_preprocessed_boxes.png\n",
      "[OK] img_46_preprocessed.png: 0 digits detected → C:\\Users\\yugaa\\Documents\\Intelligentsystems\\notebooks\\segmentation\\img_46_preprocessed_boxes.png\n",
      "[OK] img_47_preprocessed.png: 0 digits detected → C:\\Users\\yugaa\\Documents\\Intelligentsystems\\notebooks\\segmentation\\img_47_preprocessed_boxes.png\n",
      "[OK] img_48_preprocessed.png: 0 digits detected → C:\\Users\\yugaa\\Documents\\Intelligentsystems\\notebooks\\segmentation\\img_48_preprocessed_boxes.png\n",
      "[OK] img_49_preprocessed.png: 0 digits detected → C:\\Users\\yugaa\\Documents\\Intelligentsystems\\notebooks\\segmentation\\img_49_preprocessed_boxes.png\n",
      "[OK] img_4_preprocessed.png: 0 digits detected → C:\\Users\\yugaa\\Documents\\Intelligentsystems\\notebooks\\segmentation\\img_4_preprocessed_boxes.png\n",
      "[OK] img_50_preprocessed.png: 0 digits detected → C:\\Users\\yugaa\\Documents\\Intelligentsystems\\notebooks\\segmentation\\img_50_preprocessed_boxes.png\n",
      "[OK] img_51_preprocessed.png: 0 digits detected → C:\\Users\\yugaa\\Documents\\Intelligentsystems\\notebooks\\segmentation\\img_51_preprocessed_boxes.png\n",
      "[OK] img_52_preprocessed.png: 0 digits detected → C:\\Users\\yugaa\\Documents\\Intelligentsystems\\notebooks\\segmentation\\img_52_preprocessed_boxes.png\n",
      "[OK] img_53_preprocessed.png: 0 digits detected → C:\\Users\\yugaa\\Documents\\Intelligentsystems\\notebooks\\segmentation\\img_53_preprocessed_boxes.png\n",
      "[OK] img_54_preprocessed.png: 0 digits detected → C:\\Users\\yugaa\\Documents\\Intelligentsystems\\notebooks\\segmentation\\img_54_preprocessed_boxes.png\n",
      "[OK] img_55_preprocessed.png: 0 digits detected → C:\\Users\\yugaa\\Documents\\Intelligentsystems\\notebooks\\segmentation\\img_55_preprocessed_boxes.png\n",
      "[OK] img_56_preprocessed.png: 0 digits detected → C:\\Users\\yugaa\\Documents\\Intelligentsystems\\notebooks\\segmentation\\img_56_preprocessed_boxes.png\n",
      "[OK] img_57_preprocessed.png: 0 digits detected → C:\\Users\\yugaa\\Documents\\Intelligentsystems\\notebooks\\segmentation\\img_57_preprocessed_boxes.png\n",
      "[OK] img_58_preprocessed.png: 0 digits detected → C:\\Users\\yugaa\\Documents\\Intelligentsystems\\notebooks\\segmentation\\img_58_preprocessed_boxes.png\n",
      "[OK] img_59_preprocessed.png: 0 digits detected → C:\\Users\\yugaa\\Documents\\Intelligentsystems\\notebooks\\segmentation\\img_59_preprocessed_boxes.png\n",
      "[OK] img_5_preprocessed.png: 0 digits detected → C:\\Users\\yugaa\\Documents\\Intelligentsystems\\notebooks\\segmentation\\img_5_preprocessed_boxes.png\n",
      "[OK] img_60_preprocessed.png: 0 digits detected → C:\\Users\\yugaa\\Documents\\Intelligentsystems\\notebooks\\segmentation\\img_60_preprocessed_boxes.png\n",
      "[OK] img_61_preprocessed.png: 0 digits detected → C:\\Users\\yugaa\\Documents\\Intelligentsystems\\notebooks\\segmentation\\img_61_preprocessed_boxes.png\n",
      "[OK] img_62_preprocessed.png: 0 digits detected → C:\\Users\\yugaa\\Documents\\Intelligentsystems\\notebooks\\segmentation\\img_62_preprocessed_boxes.png\n",
      "[OK] img_63_preprocessed.png: 0 digits detected → C:\\Users\\yugaa\\Documents\\Intelligentsystems\\notebooks\\segmentation\\img_63_preprocessed_boxes.png\n",
      "[OK] img_64_preprocessed.png: 0 digits detected → C:\\Users\\yugaa\\Documents\\Intelligentsystems\\notebooks\\segmentation\\img_64_preprocessed_boxes.png\n",
      "[OK] img_65_preprocessed.png: 0 digits detected → C:\\Users\\yugaa\\Documents\\Intelligentsystems\\notebooks\\segmentation\\img_65_preprocessed_boxes.png\n",
      "[OK] img_66_preprocessed.png: 0 digits detected → C:\\Users\\yugaa\\Documents\\Intelligentsystems\\notebooks\\segmentation\\img_66_preprocessed_boxes.png\n",
      "[OK] img_67_preprocessed.png: 0 digits detected → C:\\Users\\yugaa\\Documents\\Intelligentsystems\\notebooks\\segmentation\\img_67_preprocessed_boxes.png\n",
      "[OK] img_68_preprocessed.png: 0 digits detected → C:\\Users\\yugaa\\Documents\\Intelligentsystems\\notebooks\\segmentation\\img_68_preprocessed_boxes.png\n",
      "[OK] img_69_preprocessed.png: 0 digits detected → C:\\Users\\yugaa\\Documents\\Intelligentsystems\\notebooks\\segmentation\\img_69_preprocessed_boxes.png\n",
      "[OK] img_6_preprocessed.png: 0 digits detected → C:\\Users\\yugaa\\Documents\\Intelligentsystems\\notebooks\\segmentation\\img_6_preprocessed_boxes.png\n",
      "[OK] img_70_preprocessed.png: 0 digits detected → C:\\Users\\yugaa\\Documents\\Intelligentsystems\\notebooks\\segmentation\\img_70_preprocessed_boxes.png\n",
      "[OK] img_71_preprocessed.png: 0 digits detected → C:\\Users\\yugaa\\Documents\\Intelligentsystems\\notebooks\\segmentation\\img_71_preprocessed_boxes.png\n",
      "[OK] img_72_preprocessed.png: 0 digits detected → C:\\Users\\yugaa\\Documents\\Intelligentsystems\\notebooks\\segmentation\\img_72_preprocessed_boxes.png\n",
      "[OK] img_73_preprocessed.png: 0 digits detected → C:\\Users\\yugaa\\Documents\\Intelligentsystems\\notebooks\\segmentation\\img_73_preprocessed_boxes.png\n",
      "[OK] img_74_preprocessed.png: 0 digits detected → C:\\Users\\yugaa\\Documents\\Intelligentsystems\\notebooks\\segmentation\\img_74_preprocessed_boxes.png\n",
      "[OK] img_75_preprocessed.png: 0 digits detected → C:\\Users\\yugaa\\Documents\\Intelligentsystems\\notebooks\\segmentation\\img_75_preprocessed_boxes.png\n",
      "[OK] img_76_preprocessed.png: 0 digits detected → C:\\Users\\yugaa\\Documents\\Intelligentsystems\\notebooks\\segmentation\\img_76_preprocessed_boxes.png\n",
      "[OK] img_77_preprocessed.png: 0 digits detected → C:\\Users\\yugaa\\Documents\\Intelligentsystems\\notebooks\\segmentation\\img_77_preprocessed_boxes.png\n",
      "[OK] img_78_preprocessed.png: 0 digits detected → C:\\Users\\yugaa\\Documents\\Intelligentsystems\\notebooks\\segmentation\\img_78_preprocessed_boxes.png\n",
      "[OK] img_79_preprocessed.png: 0 digits detected → C:\\Users\\yugaa\\Documents\\Intelligentsystems\\notebooks\\segmentation\\img_79_preprocessed_boxes.png\n",
      "[OK] img_7_preprocessed.png: 0 digits detected → C:\\Users\\yugaa\\Documents\\Intelligentsystems\\notebooks\\segmentation\\img_7_preprocessed_boxes.png\n",
      "[OK] img_80_preprocessed.png: 0 digits detected → C:\\Users\\yugaa\\Documents\\Intelligentsystems\\notebooks\\segmentation\\img_80_preprocessed_boxes.png\n",
      "[OK] img_81_preprocessed.png: 0 digits detected → C:\\Users\\yugaa\\Documents\\Intelligentsystems\\notebooks\\segmentation\\img_81_preprocessed_boxes.png\n",
      "[OK] img_82_preprocessed.png: 0 digits detected → C:\\Users\\yugaa\\Documents\\Intelligentsystems\\notebooks\\segmentation\\img_82_preprocessed_boxes.png\n",
      "[OK] img_83_preprocessed.png: 0 digits detected → C:\\Users\\yugaa\\Documents\\Intelligentsystems\\notebooks\\segmentation\\img_83_preprocessed_boxes.png\n",
      "[OK] img_84_preprocessed.png: 0 digits detected → C:\\Users\\yugaa\\Documents\\Intelligentsystems\\notebooks\\segmentation\\img_84_preprocessed_boxes.png\n",
      "[OK] img_85_preprocessed.png: 0 digits detected → C:\\Users\\yugaa\\Documents\\Intelligentsystems\\notebooks\\segmentation\\img_85_preprocessed_boxes.png\n",
      "[OK] img_86_preprocessed.png: 0 digits detected → C:\\Users\\yugaa\\Documents\\Intelligentsystems\\notebooks\\segmentation\\img_86_preprocessed_boxes.png\n",
      "[OK] img_87_preprocessed.png: 0 digits detected → C:\\Users\\yugaa\\Documents\\Intelligentsystems\\notebooks\\segmentation\\img_87_preprocessed_boxes.png\n",
      "[OK] img_88_preprocessed.png: 0 digits detected → C:\\Users\\yugaa\\Documents\\Intelligentsystems\\notebooks\\segmentation\\img_88_preprocessed_boxes.png\n",
      "[OK] img_89_preprocessed.png: 0 digits detected → C:\\Users\\yugaa\\Documents\\Intelligentsystems\\notebooks\\segmentation\\img_89_preprocessed_boxes.png\n",
      "[OK] img_8_preprocessed.png: 0 digits detected → C:\\Users\\yugaa\\Documents\\Intelligentsystems\\notebooks\\segmentation\\img_8_preprocessed_boxes.png\n",
      "[OK] img_90_preprocessed.png: 0 digits detected → C:\\Users\\yugaa\\Documents\\Intelligentsystems\\notebooks\\segmentation\\img_90_preprocessed_boxes.png\n",
      "[OK] img_91_preprocessed.png: 0 digits detected → C:\\Users\\yugaa\\Documents\\Intelligentsystems\\notebooks\\segmentation\\img_91_preprocessed_boxes.png\n",
      "[OK] img_92_preprocessed.png: 0 digits detected → C:\\Users\\yugaa\\Documents\\Intelligentsystems\\notebooks\\segmentation\\img_92_preprocessed_boxes.png\n",
      "[OK] img_93_preprocessed.png: 0 digits detected → C:\\Users\\yugaa\\Documents\\Intelligentsystems\\notebooks\\segmentation\\img_93_preprocessed_boxes.png\n",
      "[OK] img_94_preprocessed.png: 0 digits detected → C:\\Users\\yugaa\\Documents\\Intelligentsystems\\notebooks\\segmentation\\img_94_preprocessed_boxes.png\n",
      "[OK] img_95_preprocessed.png: 0 digits detected → C:\\Users\\yugaa\\Documents\\Intelligentsystems\\notebooks\\segmentation\\img_95_preprocessed_boxes.png\n",
      "[OK] img_96_preprocessed.png: 0 digits detected → C:\\Users\\yugaa\\Documents\\Intelligentsystems\\notebooks\\segmentation\\img_96_preprocessed_boxes.png\n",
      "[OK] img_97_preprocessed.png: 0 digits detected → C:\\Users\\yugaa\\Documents\\Intelligentsystems\\notebooks\\segmentation\\img_97_preprocessed_boxes.png\n",
      "[OK] img_98_preprocessed.png: 0 digits detected → C:\\Users\\yugaa\\Documents\\Intelligentsystems\\notebooks\\segmentation\\img_98_preprocessed_boxes.png\n",
      "[OK] img_99_preprocessed.png: 0 digits detected → C:\\Users\\yugaa\\Documents\\Intelligentsystems\\notebooks\\segmentation\\img_99_preprocessed_boxes.png\n",
      "[OK] img_9_preprocessed.png: 0 digits detected → C:\\Users\\yugaa\\Documents\\Intelligentsystems\\notebooks\\segmentation\\img_9_preprocessed_boxes.png\n",
      "[OK] mnist0_preprocessed.png: 1 digits detected → C:\\Users\\yugaa\\Documents\\Intelligentsystems\\notebooks\\segmentation\\mnist0_preprocessed_boxes.png\n",
      "[OK] mnist10_preprocessed.png: 1 digits detected → C:\\Users\\yugaa\\Documents\\Intelligentsystems\\notebooks\\segmentation\\mnist10_preprocessed_boxes.png\n",
      "[OK] mnist11_preprocessed.png: 1 digits detected → C:\\Users\\yugaa\\Documents\\Intelligentsystems\\notebooks\\segmentation\\mnist11_preprocessed_boxes.png\n",
      "[OK] mnist12_preprocessed.png: 1 digits detected → C:\\Users\\yugaa\\Documents\\Intelligentsystems\\notebooks\\segmentation\\mnist12_preprocessed_boxes.png\n",
      "[OK] mnist13_preprocessed.png: 1 digits detected → C:\\Users\\yugaa\\Documents\\Intelligentsystems\\notebooks\\segmentation\\mnist13_preprocessed_boxes.png\n",
      "[OK] mnist14_preprocessed.png: 1 digits detected → C:\\Users\\yugaa\\Documents\\Intelligentsystems\\notebooks\\segmentation\\mnist14_preprocessed_boxes.png\n",
      "[OK] mnist15_preprocessed.png: 1 digits detected → C:\\Users\\yugaa\\Documents\\Intelligentsystems\\notebooks\\segmentation\\mnist15_preprocessed_boxes.png\n",
      "[OK] mnist16_preprocessed.png: 1 digits detected → C:\\Users\\yugaa\\Documents\\Intelligentsystems\\notebooks\\segmentation\\mnist16_preprocessed_boxes.png\n",
      "[OK] mnist17_preprocessed.png: 1 digits detected → C:\\Users\\yugaa\\Documents\\Intelligentsystems\\notebooks\\segmentation\\mnist17_preprocessed_boxes.png\n",
      "[OK] mnist18_preprocessed.png: 1 digits detected → C:\\Users\\yugaa\\Documents\\Intelligentsystems\\notebooks\\segmentation\\mnist18_preprocessed_boxes.png\n",
      "[OK] mnist19_preprocessed.png: 1 digits detected → C:\\Users\\yugaa\\Documents\\Intelligentsystems\\notebooks\\segmentation\\mnist19_preprocessed_boxes.png\n",
      "[OK] mnist1_preprocessed.png: 1 digits detected → C:\\Users\\yugaa\\Documents\\Intelligentsystems\\notebooks\\segmentation\\mnist1_preprocessed_boxes.png\n",
      "[OK] mnist20_preprocessed.png: 1 digits detected → C:\\Users\\yugaa\\Documents\\Intelligentsystems\\notebooks\\segmentation\\mnist20_preprocessed_boxes.png\n",
      "[OK] mnist21_preprocessed.png: 1 digits detected → C:\\Users\\yugaa\\Documents\\Intelligentsystems\\notebooks\\segmentation\\mnist21_preprocessed_boxes.png\n",
      "[OK] mnist22_preprocessed.png: 1 digits detected → C:\\Users\\yugaa\\Documents\\Intelligentsystems\\notebooks\\segmentation\\mnist22_preprocessed_boxes.png\n",
      "[OK] mnist23_preprocessed.png: 1 digits detected → C:\\Users\\yugaa\\Documents\\Intelligentsystems\\notebooks\\segmentation\\mnist23_preprocessed_boxes.png\n",
      "[OK] mnist24_preprocessed.png: 1 digits detected → C:\\Users\\yugaa\\Documents\\Intelligentsystems\\notebooks\\segmentation\\mnist24_preprocessed_boxes.png\n",
      "[OK] mnist25_preprocessed.png: 1 digits detected → C:\\Users\\yugaa\\Documents\\Intelligentsystems\\notebooks\\segmentation\\mnist25_preprocessed_boxes.png\n",
      "[OK] mnist26_preprocessed.png: 1 digits detected → C:\\Users\\yugaa\\Documents\\Intelligentsystems\\notebooks\\segmentation\\mnist26_preprocessed_boxes.png\n",
      "[OK] mnist27_preprocessed.png: 1 digits detected → C:\\Users\\yugaa\\Documents\\Intelligentsystems\\notebooks\\segmentation\\mnist27_preprocessed_boxes.png\n",
      "[OK] mnist28_preprocessed.png: 1 digits detected → C:\\Users\\yugaa\\Documents\\Intelligentsystems\\notebooks\\segmentation\\mnist28_preprocessed_boxes.png\n",
      "[OK] mnist29_preprocessed.png: 1 digits detected → C:\\Users\\yugaa\\Documents\\Intelligentsystems\\notebooks\\segmentation\\mnist29_preprocessed_boxes.png\n",
      "[OK] mnist2_preprocessed.png: 1 digits detected → C:\\Users\\yugaa\\Documents\\Intelligentsystems\\notebooks\\segmentation\\mnist2_preprocessed_boxes.png\n",
      "[OK] mnist30_preprocessed.png: 1 digits detected → C:\\Users\\yugaa\\Documents\\Intelligentsystems\\notebooks\\segmentation\\mnist30_preprocessed_boxes.png\n",
      "[OK] mnist31_preprocessed.png: 1 digits detected → C:\\Users\\yugaa\\Documents\\Intelligentsystems\\notebooks\\segmentation\\mnist31_preprocessed_boxes.png\n",
      "[OK] mnist32_preprocessed.png: 1 digits detected → C:\\Users\\yugaa\\Documents\\Intelligentsystems\\notebooks\\segmentation\\mnist32_preprocessed_boxes.png\n",
      "[OK] mnist33_preprocessed.png: 1 digits detected → C:\\Users\\yugaa\\Documents\\Intelligentsystems\\notebooks\\segmentation\\mnist33_preprocessed_boxes.png\n",
      "[OK] mnist34_preprocessed.png: 1 digits detected → C:\\Users\\yugaa\\Documents\\Intelligentsystems\\notebooks\\segmentation\\mnist34_preprocessed_boxes.png\n",
      "[OK] mnist35_preprocessed.png: 1 digits detected → C:\\Users\\yugaa\\Documents\\Intelligentsystems\\notebooks\\segmentation\\mnist35_preprocessed_boxes.png\n",
      "[OK] mnist36_preprocessed.png: 1 digits detected → C:\\Users\\yugaa\\Documents\\Intelligentsystems\\notebooks\\segmentation\\mnist36_preprocessed_boxes.png\n",
      "[OK] mnist37_preprocessed.png: 1 digits detected → C:\\Users\\yugaa\\Documents\\Intelligentsystems\\notebooks\\segmentation\\mnist37_preprocessed_boxes.png\n",
      "[OK] mnist38_preprocessed.png: 1 digits detected → C:\\Users\\yugaa\\Documents\\Intelligentsystems\\notebooks\\segmentation\\mnist38_preprocessed_boxes.png\n",
      "[OK] mnist39_preprocessed.png: 1 digits detected → C:\\Users\\yugaa\\Documents\\Intelligentsystems\\notebooks\\segmentation\\mnist39_preprocessed_boxes.png\n",
      "[OK] mnist3_preprocessed.png: 1 digits detected → C:\\Users\\yugaa\\Documents\\Intelligentsystems\\notebooks\\segmentation\\mnist3_preprocessed_boxes.png\n",
      "[OK] mnist40_preprocessed.png: 1 digits detected → C:\\Users\\yugaa\\Documents\\Intelligentsystems\\notebooks\\segmentation\\mnist40_preprocessed_boxes.png\n",
      "[OK] mnist41_preprocessed.png: 1 digits detected → C:\\Users\\yugaa\\Documents\\Intelligentsystems\\notebooks\\segmentation\\mnist41_preprocessed_boxes.png\n",
      "[OK] mnist42_preprocessed.png: 1 digits detected → C:\\Users\\yugaa\\Documents\\Intelligentsystems\\notebooks\\segmentation\\mnist42_preprocessed_boxes.png\n",
      "[OK] mnist43_preprocessed.png: 1 digits detected → C:\\Users\\yugaa\\Documents\\Intelligentsystems\\notebooks\\segmentation\\mnist43_preprocessed_boxes.png\n",
      "[OK] mnist44_preprocessed.png: 1 digits detected → C:\\Users\\yugaa\\Documents\\Intelligentsystems\\notebooks\\segmentation\\mnist44_preprocessed_boxes.png\n",
      "[OK] mnist45_preprocessed.png: 1 digits detected → C:\\Users\\yugaa\\Documents\\Intelligentsystems\\notebooks\\segmentation\\mnist45_preprocessed_boxes.png\n",
      "[OK] mnist46_preprocessed.png: 1 digits detected → C:\\Users\\yugaa\\Documents\\Intelligentsystems\\notebooks\\segmentation\\mnist46_preprocessed_boxes.png\n",
      "[OK] mnist47_preprocessed.png: 1 digits detected → C:\\Users\\yugaa\\Documents\\Intelligentsystems\\notebooks\\segmentation\\mnist47_preprocessed_boxes.png\n",
      "[OK] mnist48_preprocessed.png: 1 digits detected → C:\\Users\\yugaa\\Documents\\Intelligentsystems\\notebooks\\segmentation\\mnist48_preprocessed_boxes.png\n",
      "[OK] mnist49_preprocessed.png: 1 digits detected → C:\\Users\\yugaa\\Documents\\Intelligentsystems\\notebooks\\segmentation\\mnist49_preprocessed_boxes.png\n",
      "[OK] mnist4_preprocessed.png: 1 digits detected → C:\\Users\\yugaa\\Documents\\Intelligentsystems\\notebooks\\segmentation\\mnist4_preprocessed_boxes.png\n",
      "[OK] mnist50_preprocessed.png: 1 digits detected → C:\\Users\\yugaa\\Documents\\Intelligentsystems\\notebooks\\segmentation\\mnist50_preprocessed_boxes.png\n",
      "[OK] mnist51_preprocessed.png: 1 digits detected → C:\\Users\\yugaa\\Documents\\Intelligentsystems\\notebooks\\segmentation\\mnist51_preprocessed_boxes.png\n",
      "[OK] mnist52_preprocessed.png: 1 digits detected → C:\\Users\\yugaa\\Documents\\Intelligentsystems\\notebooks\\segmentation\\mnist52_preprocessed_boxes.png\n",
      "[OK] mnist53_preprocessed.png: 1 digits detected → C:\\Users\\yugaa\\Documents\\Intelligentsystems\\notebooks\\segmentation\\mnist53_preprocessed_boxes.png\n",
      "[OK] mnist54_preprocessed.png: 1 digits detected → C:\\Users\\yugaa\\Documents\\Intelligentsystems\\notebooks\\segmentation\\mnist54_preprocessed_boxes.png\n",
      "[OK] mnist55_preprocessed.png: 1 digits detected → C:\\Users\\yugaa\\Documents\\Intelligentsystems\\notebooks\\segmentation\\mnist55_preprocessed_boxes.png\n",
      "[OK] mnist56_preprocessed.png: 1 digits detected → C:\\Users\\yugaa\\Documents\\Intelligentsystems\\notebooks\\segmentation\\mnist56_preprocessed_boxes.png\n",
      "[OK] mnist57_preprocessed.png: 1 digits detected → C:\\Users\\yugaa\\Documents\\Intelligentsystems\\notebooks\\segmentation\\mnist57_preprocessed_boxes.png\n",
      "[OK] mnist58_preprocessed.png: 1 digits detected → C:\\Users\\yugaa\\Documents\\Intelligentsystems\\notebooks\\segmentation\\mnist58_preprocessed_boxes.png\n",
      "[OK] mnist59_preprocessed.png: 1 digits detected → C:\\Users\\yugaa\\Documents\\Intelligentsystems\\notebooks\\segmentation\\mnist59_preprocessed_boxes.png\n",
      "[OK] mnist5_preprocessed.png: 1 digits detected → C:\\Users\\yugaa\\Documents\\Intelligentsystems\\notebooks\\segmentation\\mnist5_preprocessed_boxes.png\n",
      "[OK] mnist60_preprocessed.png: 1 digits detected → C:\\Users\\yugaa\\Documents\\Intelligentsystems\\notebooks\\segmentation\\mnist60_preprocessed_boxes.png\n",
      "[OK] mnist61_preprocessed.png: 1 digits detected → C:\\Users\\yugaa\\Documents\\Intelligentsystems\\notebooks\\segmentation\\mnist61_preprocessed_boxes.png\n",
      "[OK] mnist62_preprocessed.png: 1 digits detected → C:\\Users\\yugaa\\Documents\\Intelligentsystems\\notebooks\\segmentation\\mnist62_preprocessed_boxes.png\n",
      "[OK] mnist63_preprocessed.png: 1 digits detected → C:\\Users\\yugaa\\Documents\\Intelligentsystems\\notebooks\\segmentation\\mnist63_preprocessed_boxes.png\n",
      "[OK] mnist64_preprocessed.png: 1 digits detected → C:\\Users\\yugaa\\Documents\\Intelligentsystems\\notebooks\\segmentation\\mnist64_preprocessed_boxes.png\n",
      "[OK] mnist65_preprocessed.png: 1 digits detected → C:\\Users\\yugaa\\Documents\\Intelligentsystems\\notebooks\\segmentation\\mnist65_preprocessed_boxes.png\n",
      "[OK] mnist66_preprocessed.png: 1 digits detected → C:\\Users\\yugaa\\Documents\\Intelligentsystems\\notebooks\\segmentation\\mnist66_preprocessed_boxes.png\n",
      "[OK] mnist67_preprocessed.png: 1 digits detected → C:\\Users\\yugaa\\Documents\\Intelligentsystems\\notebooks\\segmentation\\mnist67_preprocessed_boxes.png\n",
      "[OK] mnist68_preprocessed.png: 1 digits detected → C:\\Users\\yugaa\\Documents\\Intelligentsystems\\notebooks\\segmentation\\mnist68_preprocessed_boxes.png\n",
      "[OK] mnist69_preprocessed.png: 1 digits detected → C:\\Users\\yugaa\\Documents\\Intelligentsystems\\notebooks\\segmentation\\mnist69_preprocessed_boxes.png\n",
      "[OK] mnist6_preprocessed.png: 1 digits detected → C:\\Users\\yugaa\\Documents\\Intelligentsystems\\notebooks\\segmentation\\mnist6_preprocessed_boxes.png\n",
      "[OK] mnist70_preprocessed.png: 1 digits detected → C:\\Users\\yugaa\\Documents\\Intelligentsystems\\notebooks\\segmentation\\mnist70_preprocessed_boxes.png\n",
      "[OK] mnist71_preprocessed.png: 1 digits detected → C:\\Users\\yugaa\\Documents\\Intelligentsystems\\notebooks\\segmentation\\mnist71_preprocessed_boxes.png\n",
      "[OK] mnist72_preprocessed.png: 1 digits detected → C:\\Users\\yugaa\\Documents\\Intelligentsystems\\notebooks\\segmentation\\mnist72_preprocessed_boxes.png\n",
      "[OK] mnist73_preprocessed.png: 1 digits detected → C:\\Users\\yugaa\\Documents\\Intelligentsystems\\notebooks\\segmentation\\mnist73_preprocessed_boxes.png\n",
      "[OK] mnist74_preprocessed.png: 1 digits detected → C:\\Users\\yugaa\\Documents\\Intelligentsystems\\notebooks\\segmentation\\mnist74_preprocessed_boxes.png\n",
      "[OK] mnist75_preprocessed.png: 1 digits detected → C:\\Users\\yugaa\\Documents\\Intelligentsystems\\notebooks\\segmentation\\mnist75_preprocessed_boxes.png\n",
      "[OK] mnist76_preprocessed.png: 1 digits detected → C:\\Users\\yugaa\\Documents\\Intelligentsystems\\notebooks\\segmentation\\mnist76_preprocessed_boxes.png\n",
      "[OK] mnist77_preprocessed.png: 1 digits detected → C:\\Users\\yugaa\\Documents\\Intelligentsystems\\notebooks\\segmentation\\mnist77_preprocessed_boxes.png\n",
      "[OK] mnist78_preprocessed.png: 1 digits detected → C:\\Users\\yugaa\\Documents\\Intelligentsystems\\notebooks\\segmentation\\mnist78_preprocessed_boxes.png\n",
      "[OK] mnist79_preprocessed.png: 1 digits detected → C:\\Users\\yugaa\\Documents\\Intelligentsystems\\notebooks\\segmentation\\mnist79_preprocessed_boxes.png\n",
      "[OK] mnist7_preprocessed.png: 1 digits detected → C:\\Users\\yugaa\\Documents\\Intelligentsystems\\notebooks\\segmentation\\mnist7_preprocessed_boxes.png\n",
      "[OK] mnist80_preprocessed.png: 1 digits detected → C:\\Users\\yugaa\\Documents\\Intelligentsystems\\notebooks\\segmentation\\mnist80_preprocessed_boxes.png\n",
      "[OK] mnist81_preprocessed.png: 1 digits detected → C:\\Users\\yugaa\\Documents\\Intelligentsystems\\notebooks\\segmentation\\mnist81_preprocessed_boxes.png\n",
      "[OK] mnist82_preprocessed.png: 1 digits detected → C:\\Users\\yugaa\\Documents\\Intelligentsystems\\notebooks\\segmentation\\mnist82_preprocessed_boxes.png\n",
      "[OK] mnist83_preprocessed.png: 1 digits detected → C:\\Users\\yugaa\\Documents\\Intelligentsystems\\notebooks\\segmentation\\mnist83_preprocessed_boxes.png\n",
      "[OK] mnist84_preprocessed.png: 1 digits detected → C:\\Users\\yugaa\\Documents\\Intelligentsystems\\notebooks\\segmentation\\mnist84_preprocessed_boxes.png\n",
      "[OK] mnist85_preprocessed.png: 1 digits detected → C:\\Users\\yugaa\\Documents\\Intelligentsystems\\notebooks\\segmentation\\mnist85_preprocessed_boxes.png\n",
      "[OK] mnist86_preprocessed.png: 1 digits detected → C:\\Users\\yugaa\\Documents\\Intelligentsystems\\notebooks\\segmentation\\mnist86_preprocessed_boxes.png\n",
      "[OK] mnist87_preprocessed.png: 1 digits detected → C:\\Users\\yugaa\\Documents\\Intelligentsystems\\notebooks\\segmentation\\mnist87_preprocessed_boxes.png\n",
      "[OK] mnist88_preprocessed.png: 1 digits detected → C:\\Users\\yugaa\\Documents\\Intelligentsystems\\notebooks\\segmentation\\mnist88_preprocessed_boxes.png\n",
      "[OK] mnist89_preprocessed.png: 1 digits detected → C:\\Users\\yugaa\\Documents\\Intelligentsystems\\notebooks\\segmentation\\mnist89_preprocessed_boxes.png\n",
      "[OK] mnist8_preprocessed.png: 1 digits detected → C:\\Users\\yugaa\\Documents\\Intelligentsystems\\notebooks\\segmentation\\mnist8_preprocessed_boxes.png\n",
      "[OK] mnist90_preprocessed.png: 1 digits detected → C:\\Users\\yugaa\\Documents\\Intelligentsystems\\notebooks\\segmentation\\mnist90_preprocessed_boxes.png\n",
      "[OK] mnist91_preprocessed.png: 1 digits detected → C:\\Users\\yugaa\\Documents\\Intelligentsystems\\notebooks\\segmentation\\mnist91_preprocessed_boxes.png\n",
      "[OK] mnist92_preprocessed.png: 1 digits detected → C:\\Users\\yugaa\\Documents\\Intelligentsystems\\notebooks\\segmentation\\mnist92_preprocessed_boxes.png\n",
      "[OK] mnist93_preprocessed.png: 1 digits detected → C:\\Users\\yugaa\\Documents\\Intelligentsystems\\notebooks\\segmentation\\mnist93_preprocessed_boxes.png\n",
      "[OK] mnist94_preprocessed.png: 1 digits detected → C:\\Users\\yugaa\\Documents\\Intelligentsystems\\notebooks\\segmentation\\mnist94_preprocessed_boxes.png\n",
      "[OK] mnist95_preprocessed.png: 1 digits detected → C:\\Users\\yugaa\\Documents\\Intelligentsystems\\notebooks\\segmentation\\mnist95_preprocessed_boxes.png\n",
      "[OK] mnist96_preprocessed.png: 1 digits detected → C:\\Users\\yugaa\\Documents\\Intelligentsystems\\notebooks\\segmentation\\mnist96_preprocessed_boxes.png\n",
      "[OK] mnist97_preprocessed.png: 1 digits detected → C:\\Users\\yugaa\\Documents\\Intelligentsystems\\notebooks\\segmentation\\mnist97_preprocessed_boxes.png\n",
      "[OK] mnist98_preprocessed.png: 1 digits detected → C:\\Users\\yugaa\\Documents\\Intelligentsystems\\notebooks\\segmentation\\mnist98_preprocessed_boxes.png\n",
      "[OK] mnist99_preprocessed.png: 1 digits detected → C:\\Users\\yugaa\\Documents\\Intelligentsystems\\notebooks\\segmentation\\mnist99_preprocessed_boxes.png\n",
      "[OK] mnist9_preprocessed.png: 1 digits detected → C:\\Users\\yugaa\\Documents\\Intelligentsystems\\notebooks\\segmentation\\mnist9_preprocessed_boxes.png\n",
      "\n",
      "Task 2 complete. Overlays with thin boxes saved in: C:\\Users\\yugaa\\Documents\\Intelligentsystems\\notebooks\\segmentation\n"
     ]
    }
   ],
   "source": [
    "\n",
    "BASE_DIR = Path(os.getcwd())\n",
    "IN_DIR  = BASE_DIR /\"Preprocessed\"\n",
    "OUT_DIR  = BASE_DIR /\"segmentation\"\n",
    "\n",
    "IN_DIR.mkdir(parents=True, exist_ok=True)\n",
    "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "#Contour segmentation\n",
    "def segment_contours(bw, dilate_kernel=(3,3), min_area=30):\n",
    "    dil = cv2.dilate(bw, cv2.getStructuringElement(cv2.MORPH_RECT, dilate_kernel), 1)\n",
    "    contours, _ = cv2.findContours(dil, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    boxes = []\n",
    "    for c in contours:\n",
    "        x,y,w,h = cv2.boundingRect(c)\n",
    "        if w*h >= min_area and h > 6 and w > 3:\n",
    "            boxes.append((x,y,w,h))\n",
    "    return sorted(boxes, key=lambda b: b[0])\n",
    "\n",
    "# --- Splitter for wide blobs ---\n",
    "def projection_split(sub_bw, min_run=6):\n",
    "    v = (sub_bw.sum(axis=0) > 0).astype(np.uint8)\n",
    "    runs, start = [], None\n",
    "    for i, val in enumerate(v):\n",
    "        if val and start is None:\n",
    "            start = i\n",
    "        if not val and start is not None:\n",
    "            if i - start >= min_run:\n",
    "                runs.append((start, i))\n",
    "            start = None\n",
    "    if start is not None and len(v)-start >= min_run:\n",
    "        runs.append((start, len(v)))\n",
    "    return runs\n",
    "\n",
    "# --- Main segmentation ---\n",
    "def segment_digits(img_gray):\n",
    "    _, bw = cv2.threshold(img_gray, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "    boxes = segment_contours(bw)\n",
    "\n",
    "    refined = []\n",
    "    for (x,y,w,h) in boxes:\n",
    "        if w > 1.5 * h:  # only split if clearly wide\n",
    "            sub = bw[y:y+h, x:x+w]\n",
    "            splits = projection_split(sub, min_run=6)\n",
    "            if len(splits) >= 2:\n",
    "                for sx, ex in splits:\n",
    "                    refined.append((x+sx, y, ex-sx, h))\n",
    "                continue\n",
    "        refined.append((x,y,w,h))\n",
    "\n",
    "    refined = sorted(refined, key=lambda b: b[0])\n",
    "\n",
    "    vis = cv2.cvtColor(img_gray, cv2.COLOR_GRAY2BGR)\n",
    "    for (x,y,w,h) in refined:\n",
    "        cv2.rectangle(vis, (x,y), (x+w, y+h), (0,255,0), 1)  # <!-- thinner box\n",
    "\n",
    "    return refined, vis\n",
    "\n",
    "# --- Run on all Task 1 images ---\n",
    "for fname in os.listdir(IN_DIR):\n",
    "    if not fname.lower().endswith(\".png\"):\n",
    "        continue\n",
    "    path = os.path.join(IN_DIR, fname)\n",
    "    img_gray = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "    boxes, vis = segment_digits(img_gray)\n",
    "    base = os.path.splitext(fname)[0]\n",
    "\n",
    "    out_path = os.path.join(OUT_DIR, f\"{base}_boxes.png\")\n",
    "    cv2.imwrite(out_path, vis)\n",
    "\n",
    "    print(f\"[OK] {fname}: {len(boxes)} digits detected → {out_path}\")\n",
    "\n",
    "print(\"\\nTask 2 complete. Overlays with thin boxes saved in:\", OUT_DIR)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Nt31PZF2Qynf"
   },
   "source": [
    "# Detection Test Printing Random Number "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 487
    },
    "id": "8rOn07u2pJhQ",
    "jupyter": {
     "source_hidden": true
    },
    "outputId": "358dc3ac-b5fe-4b53-de52-3aff21273a2a",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28) (60000,)\n",
      "1\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#test The printing\n",
    "BASE_DIR = Path(os.getcwd())\n",
    "IN_DIR  = BASE_DIR /\"Segmentation\"\n",
    "OUT_DIR  = BASE_DIR /\"Detected\"\n",
    "\n",
    "IN_DIR.mkdir(parents=True, exist_ok=True)\n",
    "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "\n",
    "#Output the image and label to screen\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import random\n",
    "random_i=random.randint(0,999)\n",
    "\n",
    "print(x_train.shape, y_train.shape)  # print shape\n",
    "plt.imshow(x_train[random_i], cmap='gray')  # See the first digit\n",
    "plt.title(f\"Label: {y_train[random_i]}\")\n",
    "print(f\"{y_train[random_i]}\")\n",
    "plt.show()\n",
    "#This part above might be good for gui\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KaToZmRqRgJl"
   },
   "source": [
    "# Digit Detection\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 587
    },
    "collapsed": true,
    "id": "sGZQCHKVC8PM",
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "outputId": "8a3cfb34-776c-4bf0-82dc-080e2c9d0e8a",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"Multiple_Layer_Perceptron\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"Multiple_Layer_Perceptron\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ flatten_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">784</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │         <span style=\"color: #00af00; text-decoration-color: #00af00\">100,480</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">650</span> │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ flatten_1 (\u001b[38;5;33mFlatten\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m784\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │         \u001b[38;5;34m100,480\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │           \u001b[38;5;34m8,256\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_5 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)                  │             \u001b[38;5;34m650\u001b[0m │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">109,386</span> (427.29 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m109,386\u001b[0m (427.29 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">109,386</span> (427.29 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m109,386\u001b[0m (427.29 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Sequential name=Multiple_Layer_Perceptron, built=True>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Mutiple layer perception\n",
    "#connected neural net\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Flatten, Dense\n",
    "def Multiple_Layer_Perceptron(input_shape):\n",
    "    name=\"Multiple_Layer_Perceptron\"\n",
    "      #The yes/no decision layer stack\n",
    "    model=Sequential(name=name)\n",
    "    \n",
    "    model.add(Flatten(input_shape=input_shape))#turn into 1 flat layer aka 28 x 28 in line of 784 pix instead of grid\n",
    "    model.add(Dense(128,activation='relu'))#rectafy liner unit keep pos kill neg------this si the first hidden layer\n",
    "    model.add(Dense(64,activation='relu'))#second hidden layer\n",
    "    model.add(Dense(10,activation='softmax'))#Output layer, 10 neurons--all outputs must + to get 1\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss='sparse_categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    model.summary()\n",
    "    #model.compile(optimizer=\"adam\",loss=\"categorical_crossentropy\", metrics=['accuracy'])\n",
    "    #model.fit(x_train,y_train)\n",
    "    #hamTest=eval_model(model,x_test,y_test,\"MLP\")\n",
    "    return model\n",
    "    \n",
    "Multiple_Layer_Perceptron((28,28))\n",
    "\n",
    "#Reinforcement and supervision learning test\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 449,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"Convolutional_Neural_Network\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"Convolutional_Neural_Network\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ conv2d_48 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">896</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling2d_32 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)          │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_49 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │          <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling2d_33 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)            │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_50 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)            │          <span style=\"color: #00af00; text-decoration-color: #00af00\">36,928</span> │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ conv2d_48 (\u001b[38;5;33mConv2D\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m32\u001b[0m)          │             \u001b[38;5;34m896\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling2d_32 (\u001b[38;5;33mMaxPooling2D\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m32\u001b[0m)          │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_49 (\u001b[38;5;33mConv2D\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m13\u001b[0m, \u001b[38;5;34m13\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │          \u001b[38;5;34m18,496\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling2d_33 (\u001b[38;5;33mMaxPooling2D\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m64\u001b[0m)            │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_50 (\u001b[38;5;33mConv2D\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m64\u001b[0m)            │          \u001b[38;5;34m36,928\u001b[0m │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">56,320</span> (220.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m56,320\u001b[0m (220.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">56,320</span> (220.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m56,320\u001b[0m (220.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#cnn\n",
    "from tensorflow.keras.layers import Conv2D,MaxPooling2D\n",
    "from tensorflow.keras.models import Sequential\n",
    "def Convolutional_Neural_Network(input_shape):\n",
    "    name=\"Convolutional_Neural_Network\"\n",
    "    model=keras.Sequential([ \n",
    "        Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        Conv2D(64, (3, 3), activation='relu'),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        Conv2D(64, (3, 3), activation='relu')\n",
    "    ],name=name)\n",
    "  \n",
    "    model.summary()\n",
    "Convolutional_Neural_Network((28,28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "XgJAlugNPRnt"
   },
   "outputs": [],
   "source": [
    "#This is the evalute model tester function\n",
    "def eval_model(model,x_test,y_test,model_name=\"hambubgerV1\"):\n",
    "  loss,accuracy=model.evaluate(x_test,y_test)\n",
    "  print(f\"{model_name} - Test Accuracy: {accuracy:.4f}\")\n",
    "  return accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 968
    },
    "id": "aEXaJavwzfms",
    "outputId": "b50e7ac8-89a4-4327-b326-709e3e99af55"
   },
   "outputs": [],
   "source": [
    "# Choose Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ reshape_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Reshape</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>)              │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ lstm_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │          <span style=\"color: #00af00; text-decoration-color: #00af00\">80,384</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">4,128</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">330</span> │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ reshape_1 (\u001b[38;5;33mReshape\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m)              │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ lstm_1 (\u001b[38;5;33mLSTM\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │          \u001b[38;5;34m80,384\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │           \u001b[38;5;34m4,128\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)                  │             \u001b[38;5;34m330\u001b[0m │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">84,842</span> (331.41 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m84,842\u001b[0m (331.41 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">84,842</span> (331.41 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m84,842\u001b[0m (331.41 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Sequential name=sequential_1, built=True>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense,Input,Reshape\n",
    "\n",
    "def Recurrent_Neural_Networks(input_shape):\n",
    "    model = Sequential([\n",
    "        Input(shape=input_shape),        # Proper way to define input shape\n",
    "        Reshape((28, 28)),              # reshape 28x28 image → sequence\n",
    "        LSTM(128),                      # LSTM layer\n",
    "        Dense(32, activation=\"relu\"), # Output layer for 10 digits\n",
    "        Dense(10, activation=\"softmax\") # Output layer for 10 digits\n",
    "    ])\n",
    "    model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "   \n",
    "    model.summary()\n",
    "    return model\n",
    "Recurrent_Neural_Networks((28,28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 968
    },
    "id": "aEXaJavwzfms",
    "outputId": "b50e7ac8-89a4-4327-b326-709e3e99af55",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Please select a model(0=default program, 1=MLP,2= CNN, 3=DNN, 4=RNN) 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You have selected: Recurrent Neural Networks (RNNs)\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Please select a option(1=Test Model, 2=Train Model) 1\n",
      "Please choose index betwen 0-900:  46\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ reshape (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Reshape</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>)              │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │          <span style=\"color: #00af00; text-decoration-color: #00af00\">80,384</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">4,128</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">330</span> │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ reshape (\u001b[38;5;33mReshape\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m)              │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │          \u001b[38;5;34m80,384\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │           \u001b[38;5;34m4,128\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)                  │             \u001b[38;5;34m330\u001b[0m │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">84,842</span> (331.41 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m84,842\u001b[0m (331.41 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">84,842</span> (331.41 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m84,842\u001b[0m (331.41 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 22ms/step - accuracy: 0.1594 - loss: 2.2272\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 105ms/step\n",
      "Model predicts 1\n",
      "True label is: 1\n",
      "IT IS CORRECT\n",
      "saved image to C:\\Users\\yugaa\\Documents\\Intelligentsystems\\notebooks\\Detected\\label_46_predicted_1.png\n"
     ]
    }
   ],
   "source": [
    "BASE_DIR = Path(os.getcwd())\n",
    "IN_DIR  = BASE_DIR /\"Segmentation\"\n",
    "OUT_DIR  = BASE_DIR /\"Detected\"\n",
    "\n",
    "IN_DIR.mkdir(parents=True, exist_ok=True)\n",
    "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "#Fully connected neural net\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Flatten, Dense\n",
    "from tensorflow.keras import backend as K\n",
    "#The below is a calling method to test all of the types of models\n",
    "#THIS DOES NOT INCLUDE TRAINING!!!! THIS IS TO TEST SPECFIC ONES\n",
    "\n",
    "\n",
    "\n",
    "available_models=[\"Pray\",\"Multi Layer Perception Model (MLPs)\",\"Convolutional Neural Networks (CNNs) \",\"Deep Neural Networks (DNNs) \",\"Recurrent Neural Networks (RNNs)\"]\n",
    "which_model=int(input(\"Please select a model(0=default program, 1=MLP,2= CNN, 3=DNN, 4=RNN)\"))\n",
    "print(f\"You have selected: {available_models[which_model]}\")\n",
    "train_or_test=int(input(\"Please select a option(1=Test Model, 2=Train Model)\"))\n",
    "if train_or_test==1:\n",
    "    dataset='test'\n",
    "    reinforce=False\n",
    "elif train_or_test==2:\n",
    "    dataset='train'\n",
    "    reinforce=True\n",
    "else:\n",
    "    print(\"I dont want to add another option\")\n",
    "K.clear_session()\n",
    "match which_model:\n",
    "  #Multi Layer Perception Model (MLPs)\n",
    "  case 1:\n",
    "  #specific test\n",
    "    i=int(input(\"Please choose index betwen 0-900: \"))\n",
    "    if i >= 0 and i <=900:\n",
    "      img=x_test[i]\n",
    "      true_label=y_test[i]\n",
    "      #SHOW ME THE MONEY\n",
    "      plt.imshow(img,cmap='gray')\n",
    "      plt.title(f\" Data test #{i} - True Label:{true_label}\")\n",
    "      plt.show()\n",
    "      model = Multiple_Layer_Perceptron(x_train.shape[1:])\n",
    "      model.compile(optimizer=\"adam\",loss=\"sparse_categorical_crossentropy\", metrics=['accuracy'])\n",
    "      img_mlp = np.expand_dims(img, axis=0)\n",
    "      predicted_label=np.argmax(model.predict(img_mlp))\n",
    "\n",
    "   \n",
    "         #Somehow lost a variable at some point so were doing longer math\n",
    "    if len(np.shape(true_label))>0:#Prob a one hot girlie\n",
    "        truth_of_label_index=int(np.argmax(true_label))\n",
    "    else:\n",
    "        truth_of_label_index=int(true_label)\n",
    "    print(f\"Model predicts {predicted_label}\")\n",
    "        #Had to Change back\n",
    "    print(f\"True label is: {truth_of_label_index}\")\n",
    "      \n",
    "    if predicted_label != truth_of_label_index:\n",
    "        reinforcement(i=i, model=model,model_index=1, dataset=dataset, reinforce=reinforce)\n",
    "    else:\n",
    "        print(\"IT IS CORRECT\")\n",
    "  #Convolutional Neural Networks (CNNs) \n",
    "  case 2:\n",
    "    print(f\"{available_models[which_model]}\")\n",
    "  #\n",
    "  case 3:\n",
    "    print(f\"{available_models[which_model]}\")\n",
    "  #Recurrent Neural Networks (RNNs)\n",
    "    #https://stanford.edu/~shervine/teaching/cs-230/cheatsheet-recurrent-neural-networks\n",
    "#This cheatsheet is the only way to understand what on earth the math is\n",
    "  case 4:\n",
    "    dataset=dataset\n",
    "    i=int(input(\"Please choose index betwen 0-900: \"))\n",
    "    if i >= 0 and i <=900:\n",
    "          img=x_test[i]\n",
    "          true_label=y_test[i]\n",
    "          #SHOW ME THE MONEY\n",
    "          plt.imshow(img,cmap='gray')\n",
    "          plt.title(f\" Data test #{i} - True Label:{true_label}\")\n",
    "          plt.show()\n",
    "        #Build the rnn model\n",
    "        #MUST MAKE SURE THE THING IS PASSED AS TWO AGURMENTS INSTEAD OF ONE TUPLE . IE (28,28) IS WRONG but ((28,28)) is correct\n",
    "          model=Recurrent_Neural_Networks(x_train.shape[1:])#test mechs are x_train.shape[1:] or 28,28\n",
    "          #train the model\n",
    "          y_train_cat = to_categorical(y_train, num_classes=10)\n",
    "          model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=['accuracy'])\n",
    "          model.fit(x_train,y_train_cat,epochs=1,batch_size=128,verbose=1)\n",
    "        #predict\n",
    "       \n",
    "          img_rnn = np.expand_dims(img, axis=0)\n",
    "          predicted_label=np.argmax(model.predict(img_rnn))\n",
    "         \n",
    "          if len(np.shape(true_label)) > 0:  # one-hot\n",
    "            truth_of_label_index = int(np.argmax(true_label))\n",
    "          else:\n",
    "            truth_of_label_index = int(true_label)\n",
    "              \n",
    "          y_input = to_categorical([truth_of_label_index], num_classes=10)  # shape (1, 10)\n",
    "          print(f\"Model predicts {predicted_label}\")\n",
    "          print(f\"True label is: {truth_of_label_index}\")\n",
    "        \n",
    "          if predicted_label != truth_of_label_index:\n",
    "                reinforcement(i=i, model=model,model_index=4, dataset=dataset, reinforce=reinforce)\n",
    "          else:\n",
    "              print(\"IT IS CORRECT\")\n",
    "        \n",
    "          \n",
    "  case _:\n",
    "    print('You selected default or an invalid option.')\n",
    "\n",
    "img_uint8 = (img * 255).astype(np.uint8)\n",
    "filename = OUT_DIR/ f\"label_{i}_predicted_{truth_of_label_index}.png\"\n",
    "cv2.imwrite(str(filename), img_uint8)\n",
    "\n",
    "print(f\"saved image to {filename}\")\n",
    "#When testying try 54 its weird\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "3K9P3v_mHgEc"
   },
   "outputs": [],
   "source": [
    "#reinforcement model\n",
    "#model = multiple_layer_perceptron_model(x_train.shape[1:])  \n",
    "\n",
    "#For unknown reasons this code has decieded to be a asshole, please do not question why it will take vengeage\n",
    "#Reinforcement Testing function is mostly for weird cases i dont really know when we would want it\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import numpy as np\n",
    "\n",
    "def reinforcement(i, model, model_index, dataset, reinforce=True):\n",
    "    print(f\"Model index: {model_index}\")\n",
    "\n",
    "    # Select the correct image and true label\n",
    "    if dataset == 'test':\n",
    "        img = x_test[i]\n",
    "        true_label = y_test[i]\n",
    "    else:\n",
    "        img = x_train[i]\n",
    "        true_label = y_train[i]\n",
    "\n",
    "    # Expand dims for model input\n",
    "    img_input = np.expand_dims(img, axis=0)  # shape: (1, 28, 28) or (1, 28, 28, 1)\n",
    "\n",
    "    # Convert true_label to scalar if one-hot\n",
    "    if isinstance(true_label, np.ndarray) and len(true_label.shape) > 0:\n",
    "        truth_of_label_index = int(np.argmax(true_label))\n",
    "    else:\n",
    "        truth_of_label_index = int(true_label)\n",
    "\n",
    "    # Predict label\n",
    "    predicted_label = int(np.argmax(model.predict(img_input)))\n",
    "\n",
    "    print(f\"Predicted label: {predicted_label}\")\n",
    "    print(f\"True label: {truth_of_label_index}\")\n",
    "\n",
    "    # Reinforce only if prediction is wrong\n",
    "    if predicted_label != truth_of_label_index and reinforce:\n",
    "        print(\"Incorrect! Updating model with correct label...\")\n",
    "\n",
    "        # Determine whether to use sparse or categorical\n",
    "        if model.loss == 'categorical_crossentropy':\n",
    "            y_input = to_categorical([truth_of_label_index], num_classes=10)\n",
    "        else:  # sparse_categorical_crossentropy\n",
    "            y_input = np.array([truth_of_label_index])\n",
    "\n",
    "        # Update model\n",
    "        model.fit(img_input, y_input, epochs=1, verbose=0)\n",
    "        print(\"Model updated!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zLHapOWiRtds"
   },
   "outputs": [],
   "source": [
    "#This is for other detection\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A-76qD_MTZjV"
   },
   "source": [
    "# Letter detection\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 505
    },
    "id": "7NEsM5oITckU",
    "outputId": "99b1e990-4b36-4ba4-cd1f-a2a3bc9e6de2"
   },
   "outputs": [],
   "source": [
    "i=\n",
    "def predict_letters(i,model,dataset='test',save_image=True):\n",
    "  \"\"\"\n",
    "  predict oimage label, show it and print predict\n",
    "  para\n",
    "    index\n",
    "    model-being used\n",
    "    dataset-train or test data\n",
    "    save_image: if true save image to outdir\n",
    "  \"\"\"\n",
    "  if dataset=='test':\n",
    "    img=x_test[i]\n",
    "    true_label=y_test[i]\n",
    "  else:\n",
    "    img= x_train[i]\n",
    "    true_label=y_train[i]\n",
    "  #PREPARE FOR MODEL\n",
    "\n",
    "img_input=np.expand_dims(img,axis=0)\n",
    "predict_label=np.argmax(model.predict(img_input))\n",
    "#display\n",
    "plt.imshow(img.squeeze(),cmap='gray')\n",
    "plt.title(f\"Image #{i} - True: {true_label}, Predicted Value: {predict_label}\")\n",
    "plt.axis=(\"off\")\n",
    "plt.show()\n",
    "print(f\"Predicted: {predict_label}\")\n",
    "print(f\"True: {true_label}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
